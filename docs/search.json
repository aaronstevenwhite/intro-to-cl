[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About",
    "section": "",
    "text": "This site contains materials for Introduction to Computational Linguistics–a course given by Aaron Steven White at the University of Rochester."
  },
  {
    "objectID": "index.html#about-the-course",
    "href": "index.html#about-the-course",
    "title": "About",
    "section": "About the course",
    "text": "About the course\nThis course covers foundational concepts in computational linguistics. Major focus is placed on the use of formal languages as a tool for understanding natural language as well as on developing students’ ability to implement foundational algorithms pertaining to those formal languages. Topics include basic formal language theory, finite state phonological and morphological parsing, and syntactic parsing for context free grammars and mildly context sensitive formalisms."
  },
  {
    "objectID": "index.html#prerequisites",
    "href": "index.html#prerequisites",
    "title": "About",
    "section": "Prerequisites",
    "text": "Prerequisites\nThis course relies on concepts covered in an introductory linguistics course and an introductory programming course. With respect to the latter, it specifically assumes that you can competently write scripts that do non-trivial things and can work competently with Python’s object-oriented programming facilities but maybe not develop a package on your own."
  },
  {
    "objectID": "index.html#about-the-instructor",
    "href": "index.html#about-the-instructor",
    "title": "About",
    "section": "About the instructor",
    "text": "About the instructor\nAaron Steven White is an Associate Professor of Linguistics and Computer Science at the University of Rochester, where he directs the Formal and Computational Semantics lab (FACTS.lab). His research investigates the relationship between linguistic expressions and conceptual categories that undergird the human ability to convey information about possible past, present, and future configurations of things in the world.\nIn addition to being a principal investigator on numerous federally funded grants and contracts, White is the recipient of a National Science Foundation Faculty Early Career Development (CAREER) award. His work has appeared in a variety linguistics, cognitive science, and natural language processing venues, including Semantics & Pragmatics, Glossa, Language Acquisition, Cognitive Science, Cognitive Psychology, Transactions of the Association for Computational Linguistics, and Empirical Methods in Natural Language Processing."
  },
  {
    "objectID": "index.html#about-the-site",
    "href": "index.html#about-the-site",
    "title": "About",
    "section": "About the site",
    "text": "About the site\nThe site itself is built using Quarto. The source files for this site are available on github at aaronstevenwhite/intro-to-cl. See Installation for information on how to run the code documented here."
  },
  {
    "objectID": "index.html#acknowledgments",
    "href": "index.html#acknowledgments",
    "title": "About",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nThe development of these materials was supported by the University of Rochester and a National Science Foundation grant: CAREER: Logical Form Induction (BCS/IIS-2237175)."
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "About",
    "section": "License ",
    "text": "License \nIntroduction to Computational Linguistics by Aaron Steven White is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License. Based on a work at https://github.com/aaronstevenwhite/intro-to-cl."
  },
  {
    "objectID": "installation.html",
    "href": "installation.html",
    "title": "Installation",
    "section": "",
    "text": "The site itself is built using Quarto. The source files for this site are available on github at aaronstevenwhite/intro-to-cl. You can obtain the files by cloning this repo.\nAll further code on this page assumes that you are inside of this cloned repo."
  },
  {
    "objectID": "installation.html#installing-quarto-and-extensions",
    "href": "installation.html#installing-quarto-and-extensions",
    "title": "Installation",
    "section": "Installing Quarto and extensions",
    "text": "Installing Quarto and extensions\nTo build this site, you will need to install Quarto as well as its include-code-files and line-highlight extensions.\nquarto add quarto-ext/include-code-files\nquarto add shafayetShafee/line-highlight\nThese extensions are mainly used for including and highlighting parts of external files."
  },
  {
    "objectID": "installation.html#building-the-docker-container",
    "href": "installation.html#building-the-docker-container",
    "title": "Installation",
    "section": "Building the Docker container",
    "text": "Building the Docker container\nAll pages that have executed code blocks are generated from jupyter notebooks, which were run within a Docker container constructed using the Dockerfile contained in this repo.\nFROM jupyter/minimal-notebook:x86_64-python-3.11.6\n\n\n\nRUN conda install -c conda-forge pynini\nAssuming you have Docker installed, the image can be built using:\ndocker build --platform linux/amd64 -t intro-to-cl .\nA container based on this image can then be constructed using:\ndocker run -it --rm -p 8888:8888 -v \"${PWD}\":/home/jovyan/work intro-to-cl\nTo access jupyter, simply copy the link provided when running this command. It should look something like this (though your access tokens will differ):\nTo access the server, open this file in a browser:\n    file:///home/jovyan/.local/share/jupyter/runtime/jpserver-8-open.html\nOr copy and paste one of these URLs:\n    http://4738b6192fb0:8888/lab?token=8fc165776e7e99c98ec19883f750071a187e85a0a9253b81\n    http://127.0.0.1:8888/lab?token=8fc165776e7e99c98ec19883f750071a187e85a0a9253b81\nYou can change the port that docker forwards to by changing the first 8888 in the -p 8888:8888 option–e.g. to redirect port 10000 -p 10000:8888. Just remember to correspondingly change the port you attempt to access in your browser: so even though the message above has you accessing port 8888, that’s the docker container’s port 8888, which forwards to your machine’s 10000."
  },
  {
    "objectID": "formal-and-practical-preliminaries/index.html",
    "href": "formal-and-practical-preliminaries/index.html",
    "title": "Overview",
    "section": "",
    "text": "In this first module of the course, we are going to focus on developing a set of formal and practical tools that we will use through the rest of the course."
  },
  {
    "objectID": "formal-and-practical-preliminaries/elementary-mathematical-concepts/index.html",
    "href": "formal-and-practical-preliminaries/elementary-mathematical-concepts/index.html",
    "title": "Overview",
    "section": "",
    "text": "Before getting to the fun parts of this course, we need to develop some basic formal tools. In this submodule, we’ll focus on some core concepts in naïve set theory and objects—such as relations and functions—constructed with these concepts. We’ll then use these concepts to develop a formal concept of strings on an alphabet and the set of all languages constructed from those strings.\nAs we develop these formal tools, we will also see how they are implemented in Python. I’m going to assume that you have some basic Python under your belt: that you can competently write scripts that do non-trivial things and can work competently with Python’s object-oriented programming facilities but maybe not develop a package on your own."
  },
  {
    "objectID": "formal-and-practical-preliminaries/elementary-mathematical-concepts/sets.html",
    "href": "formal-and-practical-preliminaries/elementary-mathematical-concepts/sets.html",
    "title": "Sets",
    "section": "",
    "text": "Sets are unordered, uniqued collections of things. One way to represent sets is by placing (representations of) their elements between curly braces.\nFor instance, we can represent the set of vowel phonemes in English in the following way.\n\\[V_1 \\equiv \\{\\text{e, i, o, u, æ, ɑ, ɔ, ə, ɛ, ɪ, ʊ}\\}\\]\nWe express that something is an element of a set using the notation \\(\\cdot \\in \\cdot\\) and that it is not an element using the notation \\(\\cdot \\not\\in \\cdot\\). So for instance, \\(\\text{e}\\) is an element of \\(V_1\\), while \\(\\text{t}\\) is not.\n\\[\\text{e} \\in V_1 \\quad \\text{t} \\not\\in V_1\\]\nTo work with sets in Python, we can use the standard library’s set type. These objects function as we would expect in terms of elementhood.\nvowels_1: set[str] = {\"e\", \"i\", \"o\", \"u\", \"æ\", \"ɑ\", \"ɔ\", \"ə\", \"ɛ\", \"ɪ\", \"ʊ\"}\n\nif \"e\" in vowels_1:\n    print(\"e ∈ V_1\")\nelse:\n    print(\"e ∉ V_1\")\n    \nif \"t\" in vowels_1:\n    print(\"t ∈ V_3\")\nelse:\n    print(\"t ∉ V_3\")\n\ne ∈ V_1\nt ∉ V_3\nSets can be represented in many ways. For instance, we could also represent the set \\(V_1\\) in this way:\n\\[V_2 \\equiv \\{\\text{o, u, æ, ɑ, ɔ, ə, ɛ, ɪ, ʊ, e, i}\\}\\]\nBecause sets are unordered, both \\(V_1\\) and \\(V_2\\) are representations of the exact same set (\\(V_1 = V_2\\)). And because sets are uniqued, \\(V_3\\) is also a representation of the same set as \\(V_1\\) and \\(V_2\\)–i.e. \\(V_1=V_2=V_3\\)–even though there are multiple copies of some vowels in this representation.\n\\[V_3 \\equiv \\{\\text{o, o, o, u, u, æ, ɑ, ɔ, ə, ə, ə, ɛ, ɪ, ʊ, e, i}\\}\\]\nPython sets work as we would expect in terms of equality.\nvowels_2: set[str] = {\"o\", \"u\", \"æ\", \"ɑ\", \"ɔ\", \"ə\", \"ɛ\", \"ɪ\", \"ʊ\", \"e\", \"i\"}\nvowels_3: set[str] = {\"o\", \"o\", \"o\", \"u\", \"u\", \"æ\", \"ɑ\", \"ɔ\", \"ə\", \"ə\", \"ə\", \"ɛ\", \"ɪ\", \"ʊ\", \"e\", \"i\"}\n\nif vowels_1 == vowels_2:\n    print(\"V_1 = V_2\")\nelse:\n    print(\"V_1 ≠ V_2\")\n    \nif vowels_1 == vowels_3:\n    print(\"V_1 = V_3\")\nelse:\n    print(\"V_1 ≠ V_3\")\n\nV_1 = V_2\nV_1 = V_3\nI’ll just call this set \\(V \\equiv V_1 = V_2 = V_3\\) moving forward.\nvowels: set[str] = vowels_1\nPython has another way of representing sets that we will have reason to use: frozenset. These work very similarly to sets in a lot of ways.\nvowels_frozen: frozenset[str] = frozenset(vowels)\n\nif vowels == vowels_frozen:\n    print(\"V = V_frozen\")\nelse:\n    print(\"V ≠ V_frozen\")\n\nV = V_frozen\nOne big difference between the two is that sets are mutable, while frozensets are immutable. Basically, we can alter sets, but we can’t alter frozensets. For instance, we can add elements to a set but not a frozenset.\ntry:\n    vowels.add(\"t\")\n    print(\"Successfully added 't' to vowels.\")\nexcept AttributeError:\n    print(\"Failed to add 't' to vowels.\")\n\ntry:\n    vowels_frozen.add(\"t\")\n    print(\"Successfully added 't' to vowels_frozen.\")\nexcept AttributeError:\n    print(\"Failed to add 't' to vowels_frozen.\")\n\nSuccessfully added 't' to vowels.\nFailed to add 't' to vowels_frozen.\nSimilarly, we can remove elements from sets but not frozensets.\ntry:\n    vowels.remove(\"t\")\n    print(\"Successfully removed 't' to vowels.\")\nexcept AttributeError:\n    print(\"Failed to remove 't' to vowels.\")\n\ntry:\n    vowels_frozen.remove(\"ə\")\n    print(\"Successfully removed 'ə' to vowels_frozen.\")\nexcept AttributeError:\n    print(\"Failed to remove 'ə' to vowels_frozen.\")\n\nSuccessfully removed 't' to vowels.\nFailed to remove 'ə' to vowels_frozen.\nThis behavior makes frozensets seem pretty useless, since it would seem they can do fewer things with them. But frozensets turn out to have a really useful property: they can be elements of other sets or frozensets.\ntry:\n    vowels_singleton: set[set[str]] = {vowels}\n    print(\"Successfully constructed the set {V}.\")\nexcept TypeError:\n    print(\"Failed to construct the set {V}.\")\n\ntry:\n    vowels_frozen_singleton: set[frozenset[str]] = {vowels_frozen}\n    print(\"Successfully constructed the set {V_frozen}.\")\nexcept TypeError:\n    print(\"Failed to construct the set {V_frozen}.\")\n\nFailed to construct the set {V}.\nSuccessfully constructed the set {V_frozen}.\nThe reason frozensets can be elements of sets or frozensets is that they are hashable, while sets are not.1 We are going to use this property extensively throughout this course."
  },
  {
    "objectID": "formal-and-practical-preliminaries/elementary-mathematical-concepts/multisets.html",
    "href": "formal-and-practical-preliminaries/elementary-mathematical-concepts/multisets.html",
    "title": "Multisets",
    "section": "",
    "text": "Multisets (or bags) are unordered, nonuniqued collections. In this course, we won’t spend too much time with these sorts of objects, but it’s useful to know the terminology.\nMultisets are often (somewhat confusingly) represented using the same notation as sets. For instance, the following is a multiset containing only vowels.\n\\[\\bar{V}_1 \\equiv \\{\\text{e, i, o, u, æ, ɑ, ɔ, ə, ɛ, ɪ, ʊ}\\}\\]\nAnd this is a representation of the same multiset, since multisets are unordered.\n\\[\\bar{V}_2 \\equiv \\{\\text{o, u, æ, ɑ, ɔ, ə, ɛ, ɪ, ʊ, e, i}\\}\\]\nBut this is not a representation of a multiset, since multisets are nonuniqued.\n\\[\\bar{V}_3 \\equiv \\{\\text{o, o, o, u, u, æ, ɑ, ɔ, ə, ə, ə, ɛ, ɪ, ʊ, e, i}\\}\\]\nAnother way of saying this is that the multiplicity of a particular element matters in a multiset in a way it doesn’t matter in a set.\nWe often work with multisets in Python using dicts or specialized subclasses thereof. One special subclass of dict that is useful for representing multisets (and that you should know) is collections.Counter.\nThe nice thing about Counter is that it can be initialized with an iterable or mapping (such as a set) containing hashable objects (such as strs) and it will make a dictionary mapping the elements of that iterable/mapping to their multiplicity–i.e. how many times they show up in that iterable/mapping.1\nfrom pprint import pprint\nfrom collections import Counter\n\nvowels_bar_1: Counter[str] = Counter(\n    [\"e\", \"i\", \"o\", \"u\", \"æ\", \"ɑ\", \"ɔ\", \"ə\", \"ɛ\", \"ɪ\", \"ʊ\"]\n)\n\npprint(vowels_bar_1)\n\nCounter({'e': 1,\n         'i': 1,\n         'o': 1,\n         'u': 1,\n         'æ': 1,\n         'ɑ': 1,\n         'ɔ': 1,\n         'ə': 1,\n         'ɛ': 1,\n         'ɪ': 1,\n         'ʊ': 1})\nvowels_bar_2: Counter[str] = Counter(\n    [\"o\", \"u\", \"æ\", \"ɑ\", \"ɔ\", \"ə\", \"ɛ\", \"ɪ\", \"ʊ\", \"e\", \"i\"]\n)\n\npprint(vowels_bar_2)\n\nCounter({'o': 1,\n         'u': 1,\n         'æ': 1,\n         'ɑ': 1,\n         'ɔ': 1,\n         'ə': 1,\n         'ɛ': 1,\n         'ɪ': 1,\n         'ʊ': 1,\n         'e': 1,\n         'i': 1})\nvowels_bar_3: Counter[str] = Counter(\n    [\"o\", \"o\", \"o\", \"u\", \"u\", \"æ\", \"ɑ\", \"ɔ\", \"ə\", \"ə\", \"ə\", \"ɛ\", \"ɪ\", \"ʊ\", \"e\", \"i\"]\n)\n\npprint(vowels_bar_3)\n\nCounter({'o': 3,\n         'ə': 3,\n         'u': 2,\n         'æ': 1,\n         'ɑ': 1,\n         'ɔ': 1,\n         'ɛ': 1,\n         'ɪ': 1,\n         'ʊ': 1,\n         'e': 1,\n         'i': 1})\nAnd Counters behave as we would expect of a multiset–at least in terms of equality.\nif vowels_bar_1 == vowels_bar_2:\n    print(\"Vbar_1 = Vbar_2\")\nelse:\n    print(\"Vbar_1 ≠ Vbar_2\")\n    \nif vowels_bar_1 == vowels_bar_3:\n    print(\"Vbar_1 = Vbar_3\")\nelse:\n    print(\"Vbar_1 ≠ Vbar_3\")\n\nVbar_1 = Vbar_2\nVbar_1 ≠ Vbar_3"
  },
  {
    "objectID": "formal-and-practical-preliminaries/elementary-mathematical-concepts/cardinality.html",
    "href": "formal-and-practical-preliminaries/elementary-mathematical-concepts/cardinality.html",
    "title": "Cardinality",
    "section": "",
    "text": "The number of things in a set is its cardinality.\n\\[|V| = |\\{\\text{e, i, o, u, æ, ɑ, ɔ, ə, ɛ, ɪ, ʊ}\\}| = 11\\]\nIn Python, we compute the cardinality using len.\n\nvowels: set[str] = {\"e\", \"i\", \"o\", \"u\", \"æ\", \"ɑ\", \"ɔ\", \"ə\", \"ɛ\", \"ɪ\", \"ʊ\"}\n\nprint(f\"|V| = {len(vowels)}\")\n\n|V| = 11\n\n\nSets can have infinite cardinality. For instance, the set of natural numbers is infinite.\n\\[\\mathbb{N} = \\{0, 1, 2, 3, \\ldots\\}\\text{ (or }\\{1, 2, 3, \\ldots\\})\\]\nWe unfortunately can’t use set to work with infinite sets in Python. Instead, we have to use generators. One way to initialize a generator is to define a function containing a yield statement.\n\nfrom collections.abc import Generator\n\ndef natural_numbers() -&gt; int:\n    \"\"\"Initialize a generator for the natural numbers\"\"\"\n    i = 0\n    while True:\n        yield i\n        i += 1\n\n# initialize a generator of the natural numbers\nN: Generator[int] = natural_numbers()\n\n# print the first 10 natural numbers\nfor i in N:\n  if i &lt; 10:\n    print(i)\n  else:\n    break\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9"
  },
  {
    "objectID": "formal-and-practical-preliminaries/elementary-mathematical-concepts/set-relations.html",
    "href": "formal-and-practical-preliminaries/elementary-mathematical-concepts/set-relations.html",
    "title": "Set relations",
    "section": "",
    "text": "Subcollections of elements of a set are subsets (of that set)\n\\[\\{\\text{i, u, ɪ, ʊ}\\} \\subseteq \\{\\text{e, i, o, u, æ, ɑ, ɔ, ə, ɛ, ɪ, ʊ}\\}\\]\n\nvowels: set[str] = {\"e\", \"i\", \"o\", \"u\", \"æ\", \"ɑ\", \"ɔ\", \"ə\", \"ɛ\", \"ɪ\", \"ʊ\"}\nhigh_vowels: set[str] = {'u', 'ʊ', 'i', 'ɪ'}\n\nif high_vowels &lt;= vowels:\n    print(f\"{high_vowels} ⊆ {vowels}\")\nelse:\n    print(f\"{high_vowels} ⊄ {vowels} ∨ {high_vowels} ≠ {vowels}\")\n\n{'u', 'i', 'ɪ', 'ʊ'} ⊆ {'i', 'ɛ', 'æ', 'ɪ', 'ə', 'ʊ', 'u', 'ɑ', 'ɔ', 'o', 'e'}\n\n\nA set is an improper subset of itself\n\\[\\{\\text{e, i, o, u, æ, ɑ, ɔ, ə, ɛ, ɪ, ʊ}\\} \\subseteq \\{\\text{e, i, o, u, æ, ɑ, ɔ, ə, ɛ, ɪ, ʊ}\\}\\]\n\nif vowels &lt;= vowels:\n    print(f\"{vowels} ⊆ {vowels}\")\nelse:\n    print(f\"{vowels} ⊄ {vowels} ∨ {vowels} ≠ {vowels}\")\n\n{'i', 'ɛ', 'æ', 'ɪ', 'ə', 'ʊ', 'u', 'ɑ', 'ɔ', 'o', 'e'} ⊆ {'i', 'ɛ', 'æ', 'ɪ', 'ə', 'ʊ', 'u', 'ɑ', 'ɔ', 'o', 'e'}\n\n\nAll other sets of a subset are proper subsets.\n\\[\\{\\text{i}\\} \\subset \\{\\text{e, i, o, u, æ, ɑ, ɔ, ə, ɛ, ɪ, ʊ}\\}\\]\n\nif {'i'} &lt; vowels:\n    print(f\"{{'i'}} ⊂ {vowels}\")\nelse:\n    print(f\"{{'i'}} ⊄ {vowels}\")\n\nif vowels &lt; vowels:\n    print(f\"{vowels} ⊂ {vowels}\")\nelse:\n    print(f\"{vowels} ⊄ {vowels}\")\n\n{'i'} ⊂ {'i', 'ɛ', 'æ', 'ɪ', 'ə', 'ʊ', 'u', 'ɑ', 'ɔ', 'o', 'e'}\n{'i', 'ɛ', 'æ', 'ɪ', 'ə', 'ʊ', 'u', 'ɑ', 'ɔ', 'o', 'e'} ⊄ {'i', 'ɛ', 'æ', 'ɪ', 'ə', 'ʊ', 'u', 'ɑ', 'ɔ', 'o', 'e'}"
  },
  {
    "objectID": "formal-and-practical-preliminaries/elementary-mathematical-concepts/set-relations.html#subsets",
    "href": "formal-and-practical-preliminaries/elementary-mathematical-concepts/set-relations.html#subsets",
    "title": "Set relations",
    "section": "",
    "text": "Subcollections of elements of a set are subsets (of that set)\n\\[\\{\\text{i, u, ɪ, ʊ}\\} \\subseteq \\{\\text{e, i, o, u, æ, ɑ, ɔ, ə, ɛ, ɪ, ʊ}\\}\\]\n\nvowels: set[str] = {\"e\", \"i\", \"o\", \"u\", \"æ\", \"ɑ\", \"ɔ\", \"ə\", \"ɛ\", \"ɪ\", \"ʊ\"}\nhigh_vowels: set[str] = {'u', 'ʊ', 'i', 'ɪ'}\n\nif high_vowels &lt;= vowels:\n    print(f\"{high_vowels} ⊆ {vowels}\")\nelse:\n    print(f\"{high_vowels} ⊄ {vowels} ∨ {high_vowels} ≠ {vowels}\")\n\n{'u', 'i', 'ɪ', 'ʊ'} ⊆ {'i', 'ɛ', 'æ', 'ɪ', 'ə', 'ʊ', 'u', 'ɑ', 'ɔ', 'o', 'e'}\n\n\nA set is an improper subset of itself\n\\[\\{\\text{e, i, o, u, æ, ɑ, ɔ, ə, ɛ, ɪ, ʊ}\\} \\subseteq \\{\\text{e, i, o, u, æ, ɑ, ɔ, ə, ɛ, ɪ, ʊ}\\}\\]\n\nif vowels &lt;= vowels:\n    print(f\"{vowels} ⊆ {vowels}\")\nelse:\n    print(f\"{vowels} ⊄ {vowels} ∨ {vowels} ≠ {vowels}\")\n\n{'i', 'ɛ', 'æ', 'ɪ', 'ə', 'ʊ', 'u', 'ɑ', 'ɔ', 'o', 'e'} ⊆ {'i', 'ɛ', 'æ', 'ɪ', 'ə', 'ʊ', 'u', 'ɑ', 'ɔ', 'o', 'e'}\n\n\nAll other sets of a subset are proper subsets.\n\\[\\{\\text{i}\\} \\subset \\{\\text{e, i, o, u, æ, ɑ, ɔ, ə, ɛ, ɪ, ʊ}\\}\\]\n\nif {'i'} &lt; vowels:\n    print(f\"{{'i'}} ⊂ {vowels}\")\nelse:\n    print(f\"{{'i'}} ⊄ {vowels}\")\n\nif vowels &lt; vowels:\n    print(f\"{vowels} ⊂ {vowels}\")\nelse:\n    print(f\"{vowels} ⊄ {vowels}\")\n\n{'i'} ⊂ {'i', 'ɛ', 'æ', 'ɪ', 'ə', 'ʊ', 'u', 'ɑ', 'ɔ', 'o', 'e'}\n{'i', 'ɛ', 'æ', 'ɪ', 'ə', 'ʊ', 'u', 'ɑ', 'ɔ', 'o', 'e'} ⊄ {'i', 'ɛ', 'æ', 'ɪ', 'ə', 'ʊ', 'u', 'ɑ', 'ɔ', 'o', 'e'}"
  },
  {
    "objectID": "formal-and-practical-preliminaries/elementary-mathematical-concepts/set-relations.html#empty-set",
    "href": "formal-and-practical-preliminaries/elementary-mathematical-concepts/set-relations.html#empty-set",
    "title": "Set relations",
    "section": "Empty set",
    "text": "Empty set\nThe empty set \\(\\emptyset\\) is a set containing no elements.\n\\[\\emptyset \\equiv \\{\\}\\]\n\nemptyset: set = set()\n\nThe empty set is a subset of all sets.\n\\[\\emptyset \\subset \\{\\text{e, i, o, u, æ, ɑ, ɔ, ə, ɛ, ɪ, ʊ}\\}\\]\n\n\nif emptyset &lt; vowels:\n    print(f\"∅ ⊂ {vowels}\")\nelse:\n    print(f\"∅ ⊄ {vowels}\")\n\n∅ ⊂ {'i', 'ɛ', 'æ', 'ɪ', 'ə', 'ʊ', 'u', 'ɑ', 'ɔ', 'o', 'e'}\n\n\nThe empty set is not in all sets, though it is in some sets\n\\[\\emptyset \\not\\in \\{\\text{e, i, o, u, æ, ɑ, ɔ, ə, ɛ, ɪ, ʊ}\\}\\] \\[\\emptyset \\in \\{\\emptyset, \\text{e, i, o, u, æ, ɑ, ɔ, ə, ɛ, ɪ, ʊ}\\}\\]\n\nvowels_with_empty: set[str] = set(vowels)\nvowels_with_empty.add(frozenset(emptyset))\n\nif emptyset in vowels:\n    print(f\"∅ ∈ {vowels}\")\nelse:\n    print(f\"∅ ∉ {vowels}\")\n    \nif emptyset in vowels_with_empty:\n    print(f\"∅ ∈ {vowels_with_empty}\")\nelse:\n    print(f\"∅ ∉ {vowels_with_empty}\")\n\n∅ ∉ {'i', 'ɛ', 'æ', 'ɪ', 'ə', 'ʊ', 'u', 'ɑ', 'ɔ', 'o', 'e'}\n∅ ∈ {'i', 'ɛ', 'æ', 'ɪ', 'ə', 'ʊ', 'u', frozenset(), 'ɑ', 'ɔ', 'o', 'e'}"
  },
  {
    "objectID": "formal-and-practical-preliminaries/elementary-mathematical-concepts/set-relations.html#intersection",
    "href": "formal-and-practical-preliminaries/elementary-mathematical-concepts/set-relations.html#intersection",
    "title": "Set relations",
    "section": "Intersection",
    "text": "Intersection\nThe intersection of two sets is the set of their shared elements. For instance, if we take the intersection of the set of high vowels with the set of back vowels, we get the high back vowels.\n\\[\\{\\text{i, u, ɪ, ʊ}\\} \\cap \\{\\text{u, ʊ, o, ɔ, ɑ}\\} = \\{\\text{u, ʊ}\\}\\]\n\nback_vowels: set[str] = {'u', 'ʊ', 'ɑ', 'ɔ', 'o'}\n\nprint(f\"{high_vowels} ∩ {back_vowels} = {high_vowels & back_vowels}\")\n\n{'u', 'i', 'ɪ', 'ʊ'} ∩ {'u', 'ɑ', 'ɔ', 'o', 'ʊ'} = {'u', 'ʊ'}\n\n\nThe intersection of a set with a subset of that set is that subset.\n\\[\\{\\text{i, u, ɪ, ʊ}\\} \\cap \\{\\text{u, ʊ}\\} = \\{\\text{u, ʊ}\\}\\] \\[\\{\\text{i, u, ɪ, ʊ}\\} \\cap \\emptyset = \\emptyset\\]\n\nhigh_back_vowels: set[str] = {'u', 'ʊ'}\n\nprint(f\"{high_vowels} ∩ {high_back_vowels} = {high_vowels & high_back_vowels}\") \n\n{'u', 'i', 'ɪ', 'ʊ'} ∩ {'u', 'ʊ'} = {'u', 'ʊ'}\n\n\nIntersection can yield the empty set.\n\\[\\{\\text{i, u, ɪ, ʊ}\\} \\cap \\{\\text{o, ɔ}\\} = \\emptyset\\]\n\nmid_back_vowels: set[str] = {'o', 'ɔ'}\n\nprint(f\"{high_vowels} ∩ {mid_back_vowels} = {high_vowels & mid_back_vowels}\") \n\n{'u', 'i', 'ɪ', 'ʊ'} ∩ {'ɔ', 'o'} = set()"
  },
  {
    "objectID": "formal-and-practical-preliminaries/elementary-mathematical-concepts/set-relations.html#union",
    "href": "formal-and-practical-preliminaries/elementary-mathematical-concepts/set-relations.html#union",
    "title": "Set relations",
    "section": "Union",
    "text": "Union\nThe union of two sets is the set of elements in both. For instance, if we take the union of the set of high vowels with the set of back vowels, we get the set of high and/or back vowels.\n\\[\\{\\text{i, u, ɪ, ʊ}\\} \\cup \\{\\text{u, ʊ, o, ɔ, ɑ}\\} = \\{\\text{i, ɪ, u, ʊ, o, ɔ, ɑ}\\}\\]\n\nprint(f\"{high_vowels} ∪ {back_vowels} = {high_vowels | back_vowels}\")\n\n{'u', 'i', 'ɪ', 'ʊ'} ∪ {'u', 'ɑ', 'ɔ', 'o', 'ʊ'} = {'i', 'ɪ', 'ʊ', 'u', 'ɑ', 'ɔ', 'o'}\n\n\nThe union of a set with itself or one of its subsets (including the empty set) is that set.\n\\[\\{\\text{i, u, ɪ, ʊ}\\} \\cup \\{\\text{i, u, ɪ, ʊ}\\} = \\{\\text{i, u, ɪ, ʊ}\\}\\] \\[\\{\\text{i, u, ɪ, ʊ}\\} \\cup \\{\\text{u, ʊ}\\} = \\{\\text{i, u, ɪ, ʊ}\\}\\]\n\nprint(f\"{high_vowels} ∪ {high_back_vowels} = {high_vowels | high_back_vowels}\")\n\n{'u', 'i', 'ɪ', 'ʊ'} ∪ {'u', 'ʊ'} = {'u', 'i', 'ɪ', 'ʊ'}\n\n\nThe + operator does not work for sets like it does for lists! You need to use | or union() explicitly.\n\ntry:\n    high_vowels + high_back_vowels\nexcept TypeError:\n    print(\"+ for sets does not implement union!\")\n\n+ for sets does not implement union!"
  },
  {
    "objectID": "formal-and-practical-preliminaries/elementary-mathematical-concepts/set-relations.html#set-builder-notation",
    "href": "formal-and-practical-preliminaries/elementary-mathematical-concepts/set-relations.html#set-builder-notation",
    "title": "Set relations",
    "section": "Set builder notation",
    "text": "Set builder notation\nIt is commonly the case that we want to filter a larger set–e.g. the vowels–down to a set containing only elements of that set with particular properties. For instance, suppose we want the high front vowels and we know how to check whether a vowel is high and whether it is front. We could describe the high front vowels using set-builder notation.\n\\[\\{x \\in \\text{vowels} \\mid x \\text{ is high and } x \\text{ is front}\\}\\]\nSet-builder notation can be implemented using set comprehensions.\n\nvowels: set[str] = {\"e\", \"i\", \"o\", \"u\", \"æ\", \"ɑ\", \"ɔ\", \"ə\", \"ɛ\", \"ɪ\", \"ʊ\"}\n\ndef is_high(x: str) -&gt; bool:\n  return x in {\"i\", \"u\", \"ɪ\", \"ʊ\"}\n\ndef is_front(x: str) -&gt; bool:\n  return x in {\"i\", \"ɪ\", \"e\", \"æ\", \"ɛ\"}\n\n{v for v in vowels if is_high(v) and is_front(v)}\n\n{'i', 'ɪ'}\n\n\nNote that:\n\\[\\{x \\in \\text{vowels} \\mid x \\text{ is high and } x \\text{ is front}\\} = \\{x \\in \\text{vowels} \\mid x \\text{ is high}\\} \\cap \\{x \\in \\text{vowels} \\mid x \\text{ is front}\\}\\]\n\n{v for v in vowels if is_high(v)} & {v for v in vowels if is_front(v)}\n\n{'i', 'ɪ'}\n\n\nThis fact will be important for your first homework."
  },
  {
    "objectID": "formal-and-practical-preliminaries/elementary-mathematical-concepts/set-relations.html#complement",
    "href": "formal-and-practical-preliminaries/elementary-mathematical-concepts/set-relations.html#complement",
    "title": "Set relations",
    "section": "Complement",
    "text": "Complement\nThe (absolute) complement of a set \\(A\\) relative to a universe \\(U\\) (a possibly improper superset of \\(A\\)) is all elements in \\(U\\) that are not in \\(A\\).\n\\[A^\\complement = \\overline{A} = A' = \\{x\\;|\\;x \\in U \\land x \\not\\in A\\}\\]\nFor instance, if \\(U \\equiv \\{\\text{e, i, o, u, æ, ɑ, ɔ, ə, ɛ, ɪ, ʊ}\\}\\), then the complement of the high vowels is the non-high vowels.\n\\[\\{\\text{i, u, ɪ, ʊ}\\}^\\complement = \\{\\text{e, o, æ, ɑ, ɔ, ə, ɛ}\\}\\]\nNote that \\(U = A \\cup \\overline{A}\\)."
  },
  {
    "objectID": "formal-and-practical-preliminaries/elementary-mathematical-concepts/set-relations.html#set-difference",
    "href": "formal-and-practical-preliminaries/elementary-mathematical-concepts/set-relations.html#set-difference",
    "title": "Set relations",
    "section": "Set difference",
    "text": "Set difference\nThe set difference (or relative complement) of a set \\(A\\) relative to another set \\(B\\) is all elements in \\(B\\) that are not in \\(A\\)\n\\[B - A = \\{x\\;|\\;x \\in B \\land x \\not\\in A\\}\\]\nFor instance, the difference of the set of high vowels relative to the set of high back vowels, is the high non-back vowels.\n\\[\\{\\text{i, u, ɪ, ʊ}\\} - \\{\\text{u, ʊ}\\} = \\{\\text{i, ɪ}\\}\\]\n\nprint(f\"{high_vowels} - {high_back_vowels} = {high_vowels - high_back_vowels}\")\n\n{'u', 'i', 'ɪ', 'ʊ'} - {'u', 'ʊ'} = {'i', 'ɪ'}"
  },
  {
    "objectID": "formal-and-practical-preliminaries/elementary-mathematical-concepts/power-sets.html",
    "href": "formal-and-practical-preliminaries/elementary-mathematical-concepts/power-sets.html",
    "title": "Power Sets",
    "section": "",
    "text": "The set of all subsets of a set is its power set.\n\\[\\mathcal{P}(A) = 2^A = \\{X \\mid X \\subseteq A\\}\\]\nFor example, for the set \\(\\{\\text{i}, \\text{u}, \\text{ə}\\}\\), we have:\n\\[\\mathcal{P}(\\{\\text{i},\\text{u},\\text{ə}\\}) = 2^{\\{\\text{i},\\text{u},\\text{ə}\\}} = \\{\\emptyset, \\{\\text{i}\\}, \\{\\text{u}\\}, \\{\\text{ə}\\}, \\{\\text{i}, \\text{u}\\}, \\{\\text{u},\\text{ə}\\}, \\{\\text{i},\\text{ə}\\}, \\{\\text{i}, \\text{u}, \\text{ə}\\}\\}\\]\nTo obtain the power set of some set, we can loop through all possible subset cardinalities, and use the itertools.combinations function to obtain all subsets of our set of interest (the high vowels) of a particular cardinality. To do this, we need a second loop over the output of itertools.combinations at each cardinality is necessary to flatten the sets.\n\nfrom itertools import combinations\n\nhigh_vowels: set[str] = {'u', 'ʊ', 'i', 'ɪ'}\n\npowerset_of_high_vowels = {subset \n                           for cardinality in range(len(high_vowels)+1) \n                           for subset in combinations(high_vowels, cardinality)}\n\npowerset_of_high_vowels\n\n{(),\n ('i',),\n ('i', 'ɪ'),\n ('i', 'ɪ', 'ʊ'),\n ('i', 'ʊ'),\n ('u',),\n ('u', 'i'),\n ('u', 'i', 'ɪ'),\n ('u', 'i', 'ɪ', 'ʊ'),\n ('u', 'i', 'ʊ'),\n ('u', 'ɪ'),\n ('u', 'ɪ', 'ʊ'),\n ('u', 'ʊ'),\n ('ɪ',),\n ('ɪ', 'ʊ'),\n ('ʊ',)}\n\n\nOne slightly weird thing about this output is that the set we get has tuples as elements. For most purposes, this result is fine, but sometimes we want the elements to themselves be sets, so we can do set operations on them easily. The issue is that, as we’ve already seen, sets can’t be elements of sets in Python. This is a case where we need frozensets.\n\npowerset_of_high_vowels = {frozenset(subset) \n                           for cardinality in range(len(high_vowels)+1) \n                           for subset in combinations(high_vowels, cardinality)}\n\npowerset_of_high_vowels\n\n{frozenset(),\n frozenset({'u', 'ʊ'}),\n frozenset({'i', 'u', 'ʊ'}),\n frozenset({'u', 'ɪ'}),\n frozenset({'i', 'ɪ'}),\n frozenset({'ɪ', 'ʊ'}),\n frozenset({'i', 'ʊ'}),\n frozenset({'ɪ'}),\n frozenset({'i'}),\n frozenset({'ʊ'}),\n frozenset({'u'}),\n frozenset({'i', 'u'}),\n frozenset({'i', 'u', 'ɪ'}),\n frozenset({'u', 'ɪ', 'ʊ'}),\n frozenset({'i', 'ɪ', 'ʊ'}),\n frozenset({'i', 'u', 'ɪ', 'ʊ'})}\n\n\nSo if we wanted to be able to take the power set of anything we can represent in python as a set, we could wrap this comprehension in a function.\n\nfrom typing import Set\n\ndef powerset(x: set) -&gt; Set[frozenset]:\n  return {\n      frozenset(subset) \n      for cardinality in range(len(x)+1) \n      for subset in combinations(x, cardinality)\n  }\n\npowerset(high_vowels)\n\n{frozenset(),\n frozenset({'u', 'ʊ'}),\n frozenset({'i', 'u', 'ʊ'}),\n frozenset({'u', 'ɪ'}),\n frozenset({'i', 'ɪ'}),\n frozenset({'ɪ', 'ʊ'}),\n frozenset({'i', 'ʊ'}),\n frozenset({'ɪ'}),\n frozenset({'i'}),\n frozenset({'ʊ'}),\n frozenset({'u'}),\n frozenset({'i', 'u'}),\n frozenset({'i', 'u', 'ɪ'}),\n frozenset({'u', 'ɪ', 'ʊ'}),\n frozenset({'i', 'ɪ', 'ʊ'}),\n frozenset({'i', 'u', 'ɪ', 'ʊ'})}\n\n\nAlternatively, we can use the following itertools recipe. The main difference here is that we don’t have the explicit for loop over subsets of a particular cardinality, which we needed for the purposes of flattening sets. That’s what itertools.chain.from_iterable does for us. This returns an itertools.chain object, which you can treat as a generator.\n\nfrom typing import Iterable\nfrom itertools import chain\n\ndef powerset(iterable: Iterable) -&gt; chain:\n    s = list(iterable)\n    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n\npowerset(high_vowels)\n\n&lt;itertools.chain at 0x106193070&gt;\n\n\nTo get a set of frozensets, we need to some explicit type casting (so we don’t really avoid the second for loop…).\n\n{frozenset(subset) for subset in powerset(high_vowels)}\n\n{frozenset(),\n frozenset({'u', 'ʊ'}),\n frozenset({'i', 'u', 'ʊ'}),\n frozenset({'u', 'ɪ'}),\n frozenset({'i', 'ɪ'}),\n frozenset({'ɪ', 'ʊ'}),\n frozenset({'i', 'ʊ'}),\n frozenset({'ɪ'}),\n frozenset({'i'}),\n frozenset({'ʊ'}),\n frozenset({'u'}),\n frozenset({'i', 'u'}),\n frozenset({'i', 'u', 'ɪ'}),\n frozenset({'u', 'ɪ', 'ʊ'}),\n frozenset({'i', 'ɪ', 'ʊ'}),\n frozenset({'i', 'u', 'ɪ', 'ʊ'})}\n\n\nNote that the thing we’re taking the power set of needs to be of finite size in both implementations–i.e. it can’t be a generator that runs forever. To see this, let’s create a generator for the natural numbers using yield statements. If we create a generator by calling natural_numbers with no arguments, it would run forever. (Below I break it after 10 iterations.)\nAnd if I pass this generator (an iterable) to powerset, it will hang.\n\nfrom collections.abc import Generator\nfrom multiprocessing import Process\n\ndef natural_numbers() -&gt; int:\n    \"\"\"Initialize a generator for the natural numbers\"\"\"\n    i = 0\n    while True:\n        yield i\n        i += 1\n\n# initialize a generator of the natural numbers\nN: Generator[int] = natural_numbers()\n\n# this will hang\n# powerset(N)\n\nIf we want to be able to generate elements of the power set of an infinite set, we will have to do it in a slightly smarter way.\n\nfrom typing import TypeVar, Set, Iterable\n\nT = TypeVar(\"T\")\n\nemptyset = frozenset()\n\ndef powerset(iterable: Iterable[T]) -&gt; Set[T]:\n    yield emptyset\n\n    seen = {emptyset}\n\n    for r in iterable:\n        new = {s | frozenset({r}) for s in seen}\n        for n in new:\n            yield n\n            seen.add(n)\n\nThis will still get us the correct result for finite sets.\n\n{s for s in powerset(high_vowels)}\n\n{frozenset(),\n frozenset({'u', 'ʊ'}),\n frozenset({'i', 'u', 'ʊ'}),\n frozenset({'u', 'ɪ'}),\n frozenset({'i', 'ɪ'}),\n frozenset({'ɪ', 'ʊ'}),\n frozenset({'i', 'ʊ'}),\n frozenset({'ɪ'}),\n frozenset({'i'}),\n frozenset({'ʊ'}),\n frozenset({'u'}),\n frozenset({'i', 'u'}),\n frozenset({'i', 'u', 'ɪ'}),\n frozenset({'u', 'ɪ', 'ʊ'}),\n frozenset({'i', 'ɪ', 'ʊ'}),\n frozenset({'i', 'u', 'ɪ', 'ʊ'})}\n\n\nAnd it will also work for infinite sets.\n\nN = natural_numbers()\n\nfor i, s in enumerate(powerset(N)):\n  if i &lt; 100:\n    print(s)\n  else:\n    break\n\nfrozenset()\nfrozenset({0})\nfrozenset({0, 1})\nfrozenset({1})\nfrozenset({2})\nfrozenset({1, 2})\nfrozenset({0, 2})\nfrozenset({0, 1, 2})\nfrozenset({2, 3})\nfrozenset({0, 2, 3})\nfrozenset({0, 3})\nfrozenset({3})\nfrozenset({0, 1, 2, 3})\nfrozenset({1, 3})\nfrozenset({1, 2, 3})\nfrozenset({0, 1, 3})\nfrozenset({0, 3, 4})\nfrozenset({3, 4})\nfrozenset({0, 1, 4})\nfrozenset({2, 3, 4})\nfrozenset({1, 4})\nfrozenset({1, 2, 4})\nfrozenset({0, 1, 2, 3, 4})\nfrozenset({0, 2, 3, 4})\nfrozenset({0, 4})\nfrozenset({2, 4})\nfrozenset({0, 2, 4})\nfrozenset({1, 2, 3, 4})\nfrozenset({0, 1, 3, 4})\nfrozenset({0, 1, 2, 4})\nfrozenset({1, 3, 4})\nfrozenset({4})\nfrozenset({1, 3, 5})\nfrozenset({4, 5})\nfrozenset({0, 2, 5})\nfrozenset({0, 5})\nfrozenset({0, 3, 4, 5})\nfrozenset({0, 1, 3, 4, 5})\nfrozenset({0, 3, 5})\nfrozenset({0, 4, 5})\nfrozenset({0, 2, 3, 4, 5})\nfrozenset({0, 2, 3, 5})\nfrozenset({1, 2, 3, 4, 5})\nfrozenset({2, 3, 5})\nfrozenset({3, 5})\nfrozenset({3, 4, 5})\nfrozenset({1, 2, 4, 5})\nfrozenset({0, 1, 2, 4, 5})\nfrozenset({0, 1, 4, 5})\nfrozenset({0, 2, 4, 5})\nfrozenset({0, 1, 3, 5})\nfrozenset({2, 3, 4, 5})\nfrozenset({1, 2, 5})\nfrozenset({1, 5})\nfrozenset({1, 4, 5})\nfrozenset({5})\nfrozenset({0, 1, 2, 5})\nfrozenset({1, 3, 4, 5})\nfrozenset({1, 2, 3, 5})\nfrozenset({0, 1, 2, 3, 4, 5})\nfrozenset({2, 4, 5})\nfrozenset({2, 5})\nfrozenset({0, 1, 5})\nfrozenset({0, 1, 2, 3, 5})\nfrozenset({1, 4, 5, 6})\nfrozenset({4, 6})\nfrozenset({2, 3, 5, 6})\nfrozenset({2, 6})\nfrozenset({0, 1, 2, 4, 5, 6})\nfrozenset({0, 2, 4, 6})\nfrozenset({0, 1, 4, 5, 6})\nfrozenset({0, 5, 6})\nfrozenset({0, 2, 3, 6})\nfrozenset({0, 1, 2, 5, 6})\nfrozenset({1, 2, 3, 4, 5, 6})\nfrozenset({0, 3, 4, 6})\nfrozenset({0, 1, 3, 4, 5, 6})\nfrozenset({2, 3, 4, 6})\nfrozenset({4, 5, 6})\nfrozenset({0, 2, 3, 4, 5, 6})\nfrozenset({1, 3, 4, 6})\nfrozenset({1, 2, 3, 4, 6})\nfrozenset({1, 4, 6})\nfrozenset({0, 1, 2, 3, 4, 6})\nfrozenset({2, 4, 6})\nfrozenset({3, 4, 5, 6})\nfrozenset({0, 4, 6})\nfrozenset({1, 3, 4, 5, 6})\nfrozenset({0, 6})\nfrozenset({0, 3, 5, 6})\nfrozenset({0, 2, 6})\nfrozenset({0, 1, 2, 4, 6})\nfrozenset({0, 2, 5, 6})\nfrozenset({0, 3, 6})\nfrozenset({0, 4, 5, 6})\nfrozenset({0, 2, 4, 5, 6})\nfrozenset({3, 4, 6})\nfrozenset({5, 6})\nfrozenset({1, 2, 4, 5, 6})\nfrozenset({2, 4, 5, 6})"
  },
  {
    "objectID": "formal-and-practical-preliminaries/elementary-mathematical-concepts/products.html",
    "href": "formal-and-practical-preliminaries/elementary-mathematical-concepts/products.html",
    "title": "Products",
    "section": "",
    "text": "The cartesian product of a set \\(A\\) with a set \\(B\\) is the set of all pairs of some element in \\(A\\) with some element in \\(B\\) (in that order).\n\\[A \\times B = \\{\\langle x, y \\rangle\\;|\\;x \\in A \\land y \\in B\\}\\]\nThe caridinality of a cartesian product of two sets is the product of their cardinalities.\n\\[|A \\times B| = |A| \\times |B|\\]\n\nfrom itertools import product\n\nx = {1, 2, 3}\ny = {\"d\", \"u\", \"r\"}\n\n# cartesian product using nested for loop\n# in set comprehension\nz = {(i, j) for i in x for j in y}\nset(product(x, y)) == z # evaluates to True\n\nTrue\n\n\nThe cartesian product can be iterated – notated using exponentiation notation\n\\[A^3 = A \\times (A \\times A)\\] \\[A^4 = A \\times (A \\times (A \\times A))\\]\nSince we know \\(|A \\times B|\\), we also know the cardinality of \\(|A^N| = |\\times_{i=1}^N A| = |A| \\times |A^{N-1}| = |A|^N\\).\n\nvowels: set[str] = {\"e\", \"i\", \"o\", \"u\", \"æ\", \"ɑ\", \"ɔ\", \"ə\", \"ɛ\", \"ɪ\", \"ʊ\"}\n\ndef exponentiate(a, n):\n    if n == 1:\n        return a\n    else:\n        return {(x, t) for t in exponentiate(a, n-1) for x in a}\n        \n    \nexponentiate(vowels, 5)\n\n{('u', ('æ', ('o', ('u', 'i')))),\n ('ɪ', ('ɑ', ('ɑ', ('ə', 'ɛ')))),\n ('ɪ', ('ʊ', ('u', ('o', 'ɛ')))),\n ('ʊ', ('æ', ('æ', ('i', 'ɔ')))),\n ('ə', ('ʊ', ('e', ('ɑ', 'æ')))),\n ('ɑ', ('o', ('ɪ', ('ɔ', 'u')))),\n ('ɔ', ('ɛ', ('æ', ('e', 'ɪ')))),\n ('æ', ('ə', ('ɑ', ('u', 'u')))),\n ('u', ('æ', ('ɪ', ('æ', 'ʊ')))),\n ('i', ('ʊ', ('ɔ', ('u', 'ʊ')))),\n ('ɔ', ('ʊ', ('ɔ', ('ə', 'u')))),\n ('e', ('ɑ', ('u', ('ɑ', 'o')))),\n ('ɪ', ('ɔ', ('e', ('i', 'æ')))),\n ('ɔ', ('æ', ('ɑ', ('ə', 'ɔ')))),\n ('ɪ', ('u', ('ə', ('o', 'i')))),\n ('o', ('ʊ', ('ə', ('æ', 'ə')))),\n ('u', ('æ', ('æ', ('ɪ', 'u')))),\n ('e', ('o', ('u', ('e', 'o')))),\n ('ɔ', ('æ', ('æ', ('ɔ', 'ɔ')))),\n ('ʊ', ('ə', ('ʊ', ('ʊ', 'æ')))),\n ('ɔ', ('ɔ', ('u', ('i', 'e')))),\n ('ɛ', ('ɪ', ('i', ('æ', 'ʊ')))),\n ('ə', ('ʊ', ('ɔ', ('ə', 'i')))),\n ('ɪ', ('u', ('o', ('ɛ', 'o')))),\n ('ɑ', ('o', ('ɛ', ('æ', 'ɪ')))),\n ('i', ('ɛ', ('ɪ', ('i', 'ɛ')))),\n ('ə', ('ɔ', ('u', ('ɔ', 'ə')))),\n ('ɪ', ('i', ('ɛ', ('ʊ', 'æ')))),\n ('o', ('u', ('ʊ', ('ʊ', 'ɛ')))),\n ('ɑ', ('i', ('o', ('ɑ', 'ʊ')))),\n ('i', ('ʊ', ('ɛ', ('o', 'o')))),\n ('ɑ', ('ə', ('æ', ('i', 'ɪ')))),\n ('e', ('ʊ', ('ə', ('ɛ', 'ɑ')))),\n ('ʊ', ('ə', ('ɔ', ('ɔ', 'i')))),\n ('e', ('e', ('ə', ('ɪ', 'u')))),\n ('o', ('ʊ', ('e', ('e', 'ɛ')))),\n ('ɛ', ('ʊ', ('ɑ', ('ɛ', 'ə')))),\n ('o', ('e', ('ʊ', ('ɔ', 'ə')))),\n ('ɔ', ('e', ('o', ('ɔ', 'æ')))),\n ('ʊ', ('ə', ('ɛ', ('æ', 'o')))),\n ('ɪ', ('i', ('ɛ', ('ɔ', 'u')))),\n ('i', ('u', ('i', ('æ', 'u')))),\n ('u', ('ʊ', ('ɑ', ('e', 'ɑ')))),\n ('æ', ('e', ('ʊ', ('ə', 'o')))),\n ('ɔ', ('o', ('o', ('o', 'ʊ')))),\n ('ɑ', ('u', ('ɑ', ('i', 'ɛ')))),\n ('o', ('ɪ', ('ə', ('e', 'ɑ')))),\n ('ʊ', ('ə', ('e', ('ɑ', 'o')))),\n ('æ', ('i', ('ɔ', ('ɔ', 'o')))),\n ('o', ('æ', ('o', ('ɑ', 'ɛ')))),\n ('ʊ', ('ɔ', ('u', ('ɑ', 'ɑ')))),\n ('æ', ('æ', ('ɪ', ('ʊ', 'ʊ')))),\n ('ə', ('o', ('ʊ', ('æ', 'ə')))),\n ('ɪ', ('u', ('æ', ('ɑ', 'i')))),\n ('u', ('o', ('ɔ', ('ɪ', 'ɑ')))),\n ('ɔ', ('ɪ', ('ɛ', ('ɛ', 'ə')))),\n ('ə', ('æ', ('ɛ', ('ɑ', 'ʊ')))),\n ('u', ('ɑ', ('ɑ', ('u', 'e')))),\n ('ɔ', ('ɔ', ('æ', ('i', 'ɛ')))),\n ('ə', ('i', ('ɛ', ('ʊ', 'u')))),\n ('ɛ', ('æ', ('ɑ', ('o', 'ə')))),\n ('æ', ('ɑ', ('e', ('ʊ', 'æ')))),\n ('i', ('ʊ', ('ə', ('e', 'ɪ')))),\n ('u', ('o', ('ɛ', ('ɔ', 'ə')))),\n ('ɛ', ('æ', ('æ', ('æ', 'æ')))),\n ('æ', ('o', ('e', ('æ', 'ɑ')))),\n ('u', ('ɑ', ('o', ('ʊ', 'ə')))),\n ('æ', ('ʊ', ('o', ('i', 'ɛ')))),\n ('e', ('e', ('i', ('ɑ', 'æ')))),\n ('ʊ', ('ʊ', ('ə', ('u', 'æ')))),\n ('ɑ', ('ɑ', ('i', ('ə', 'ɛ')))),\n ('ɪ', ('o', ('ʊ', ('ɪ', 'i')))),\n ('o', ('e', ('ʊ', ('ɪ', 'i')))),\n ('u', ('o', ('ɑ', ('ɔ', 'ɑ')))),\n ('ə', ('ɪ', ('i', ('ɑ', 'u')))),\n ('e', ('ɪ', ('ə', ('ɔ', 'ɪ')))),\n ('ə', ('ɔ', ('ʊ', ('o', 'ɪ')))),\n ('o', ('ə', ('ɑ', ('u', 'ɛ')))),\n ('e', ('i', ('e', ('ɔ', 'i')))),\n ('ɛ', ('ɪ', ('ɔ', ('ɛ', 'ʊ')))),\n ('o', ('æ', ('e', ('o', 'ɑ')))),\n ('ɛ', ('i', ('ə', ('ɛ', 'i')))),\n ('i', ('ɑ', ('æ', ('ɑ', 'æ')))),\n ('ə', ('æ', ('o', ('ɛ', 'u')))),\n ('e', ('ɑ', ('ə', ('i', 'æ')))),\n ('ə', ('ɪ', ('ɔ', ('ə', 'ə')))),\n ('u', ('ə', ('o', ('æ', 'o')))),\n ('ɪ', ('ɔ', ('e', ('ɪ', 'ɪ')))),\n ('ɛ', ('ɔ', ('æ', ('ɛ', 'o')))),\n ('æ', ('e', ('ʊ', ('ə', 'ɑ')))),\n ('ɑ', ('ɔ', ('æ', ('ɔ', 'u')))),\n ('ɪ', ('e', ('o', ('ɑ', 'ə')))),\n ('ɪ', ('ɛ', ('e', ('ɑ', 'ɪ')))),\n ('ɪ', ('ɪ', ('ə', ('ɪ', 'ɛ')))),\n ('o', ('e', ('ɪ', ('i', 'ʊ')))),\n ('ɪ', ('ɑ', ('i', ('æ', 'u')))),\n ('ɔ', ('u', ('ə', ('ɔ', 'ʊ')))),\n ('ə', ('ɔ', ('ʊ', ('ʊ', 'ɛ')))),\n ('u', ('u', ('ə', ('e', 'ɛ')))),\n ('ɔ', ('i', ('ɛ', ('e', 'e')))),\n ('ʊ', ('u', ('ɑ', ('i', 'i')))),\n ('ʊ', ('e', ('ɛ', ('ə', 'ə')))),\n ('ɪ', ('ʊ', ('ɪ', ('e', 'e')))),\n ('æ', ('u', ('e', ('ʊ', 'ɔ')))),\n ('o', ('i', ('ɑ', ('o', 'ʊ')))),\n ('i', ('ʊ', ('ʊ', ('ɛ', 'ɛ')))),\n ('æ', ('ɛ', ('ə', ('i', 'e')))),\n ('o', ('e', ('ɑ', ('ə', 'i')))),\n ('ɑ', ('ɔ', ('o', ('u', 'o')))),\n ('ə', ('ɪ', ('ɑ', ('i', 'e')))),\n ('æ', ('u', ('e', ('ə', 'ɛ')))),\n ('ʊ', ('u', ('ɛ', ('ɪ', 'ɛ')))),\n ('u', ('o', ('ʊ', ('ɑ', 'i')))),\n ('ɛ', ('e', ('æ', ('i', 'æ')))),\n ('e', ('ɪ', ('ə', ('u', 'ɔ')))),\n ('ɑ', ('ʊ', ('e', ('ɪ', 'ɑ')))),\n ('u', ('ɔ', ('ɛ', ('ʊ', 'ɪ')))),\n ('e', ('i', ('u', ('ɪ', 'ɑ')))),\n ('ʊ', ('ɔ', ('i', ('ɔ', 'ə')))),\n ('ɑ', ('i', ('ɔ', ('e', 'u')))),\n ('ɑ', ('ɑ', ('e', ('ə', 'u')))),\n ('æ', ('ʊ', ('u', ('ʊ', 'o')))),\n ('ʊ', ('e', ('ʊ', ('ʊ', 'o')))),\n ('o', ('ɑ', ('o', ('ɛ', 'ə')))),\n ('o', ('o', ('ɔ', ('i', 'ɑ')))),\n ('ɔ', ('ɑ', ('ɑ', ('ə', 'u')))),\n ('ɔ', ('ɔ', ('ɪ', ('ə', 'ɛ')))),\n ('ɛ', ('ə', ('ɛ', ('ʊ', 'ɛ')))),\n ('o', ('e', ('i', ('i', 'i')))),\n ('ʊ', ('ɔ', ('ʊ', ('ə', 'e')))),\n ('o', ('ə', ('ɪ', ('ɛ', 'æ')))),\n ('ɪ', ('ɛ', ('ɑ', ('ɔ', 'i')))),\n ('i', ('o', ('ɛ', ('u', 'ə')))),\n ('e', ('ɛ', ('ɔ', ('u', 'ɪ')))),\n ('ɑ', ('æ', ('i', ('ɪ', 'ɔ')))),\n ('ʊ', ('ɪ', ('o', ('ɛ', 'e')))),\n ('u', ('ɑ', ('i', ('æ', 'i')))),\n ('ɛ', ('ɪ', ('ʊ', ('æ', 'ɔ')))),\n ('i', ('æ', ('o', ('ɪ', 'e')))),\n ('ʊ', ('u', ('o', ('ə', 'u')))),\n ('ɔ', ('i', ('ɛ', ('e', 'ʊ')))),\n ('ə', ('ɛ', ('o', ('e', 'ʊ')))),\n ('e', ('ɑ', ('ʊ', ('e', 'ə')))),\n ('ɑ', ('i', ('ɪ', ('ɔ', 'i')))),\n ('ɔ', ('æ', ('ɔ', ('o', 'ə')))),\n ('u', ('ɔ', ('æ', ('ɛ', 'i')))),\n ('u', ('ɪ', ('ə', ('e', 'u')))),\n ('e', ('ɪ', ('ə', ('ʊ', 'æ')))),\n ('æ', ('æ', ('ɪ', ('ʊ', 'u')))),\n ('ɔ', ('ʊ', ('e', ('ə', 'ɪ')))),\n ('ɑ', ('ɑ', ('ɛ', ('o', 'u')))),\n ('ə', ('æ', ('ɛ', ('ɑ', 'u')))),\n ('e', ('ʊ', ('ɔ', ('ʊ', 'u')))),\n ('ɛ', ('ɔ', ('ɛ', ('ɔ', 'ɛ')))),\n ('ɔ', ('ə', ('ɔ', ('i', 'ɑ')))),\n ('u', ('ɛ', ('æ', ('ʊ', 'ɪ')))),\n ('ɛ', ('æ', ('i', ('æ', 'ɪ')))),\n ('e', ('ʊ', ('æ', ('æ', 'ɔ')))),\n ('o', ('ɛ', ('u', ('ɪ', 'ə')))),\n ('ə', ('æ', ('u', ('ɛ', 'ɛ')))),\n ('ə', ('ɔ', ('ə', ('i', 'i')))),\n ('ɛ', ('ɔ', ('ʊ', ('e', 'ɔ')))),\n ('ə', ('o', ('ɑ', ('i', 'ɑ')))),\n ('i', ('ɪ', ('ɔ', ('ɪ', 'ɑ')))),\n ('i', ('e', ('o', ('ə', 'ə')))),\n ('ɪ', ('ə', ('ɔ', ('i', 'ɛ')))),\n ('i', ('ɛ', ('ɑ', ('ɛ', 'u')))),\n ('e', ('ʊ', ('ɑ', ('ɑ', 'ɛ')))),\n ('æ', ('ʊ', ('ə', ('æ', 'e')))),\n ('u', ('ɑ', ('e', ('ɪ', 'i')))),\n ('u', ('ɛ', ('o', ('o', 'u')))),\n ('i', ('ə', ('o', ('ɑ', 'e')))),\n ('i', ('u', ('ɔ', ('ɔ', 'ʊ')))),\n ('ɛ', ('ɔ', ('u', ('ə', 'ɪ')))),\n ('o', ('e', ('æ', ('ɪ', 'ɑ')))),\n ('ʊ', ('ɪ', ('æ', ('ɛ', 'u')))),\n ('i', ('ɪ', ('ɑ', ('ɔ', 'ɑ')))),\n ('ə', ('e', ('ɔ', ('e', 'i')))),\n ('o', ('o', ('u', ('ɪ', 'æ')))),\n ('ə', ('i', ('æ', ('æ', 'ɑ')))),\n ('u', ('ʊ', ('e', ('u', 'o')))),\n ('ɔ', ('u', ('ə', ('ɔ', 'u')))),\n ('e', ('ʊ', ('u', ('i', 'u')))),\n ('ɛ', ('æ', ('ɑ', ('ə', 'ə')))),\n ('æ', ('ɛ', ('ʊ', ('ʊ', 'æ')))),\n ('æ', ('ɑ', ('ɑ', ('ɪ', 'ɪ')))),\n ('ɪ', ('o', ('ɛ', ('ʊ', 'ɔ')))),\n ('ɛ', ('ʊ', ('e', ('ə', 'u')))),\n ('ɪ', ('ɪ', ('ɪ', ('æ', 'e')))),\n ('u', ('ɪ', ('æ', ('ɑ', 'ʊ')))),\n ('ɪ', ('o', ('ɛ', ('ə', 'ɛ')))),\n ('o', ('e', ('ɛ', ('ə', 'ɛ')))),\n ('o', ('æ', ('æ', ('æ', 'ʊ')))),\n ('æ', ('ɛ', ('ɪ', ('ɪ', 'ɔ')))),\n ('o', ('u', ('ɪ', ('ɔ', 'ə')))),\n ('ə', ('i', ('ə', ('ɛ', 'æ')))),\n ('æ', ('ɑ', ('æ', ('ɑ', 'e')))),\n ('i', ('ɑ', ('e', ('u', 'ə')))),\n ('æ', ('æ', ('æ', ('ʊ', 'ɔ')))),\n ('ɛ', ('æ', ('ɛ', ('ɪ', 'ɪ')))),\n ('ɑ', ('ə', ('ʊ', ('ɛ', 'ɔ')))),\n ('æ', ('u', ('ɪ', ('ə', 'o')))),\n ('ə', ('æ', ('ɛ', ('ɔ', 'ʊ')))),\n ('ɔ', ('i', ('e', ('æ', 'ɪ')))),\n ('ɪ', ('ʊ', ('æ', ('e', 'ɔ')))),\n ('u', ('e', ('ɪ', ('ʊ', 'e')))),\n ('ə', ('ɑ', ('ə', ('ɛ', 'ɑ')))),\n ('ɛ', ('e', ('ɔ', ('e', 'ɛ')))),\n ('u', ('æ', ('æ', ('o', 'æ')))),\n ('ɑ', ('ɑ', ('u', ('ʊ', 'ɑ')))),\n ('ɛ', ('i', ('i', ('æ', 'ɛ')))),\n ('i', ('ə', ('ɪ', ('u', 'i')))),\n ('e', ('ɔ', ('u', ('ɪ', 'æ')))),\n ('o', ('ʊ', ('ɪ', ('ɔ', 'ʊ')))),\n ('o', ('ɔ', ('ɑ', ('ɛ', 'e')))),\n ('u', ('ʊ', ('u', ('ɛ', 'o')))),\n ('i', ('æ', ('ɛ', ('ɪ', 'ʊ')))),\n ('ɪ', ('ʊ', ('ə', ('ə', 'i')))),\n ('o', ('u', ('i', ('ɪ', 'ɔ')))),\n ('ɔ', ('o', ('e', ('æ', 'u')))),\n ('ə', ('u', ('ɪ', ('e', 'o')))),\n ('u', ('u', ('ə', ('æ', 'ʊ')))),\n ('u', ('ɑ', ('æ', ('æ', 'o')))),\n ('o', ('u', ('ɪ', ('ɪ', 'i')))),\n ('æ', ('ɪ', ('o', ('u', 'ɪ')))),\n ('ʊ', ('o', ('ɑ', ('æ', 'ʊ')))),\n ('o', ('ɔ', ('u', ('ʊ', 'ʊ')))),\n ('ʊ', ('i', ('ɔ', ('i', 'u')))),\n ('æ', ('e', ('ɪ', ('u', 'ɪ')))),\n ('ʊ', ('o', ('ɛ', ('ɛ', 'ɑ')))),\n ('i', ('ɛ', ('ɛ', ('ɔ', 'ɑ')))),\n ('ʊ', ('ɑ', ('e', ('ɔ', 'æ')))),\n ('o', ('o', ('ʊ', ('e', 'i')))),\n ('ɪ', ('e', ('ʊ', ('ɪ', 'e')))),\n ('ɪ', ('ʊ', ('e', ('ɪ', 'o')))),\n ('ɔ', ('ɑ', ('o', ('ɪ', 'ʊ')))),\n ('ɪ', ('ʊ', ('e', ('u', 'ɑ')))),\n ('ɔ', ('o', ('o', ('o', 'ə')))),\n ('ɔ', ('e', ('ʊ', ('ə', 'u')))),\n ('ʊ', ('ɑ', ('ɪ', ('u', 'ɑ')))),\n ('ʊ', ('e', ('o', ('ɑ', 'æ')))),\n ('ɔ', ('ʊ', ('ʊ', ('ɔ', 'ɑ')))),\n ('o', ('ɑ', ('ɔ', ('ɔ', 'ɪ')))),\n ('æ', ('i', ('ə', ('ɔ', 'æ')))),\n ('i', ('ɛ', ('ɪ', ('ʊ', 'i')))),\n ('ʊ', ('o', ('e', ('i', 'ɪ')))),\n ('ɪ', ('o', ('ɪ', ('æ', 'ɑ')))),\n ('ɪ', ('ə', ('ɑ', ('ɑ', 'i')))),\n ('i', ('o', ('ɪ', ('e', 'e')))),\n ('ɪ', ('ɛ', ('ɛ', ('ʊ', 'e')))),\n ('ɛ', ('ʊ', ('u', ('æ', 'o')))),\n ('ə', ('i', ('ʊ', ('o', 'ʊ')))),\n ('i', ('ɔ', ('ɪ', ('o', 'ʊ')))),\n ('ʊ', ('ɔ', ('ɛ', ('æ', 'ə')))),\n ('æ', ('ɑ', ('i', ('ɔ', 'o')))),\n ('ɪ', ('ʊ', ('ɔ', ('ɛ', 'o')))),\n ('i', ('ə', ('ʊ', ('ɔ', 'ə')))),\n ('u', ('e', ('ɪ', ('ɛ', 'ʊ')))),\n ('u', ('e', ('ɛ', ('ɪ', 'e')))),\n ('ɪ', ('æ', ('ʊ', ('ɪ', 'u')))),\n ('i', ('e', ('e', ('o', 'o')))),\n ('ɪ', ('ɑ', ('e', ('ə', 'ɛ')))),\n ('ɪ', ('ʊ', ('i', ('ɑ', 'e')))),\n ('u', ('æ', ('ɪ', ('e', 'ɪ')))),\n ('u', ('o', ('o', ('ʊ', 'ɑ')))),\n ('e', ('e', ('ɔ', ('æ', 'e')))),\n ('ɪ', ('u', ('u', ('u', 'ɑ')))),\n ('ɪ', ('i', ('ʊ', ('ɛ', 'ʊ')))),\n ('ɪ', ('ɑ', ('e', ('ɛ', 'ɔ')))),\n ('u', ('ɑ', ('u', ('ɔ', 'u')))),\n ('ɑ', ('æ', ('ʊ', ('ɑ', 'ɑ')))),\n ('e', ('ɔ', ('ʊ', ('e', 'i')))),\n ('æ', ('u', ('ə', ('ʊ', 'ʊ')))),\n ('o', ('æ', ('u', ('u', 'æ')))),\n ('ʊ', ('u', ('ɪ', ('ʊ', 'o')))),\n ('o', ('ɪ', ('ɪ', ('o', 'ɔ')))),\n ('ɪ', ('ə', ('ɛ', ('ɔ', 'o')))),\n ('o', ('ɑ', ('ɔ', ('u', 'ɔ')))),\n ('u', ('o', ('ɑ', ('ʊ', 'ɪ')))),\n ('u', ('ɪ', ('æ', ('ɑ', 'u')))),\n ('o', ('ʊ', ('e', ('ɪ', 'ɪ')))),\n ('æ', ('i', ('æ', ('u', 'i')))),\n ('o', ('æ', ('æ', ('æ', 'u')))),\n ('ə', ('ɛ', ('e', ('æ', 'e')))),\n ('u', ('æ', ('ɛ', ('ɪ', 'u')))),\n ('i', ('ʊ', ('e', ('ʊ', 'ʊ')))),\n ('e', ('æ', ('ɔ', ('æ', 'u')))),\n ('e', ('ɪ', ('ʊ', ('i', 'ɑ')))),\n ('e', ('e', ('e', ('ɪ', 'ʊ')))),\n ('ə', ('ə', ('ɛ', ('ʊ', 'o')))),\n ('ə', ('ɔ', ('ɪ', ('ɪ', 'i')))),\n ('ə', ('u', ('ɔ', ('i', 'ə')))),\n ('u', ('e', ('o', ('ɔ', 'ə')))),\n ('o', ('ə', ('æ', ('i', 'e')))),\n ('ɪ', ('o', ('o', ('i', 'o')))),\n ('e', ('o', ('ɪ', ('o', 'ɔ')))),\n ('ɪ', ('o', ('ə', ('ɪ', 'o')))),\n ('æ', ('ə', ('o', ('æ', 'i')))),\n ('i', ('i', ('i', ('i', 'ɔ')))),\n ('ʊ', ('æ', ('ɪ', ('ʊ', 'æ')))),\n ('æ', ('ɔ', ('u', ('u', 'ɛ')))),\n ('i', ('u', ('ɑ', ('ɛ', 'e')))),\n ('ʊ', ('ɑ', ('e', ('ɛ', 'ɑ')))),\n ('ɪ', ('æ', ('ɔ', ('ə', 'e')))),\n ('e', ('ɔ', ('ɪ', ('ɛ', 'æ')))),\n ('ɛ', ('ʊ', ('æ', ('ɛ', 'ɑ')))),\n ('ʊ', ('i', ('ɪ', ('ə', 'ɔ')))),\n ('o', ('e', ('ə', ('ɑ', 'i')))),\n ('ɛ', ('e', ('æ', ('ɪ', 'u')))),\n ('u', ('u', ('ʊ', ('i', 'ɛ')))),\n ('e', ('o', ('o', ('æ', 'ʊ')))),\n ('i', ('ɑ', ('o', ('i', 'ɑ')))),\n ('ɛ', ('ɑ', ('ə', ('ɑ', 'ɛ')))),\n ('ʊ', ('ʊ', ('æ', ('o', 'o')))),\n ('o', ('ɛ', ('ɪ', ('i', 'ɑ')))),\n ('o', ('ə', ('e', ('ɔ', 'ɪ')))),\n ('o', ('ɑ', ('ɔ', ('ʊ', 'æ')))),\n ('ɔ', ('æ', ('ə', ('e', 'ɔ')))),\n ('ɑ', ('ɔ', ('ɪ', ('ɛ', 'i')))),\n ('ʊ', ('u', ('ɪ', ('ʊ', 'ɑ')))),\n ('o', ('o', ('o', ('ɛ', 'ɑ')))),\n ('ɛ', ('æ', ('e', ('o', 'ə')))),\n ('u', ('ɔ', ('ʊ', ('ɑ', 'o')))),\n ('ə', ('i', ('ʊ', ('e', 'ɑ')))),\n ('ə', ('ɑ', ('ɔ', ('ʊ', 'u')))),\n ('æ', ('ɑ', ('o', ('i', 'u')))),\n ('ɛ', ('o', ('ɪ', ('ɔ', 'ɔ')))),\n ('i', ('ɛ', ('ʊ', ('u', 'ə')))),\n ('i', ('ɑ', ('ɑ', ('i', 'ɪ')))),\n ('e', ('e', ('æ', ('e', 'ʊ')))),\n ('æ', ('o', ('i', ('æ', 'ɪ')))),\n ('ɪ', ('u', ('æ', ('ɔ', 'ə')))),\n ('ɔ', ('ɑ', ('o', ('ɪ', 'u')))),\n ('u', ('i', ('ʊ', ('i', 'i')))),\n ('ɔ', ('o', ('e', ('æ', 'ə')))),\n ('u', ('e', ('o', ('ɪ', 'i')))),\n ('o', ('o', ('ɑ', ('ɛ', 'ɪ')))),\n ('ʊ', ('ɔ', ('i', ('u', 'ʊ')))),\n ('ə', ('ə', ('ɛ', ('ʊ', 'ɑ')))),\n ('ɔ', ('e', ('i', ('o', 'ə')))),\n ('æ', ('ɛ', ('ə', ('i', 'ə')))),\n ('ə', ('ʊ', ('i', ('e', 'ɛ')))),\n ('o', ('ɔ', ('o', ('æ', 'ə')))),\n ('e', ('e', ('i', ('ɪ', 'ɛ')))),\n ('ɑ', ('ɑ', ('o', ('ə', 'ɛ')))),\n ('ɔ', ('æ', ('ɛ', ('u', 'i')))),\n ('ɔ', ('æ', ('o', ('ɪ', 'ə')))),\n ('ɛ', ('ɑ', ('æ', ('o', 'i')))),\n ('e', ('u', ('i', ('i', 'ɔ')))),\n ('i', ('ɔ', ('e', ('i', 'o')))),\n ('ɑ', ('e', ('i', ('ɔ', 'ə')))),\n ('o', ('æ', ('ɛ', ('i', 'u')))),\n ('e', ('ɔ', ('o', ('ɛ', 'ɑ')))),\n ('æ', ('æ', ('ʊ', ('ɪ', 'i')))),\n ('ɛ', ('ɔ', ('ɔ', ('æ', 'o')))),\n ('e', ('u', ('ɑ', ('e', 'ə')))),\n ('o', ('ɛ', ('i', ('ɔ', 'ʊ')))),\n ('ə', ('ɑ', ('u', ('i', 'u')))),\n ('ɪ', ('ʊ', ('ɛ', ('i', 'ɪ')))),\n ('ʊ', ('ɛ', ('æ', ('e', 'ɪ')))),\n ('ɛ', ('æ', ('u', ('e', 'i')))),\n ('ʊ', ('ʊ', ('ɔ', ('ə', 'u')))),\n ('e', ('ɔ', ('ɑ', ('ɛ', 'ɪ')))),\n ('e', ('ɪ', ('i', ('ʊ', 'æ')))),\n ('ɔ', ('ɪ', ('ɑ', ('ə', 'ɑ')))),\n ('i', ('ɪ', ('o', ('ʊ', 'ɑ')))),\n ('ɛ', ('ə', ('u', ('æ', 'ɛ')))),\n ('ɪ', ('ɛ', ('ɛ', ('u', 'ɪ')))),\n ('ɪ', ('æ', ('u', ('æ', 'ə')))),\n ('ɔ', ('ə', ('ɔ', ('e', 'ə')))),\n ('ə', ('ɛ', ('ɛ', ('ə', 'e')))),\n ('ɪ', ('ə', ('ʊ', ('ɑ', 'ɛ')))),\n ('ɪ', ('ə', ('ɔ', ('ɛ', 'ɛ')))),\n ('ʊ', ('æ', ('ɑ', ('ə', 'ɔ')))),\n ('ʊ', ('æ', ('æ', ('ɔ', 'ɔ')))),\n ('i', ('o', ('ə', ('ə', 'i')))),\n ('ə', ('ɪ', ('e', ('u', 'ʊ')))),\n ('ʊ', ('ɔ', ('u', ('i', 'e')))),\n ('æ', ('ɔ', ('ə', ('u', 'ɔ')))),\n ('e', ('ɪ', ('i', ('ɔ', 'u')))),\n ('ɔ', ('æ', ('æ', ('ɛ', 'ʊ')))),\n ('i', ('ɔ', ('o', ('e', 'ɪ')))),\n ('ɑ', ('e', ('i', ('ɪ', 'i')))),\n ('ɑ', ('ə', ('ɔ', ('e', 'ɑ')))),\n ('ɔ', ('ə', ('æ', ('o', 'ɪ')))),\n ('ɛ', ('æ', ('ɑ', ('u', 'ə')))),\n ('e', ('e', ('ɔ', ('ɑ', 'ɔ')))),\n ('e', ('e', ('u', ('o', 'e')))),\n ('o', ('ɑ', ('u', ('ʊ', 'ɪ')))),\n ('i', ('ɔ', ('u', ('ɔ', 'ɪ')))),\n ('u', ('ʊ', ('æ', ('u', 'æ')))),\n ('ɑ', ('ɪ', ('ɛ', ('o', 'ɑ')))),\n ('ɪ', ('u', ('ɪ', ('ɪ', 'e')))),\n ('ə', ('o', ('e', ('ɔ', 'ɔ')))),\n ('e', ('i', ('o', ('ɛ', 'ɪ')))),\n ('i', ('ə', ('e', ('e', 'o')))),\n ('ə', ('i', ('æ', ('ɛ', 'ɛ')))),\n ('o', ('æ', ('e', ('ɑ', 'ɔ')))),\n ('i', ('o', ('e', ('u', 'ɑ')))),\n ('u', ('ɑ', ('ɛ', ('æ', 'ɑ')))),\n ('e', ('o', ('o', ('æ', 'u')))),\n ('æ', ('u', ('ɪ', ('i', 'æ')))),\n ('ɑ', ('ɛ', ('ɛ', ('ɔ', 'e')))),\n ('ɔ', ('o', ('ɔ', ('ɔ', 'ɛ')))),\n ('ə', ('e', ('ɔ', ('ɑ', 'u')))),\n ('ɔ', ('ɑ', ('ɔ', ('e', 'ʊ')))),\n ('o', ('ɛ', ('ɔ', ('ə', 'ʊ')))),\n ('æ', ('ɑ', ('ɛ', ('æ', 'o')))),\n ('æ', ('ɔ', ('ə', ('ɑ', 'ɛ')))),\n ('ʊ', ('o', ('o', ('o', 'ʊ')))),\n ('ə', ('ɛ', ('æ', ('u', 'o')))),\n ('æ', ('ʊ', ('o', ('u', 'u')))),\n ('u', ('ɑ', ('e', ('ɑ', 'ɑ')))),\n ('i', ('i', ('æ', ('ɑ', 'ɛ')))),\n ('e', ('i', ('ə', ('i', 'ɛ')))),\n ('æ', ('ʊ', ('ɪ', ('ɑ', 'e')))),\n ('ʊ', ('ɪ', ('ɛ', ('ɛ', 'ə')))),\n ('æ', ('ɔ', ('ə', ('ʊ', 'æ')))),\n ('ʊ', ('ɔ', ('æ', ('i', 'ɛ')))),\n ('e', ('æ', ('u', ('o', 'u')))),\n ('ə', ('ɪ', ('u', ('ʊ', 'u')))),\n ('u', ('ɑ', ('ə', ('ɔ', 'ɛ')))),\n ('i', ('æ', ('o', ('o', 'ɛ')))),\n ('ɔ', ('ɪ', ('ɪ', ('i', 'ə')))),\n ('ɔ', ('ɔ', ('ɑ', ('ʊ', 'ɔ')))),\n ('i', ('u', ('o', ('æ', 'ə')))),\n ('ɔ', ('ə', ('e', ('e', 'e')))),\n ('ə', ('ʊ', ('u', ('ɪ', 'e')))),\n ('ɛ', ('ə', ('e', ('o', 'e')))),\n ('o', ('æ', ('ʊ', ('e', 'u')))),\n ('ɑ', ('ɑ', ('ɛ', ('ə', 'æ')))),\n ('ɑ', ('u', ('ɪ', ('ɔ', 'ɔ')))),\n ('e', ('ɑ', ('o', ('ə', 'ɑ')))),\n ('ɑ', ('ə', ('ɛ', ('e', 'i')))),\n ('u', ('ʊ', ('i', ('ə', 'i')))),\n ('ə', ('ɔ', ('ʊ', ('e', 'æ')))),\n ('ɛ', ('o', ('e', ('ʊ', 'i')))),\n ('u', ('i', ('æ', ('i', 'ɑ')))),\n ('æ', ('ʊ', ('æ', ('ə', 'o')))),\n ('ɔ', ('ə', ('u', ('o', 'o')))),\n ('ɪ', ('e', ('ʊ', ('i', 'ɔ')))),\n ('ɛ', ('æ', ('u', ('i', 'ɛ')))),\n ('i', ('ʊ', ('ɪ', ('ɔ', 'æ')))),\n ('æ', ('i', ('æ', ('ɔ', 'ɛ')))),\n ('ɔ', ('ɪ', ('ɔ', ('ɛ', 'e')))),\n ('ʊ', ('ɔ', ('ɑ', ('ɑ', 'ə')))),\n ('ɪ', ('i', ('ə', ('ɔ', 'ɔ')))),\n ('ɪ', ('æ', ('ə', ('u', 'e')))),\n ('ʊ', ('u', ('ə', ('ɔ', 'ʊ')))),\n ('ɪ', ('i', ('ʊ', ('ʊ', 'ə')))),\n ('u', ('u', ('ɛ', ('o', 'o')))),\n ('æ', ('e', ('ə', ('u', 'æ')))),\n ('ɔ', ('ʊ', ('ʊ', ('ʊ', 'ɪ')))),\n ('ɛ', ('e', ('e', ('o', 'u')))),\n ('u', ('ɪ', ('o', ('ɛ', 'ə')))),\n ('u', ('e', ('ɪ', ('ɛ', 'ə')))),\n ('æ', ('æ', ('æ', ('ɪ', 'ɑ')))),\n ('e', ('ɑ', ('ə', ('i', 'ɑ')))),\n ('ɔ', ('ɪ', ('i', ('i', 'u')))),\n ('ɑ', ('ɪ', ('ɪ', ('e', 'ʊ')))),\n ('ɛ', ('æ', ('i', ('ɔ', 'ɔ')))),\n ('ɔ', ('o', ('ɪ', ('e', 'ə')))),\n ('ə', ('i', ('ə', ('ʊ', 'ɔ')))),\n ('u', ('i', ('u', ('ɑ', 'i')))),\n ('u', ('ɔ', ('ɑ', ('e', 'e')))),\n ('æ', ('ɑ', ('ɛ', ('ɑ', 'e')))),\n ('ɪ', ('æ', ('e', ('e', 'ɔ')))),\n ('æ', ('æ', ('ɛ', ('ʊ', 'ɔ')))),\n ('ɛ', ('ɔ', ('ɪ', ('o', 'ə')))),\n ('o', ('ɛ', ('ɔ', ('æ', 'ɪ')))),\n ('ə', ('e', ('o', ('e', 'u')))),\n ('æ', ('æ', ('ɛ', ('ə', 'ɛ')))),\n ('ʊ', ('o', ('o', ('e', 'ɑ')))),\n ('ʊ', ('ɑ', ('ɑ', ('ə', 'u')))),\n ('ʊ', ('ɔ', ('ɪ', ('ə', 'ɛ')))),\n ('æ', ('æ', ('ɛ', ('ɛ', 'ɔ')))),\n ('u', ('æ', ('ɛ', ('o', 'æ')))),\n ('i', ('ɪ', ('ɛ', ('ɑ', 'ʊ')))),\n ('ɛ', ('ɑ', ('u', ('ʊ', 'e')))),\n ('e', ('ɪ', ('ʊ', ('e', 'ɛ')))),\n ('ɔ', ('i', ('u', ('ə', 'æ')))),\n ('u', ('u', ('ə', ('e', 'ɪ')))),\n ('e', ('e', ('i', ('æ', 'u')))),\n ('u', ('ɪ', ('i', ('ə', 'ə')))),\n ('æ', ('ə', ('i', ('u', 'ɑ')))),\n ('ʊ', ('o', ('ɑ', ('e', 'ɪ')))),\n ('æ', ('ɪ', ('æ', ('ɔ', 'æ')))),\n ('ʊ', ('i', ('ɛ', ('e', 'ʊ')))),\n ('ʊ', ('i', ('i', ('æ', 'ə')))),\n ('ʊ', ('æ', ('ɔ', ('o', 'ə')))),\n ('ɑ', ('æ', ('e', ('o', 'u')))),\n ('ɑ', ('e', ('ɛ', ('æ', 'ə')))),\n ('ʊ', ('ʊ', ('e', ('ə', 'ɪ')))),\n ('ɔ', ('æ', ('ɑ', ('o', 'u')))),\n ('ʊ', ('ʊ', ('i', ('ɪ', 'e')))),\n ('i', ('æ', ('e', ('æ', 'ɛ')))),\n ('ɛ', ('æ', ('ɔ', ('ə', 'ɔ')))),\n ('ʊ', ('ɪ', ('ɔ', ('o', 'ɪ')))),\n ('ɛ', ('u', ('e', ('ɔ', 'ɑ')))),\n ('ʊ', ('ə', ('ɔ', ('i', 'ɑ')))),\n ('æ', ('ɛ', ('o', ('u', 'ə')))),\n ('ə', ('ɔ', ('ɛ', ('ʊ', 'ə')))),\n ('i', ('ɪ', ('o', ('ɛ', 'u')))),\n ('o', ('i', ('æ', ('u', 'æ')))),\n ('ɛ', ('o', ('o', ('ʊ', 'ɛ')))),\n ('e', ('ɛ', ('ɪ', ('i', 'ə')))),\n ('i', ('ɑ', ('ɔ', ('ɔ', 'i')))),\n ('i', ('e', ('i', ('ɛ', 'u')))),\n ('ɑ', ('æ', ('ɑ', ('ɛ', 'æ')))),\n ('ə', ('ɛ', ('ɔ', ('i', 'ɛ')))),\n ('e', ('i', ('ɔ', ('u', 'æ')))),\n ('u', ('u', ('ʊ', ('ɛ', 'ɛ')))),\n ('ɔ', ('ɑ', ('o', ('o', 'æ')))),\n ('ɑ', ('i', ('ɑ', ('o', 'ɔ')))),\n ('e', ('æ', ('u', ('o', 'ə')))),\n ('ɪ', ('ə', ('ɑ', ('ɔ', 'ə')))),\n ('ɪ', ('ɑ', ('ə', ('ʊ', 'u')))),\n ('i', ('i', ('u', ('ɔ', 'e')))),\n ('ɛ', ('u', ('u', ('ɑ', 'æ')))),\n ('ɔ', ('ə', ('ə', ('ɑ', 'æ')))),\n ('e', ('ɑ', ('ə', ('ə', 'e')))),\n ('æ', ('æ', ('ɪ', ('æ', 'ɑ')))),\n ('ɑ', ('u', ('e', ('ʊ', 'i')))),\n ('ə', ('o', ('ɑ', ('u', 'o')))),\n ('o', ('i', ('o', ('e', 'e')))),\n ('ɪ', ('o', ('e', ('ɑ', 'e')))),\n ('ɔ', ('æ', ('u', ('ɑ', 'ɪ')))),\n ('ɑ', ('ɛ', ('e', ('ɑ', 'ɑ')))),\n ('u', ('i', ('o', ('e', 'ʊ')))),\n ('ɔ', ('u', ('ɑ', ('ʊ', 'i')))),\n ('ʊ', ('u', ('ə', ('ɔ', 'u')))),\n ('ə', ('ə', ('ɑ', ('ʊ', 'ə')))),\n ('u', ('ɛ', ('e', ('i', 'e')))),\n ('u', ('ɔ', ('æ', ('i', 'æ')))),\n ('u', ('ɛ', ('u', ('e', 'ɑ')))),\n ('ɪ', ('ɛ', ('æ', ('æ', 'ɔ')))),\n ('i', ('ɪ', ('e', ('u', 'ɛ')))),\n ('ɔ', ('o', ('i', ('æ', 'o')))),\n ('o', ('i', ('i', ('ə', 'i')))),\n ('ʊ', ('i', ('ɑ', ('ɪ', 'ɑ')))),\n ('ɛ', ('e', ('ɪ', ('e', 'ɪ')))),\n ('o', ('ɔ', ('ɪ', ('ʊ', 'u')))),\n ('ɪ', ('ɛ', ('æ', ('æ', 'ɪ')))),\n ('ɛ', ('u', ('ʊ', ('æ', 'ɛ')))),\n ('i', ('ɔ', ('ə', ('u', 'ə')))),\n ('ɪ', ('ɛ', ('ɑ', ('ɑ', 'ɛ')))),\n ('ɛ', ('æ', ('ʊ', ('i', 'ə')))),\n ('ə', ('i', ('ɔ', ('ʊ', 'e')))),\n ('i', ('i', ('ɛ', ('ɛ', 'æ')))),\n ('æ', ('ʊ', ('ɪ', ('ɔ', 'e')))),\n ('ɪ', ('æ', ('ɔ', ('ɔ', 'o')))),\n ('o', ('ə', ('u', ('o', 'ɔ')))),\n ('u', ('æ', ('u', ('ɔ', 'ɑ')))),\n ('æ', ('i', ('ɛ', ('i', 'o')))),\n ('e', ('ɛ', ('e', ('ɛ', 'i')))),\n ('ɪ', ('i', ('ɪ', ('ʊ', 'ɛ')))),\n ('i', ('ɑ', ('ɑ', ('æ', 'ʊ')))),\n ('ə', ('ɑ', ('ɛ', ('ɛ', 'e')))),\n ('ɔ', ('i', ('i', ('ɛ', 'ɪ')))),\n ('ɑ', ('ʊ', ('ɛ', ('i', 'æ')))),\n ('ɛ', ('ɑ', ('i', ('u', 'ə')))),\n ('ɑ', ('ɛ', ('ɪ', ('ɪ', 'ɑ')))),\n ('æ', ('ɔ', ('u', ('ʊ', 'e')))),\n ('ɑ', ('ʊ', ('ʊ', ('i', 'i')))),\n ('ə', ('æ', ('ɔ', ('ʊ', 'o')))),\n ('æ', ('æ', ('o', ('i', 'o')))),\n ('ɑ', ('æ', ('u', ('æ', 'e')))),\n ('ɛ', ('i', ('e', ('ɑ', 'æ')))),\n ('æ', ('æ', ('ə', ('ɪ', 'o')))),\n ('i', ('ɛ', ('i', ('ɔ', 'æ')))),\n ('ʊ', ('o', ('e', ('æ', 'u')))),\n ('æ', ('ʊ', ('u', ('æ', 'ɪ')))),\n ('u', ('ɪ', ('ɔ', ('ɔ', 'ɪ')))),\n ('ʊ', ('e', ('ʊ', ('æ', 'ɪ')))),\n ('e', ('ʊ', ('i', ('ʊ', 'e')))),\n ('ɪ', ('e', ('ɪ', ('ɪ', 'ɛ')))),\n ('ɪ', ('u', ('ɑ', ('æ', 'ɑ')))),\n ('ɪ', ('o', ('ɪ', ('u', 'u')))),\n ('ə', ('o', ('ə', ('æ', 'ə')))),\n ('ɛ', ('u', ('o', ('ɛ', 'æ')))),\n ('e', ('ʊ', ('u', ('u', 'u')))),\n ('ɪ', ('i', ('ə', ('i', 'ʊ')))),\n ('o', ('ɛ', ('u', ('o', 'ɪ')))),\n ('ʊ', ('ɑ', ('o', ('ɪ', 'ʊ')))),\n ('ɪ', ('u', ('ɪ', ('i', 'ɔ')))),\n ('ɔ', ('æ', ('i', ('e', 'ə')))),\n ('ɔ', ('ʊ', ('e', ('ɛ', 'æ')))),\n ('ɪ', ('ə', ('u', ('ɑ', 'ɔ')))),\n ('ʊ', ('e', ('ʊ', ('ə', 'u')))),\n ('o', ('ʊ', ('o', ('o', 'ɔ')))),\n ('ɛ', ('ɑ', ('u', ('u', 'ɪ')))),\n ('ɛ', ('i', ('æ', ('e', 'i')))),\n ('u', ('ɔ', ('ɪ', ('ə', 'æ')))),\n ('ʊ', ('ʊ', ('ʊ', ('ɔ', 'ɑ')))),\n ('ɑ', ('æ', ('ʊ', ('e', 'o')))),\n ('ə', ('u', ('e', ('i', 'i')))),\n ('i', ('ɔ', ('e', ('e', 'ə')))),\n ('æ', ('ʊ', ('ʊ', ('ɑ', 'ə')))),\n ('æ', ('ɔ', ('æ', ('ʊ', 'ɛ')))),\n ('ə', ('o', ('e', ('e', 'ɛ')))),\n ('ɑ', ('ɛ', ('ə', ('ə', 'o')))),\n ('ɑ', ('u', ('u', ('æ', 'ɛ')))),\n ('ə', ('e', ('e', ('ə', 'ɑ')))),\n ('u', ('ɪ', ('ɔ', ('u', 'ɔ')))),\n ('o', ('ɔ', ('u', ('ɔ', 'ɛ')))),\n ('ə', ('æ', ('ɔ', ('ʊ', 'ɑ')))),\n ('e', ('u', ('o', ('i', 'ɔ')))),\n ('ɑ', ('e', ('u', ('i', 'e')))),\n ('u', ('ɑ', ('ɔ', ('u', 'ɪ')))),\n ('ɔ', ('æ', ('u', ('e', 'ɪ')))),\n ('e', ('ʊ', ('ɑ', ('ɑ', 'i')))),\n ('ɑ', ('ɑ', ('ɪ', ('ɑ', 'ə')))),\n ('ɔ', ('u', ('ɛ', ('ʊ', 'ɛ')))),\n ('ə', ('ɛ', ('ɛ', ('ɔ', 'o')))),\n ('ʊ', ('ɔ', ('æ', ('ʊ', 'i')))),\n ('u', ('e', ('ɪ', ('e', 'u')))),\n ('ɛ', ('e', ('i', ('o', 'o')))),\n ('e', ('e', ('ɪ', ('ʊ', 'æ')))),\n ('o', ('ɪ', ('ɑ', ('o', 'o')))),\n ('ə', ('u', ('i', ('u', 'e')))),\n ('ə', ('ə', ('i', ('u', 'ɔ')))),\n ('ɪ', ('o', ('e', ('ɑ', 'i')))),\n ('ɑ', ('ə', ('ɛ', ('ɑ', 'u')))),\n ('e', ('ɔ', ('e', ('o', 'i')))),\n ('ɪ', ('ʊ', ('i', ('ɔ', 'ə')))),\n ('e', ('i', ('æ', ('o', 'u')))),\n ('i', ('ɛ', ('ɑ', ('ɪ', 'e')))),\n ('i', ('ɑ', ('ɑ', ('æ', 'u')))),\n ('o', ('e', ('ɔ', ('ɪ', 'ɛ')))),\n ('ɑ', ('i', ('ɑ', ('ə', 'i')))),\n ('o', ('ɛ', ('u', ('ɛ', 'æ')))),\n ('ə', ('ɑ', ('æ', ('o', 'ʊ')))),\n ('ɛ', ('ʊ', ('i', ('ʊ', 'ʊ')))),\n ('æ', ('ɔ', ('i', ('u', 'ə')))),\n ('ə', ('u', ('ɔ', ('o', 'e')))),\n ('e', ('o', ('ɑ', ('o', 'o')))),\n ('e', ('e', ('e', ('ɛ', 'ɔ')))),\n ('e', ('ɪ', ('ʊ', ('u', 'o')))),\n ('ɛ', ('æ', ('ɪ', ('i', 'ɛ')))),\n ('ɛ', ('ɑ', ('ə', ('ɑ', 'o')))),\n ('o', ('ɪ', ('ɔ', ('ɑ', 'ɛ')))),\n ('e', ('u', ('ʊ', ('i', 'o')))),\n ('ɑ', ('ɑ', ('ɔ', ('ɑ', 'ə')))),\n ('e', ('ʊ', ('ə', ('e', 'o')))),\n ('ə', ('ə', ('e', ('u', 'æ')))),\n ('ɑ', ('ɛ', ('ʊ', ('i', 'ʊ')))),\n ('o', ('e', ('æ', ('ʊ', 'æ')))),\n ('ʊ', ('ɑ', ('o', ('ɪ', 'u')))),\n ('ʊ', ('o', ('e', ('æ', 'ə')))),\n ('e', ('ɔ', ('æ', ('ɛ', 'e')))),\n ('ɪ', ('o', ('e', ('ɔ', 'e')))),\n ('æ', ('ə', ('ɔ', ('ɪ', 'u')))),\n ('ɑ', ('e', ('ɑ', ('ɑ', 'ə')))),\n ('u', ('ə', ('e', ('u', 'ɪ')))),\n ('æ', ('o', ('ɪ', ('ɪ', 'ʊ')))),\n ('ɪ', ('ɪ', ('ɑ', ('ə', 'ɔ')))),\n ('o', ('ɔ', ('ɔ', ('e', 'ɔ')))),\n ('ʊ', ('e', ('i', ('o', 'ə')))),\n ('ɛ', ('ʊ', ('ə', ('ɪ', 'ɑ')))),\n ('æ', ('ɔ', ('u', ('u', 'ɪ')))),\n ('æ', ('ɛ', ('i', ('ɔ', 'e')))),\n ('æ', ('ʊ', ('ɛ', ('ə', 'o')))),\n ('u', ('æ', ('ə', ('e', 'ʊ')))),\n ('ɛ', ('ɔ', ('ə', ('e', 'ɔ')))),\n ('ʊ', ('æ', ('ɛ', ('u', 'i')))),\n ('u', ('o', ('e', ('ə', 'i')))),\n ('e', ('o', ('ɔ', ('ɑ', 'ɛ')))),\n ('o', ('u', ('i', ('e', 'ɑ')))),\n ('ɪ', ('ɛ', ('o', ('ə', 'ɪ')))),\n ('e', ('e', ('ɔ', ('ɔ', 'u')))),\n ('e', ('æ', ('ʊ', ('i', 'æ')))),\n ('ə', ('ɪ', ('æ', ('æ', 'ɔ')))),\n ('e', ('ɪ', ('ʊ', ('u', 'ɑ')))),\n ('ɪ', ('o', ('ɛ', ('ʊ', 'ʊ')))),\n ('ə', ('ɪ', ('ɔ', ('ɛ', 'u')))),\n ('u', ('o', ('o', ('ə', 'u')))),\n ('e', ('ɔ', ('u', ('i', 'ə')))),\n ('ɔ', ('e', ('ɛ', ('ɛ', 'e')))),\n ('u', ('u', ('e', ('ʊ', 'ʊ')))),\n ('ɑ', ('ʊ', ('u', ('ɑ', 'i')))),\n ('e', ('e', ('æ', ('ɔ', 'ɔ')))),\n ('ɪ', ('ɔ', ('ɛ', ('u', 'ʊ')))),\n ('ə', ('ɪ', ('æ', ('æ', 'ɪ')))),\n ('e', ('ɑ', ('ʊ', ('æ', 'e')))),\n ('ə', ('ɪ', ('ɑ', ('ɑ', 'ɛ')))),\n ('ɑ', ('ɔ', ('æ', ('e', 'ə')))),\n ('e', ('ɑ', ('i', ('u', 'æ')))),\n ('æ', ('e', ('ɛ', ('ʊ', 'i')))),\n ('ɑ', ('ɪ', ('o', ('ɛ', 'ɔ')))),\n ('o', ('o', ('i', ('ɑ', 'æ')))),\n ('ʊ', ('ɪ', ('ɑ', ('ə', 'ɑ')))),\n ('ɪ', ('æ', ('i', ('u', 'u')))),\n ('ɔ', ('u', ('ʊ', ('ɪ', 'o')))),\n ('i', ('u', ('ɪ', ('ə', 'æ')))),\n ('ɛ', ('ɪ', ('ɑ', ('o', 'ʊ')))),\n ('ə', ('ɛ', ('ʊ', ('ɑ', 'ɛ')))),\n ('ə', ('ʊ', ('i', ('e', 'ɪ')))),\n ('e', ('u', ('i', ('ɔ', 'ɪ')))),\n ('ʊ', ('ə', ('ɔ', ('e', 'ə')))),\n ('ɑ', ('o', ('o', ('ɑ', 'i')))),\n ('ɪ', ('i', ('i', ('ɔ', 'ə')))),\n ('i', ('ɔ', ('e', ('ɪ', 'æ')))),\n ('ə', ('ɑ', ('æ', ('e', 'ɑ')))),\n ('ɔ', ('ɛ', ('ʊ', ('æ', 'æ')))),\n ('ɑ', ('ɑ', ('æ', ('ɛ', 'u')))),\n ('ɛ', ('e', ('e', ('ə', 'æ')))),\n ('ʊ', ('æ', ('æ', ('ɛ', 'ʊ')))),\n ('ʊ', ('ə', ('æ', ('o', 'ɪ')))),\n ('ɑ', ('ʊ', ('ɪ', ('ə', 'ɑ')))),\n ('e', ('ɑ', ('u', ('e', 'e')))),\n ('u', ('ʊ', ('ɑ', ('æ', 'o')))),\n ('o', ('i', ('i', ('u', 'i')))),\n ('æ', ('e', ('o', ('ə', 'æ')))),\n ('æ', ('u', ('ə', ('æ', 'ɑ')))),\n ('ɑ', ('i', ('ɛ', ('ə', 'ɛ')))),\n ('ɔ', ('ə', ('i', ('ɑ', 'æ')))),\n ('ʊ', ('o', ('ɔ', ('ɔ', 'ɛ')))),\n ('ɪ', ('i', ('ə', ('ʊ', 'e')))),\n ('i', ('i', ('ɪ', ('ɔ', 'e')))),\n ('o', ('æ', ('ə', ('i', 'ɔ')))),\n ('ʊ', ('ɑ', ('ɔ', ('e', 'ʊ')))),\n ('ɪ', ('e', ('o', ('æ', 'e')))),\n ('ɪ', ('ɔ', ('e', ('ɔ', 'ɑ')))),\n ('ʊ', ('ɪ', ('ʊ', ('ɪ', 'u')))),\n ('o', ('ɛ', ('ʊ', ('ɪ', 'o')))),\n ('i', ('ɑ', ('ɑ', ('æ', 'ə')))),\n ('ɑ', ('o', ('i', ('ə', 'u')))),\n ('e', ('ɛ', ('ʊ', ('ə', 'ə')))),\n ('ɛ', ('ɔ', ('ɔ', ('i', 'o')))),\n ('i', ('ʊ', ('e', ('æ', 'ɑ')))),\n ('ɪ', ('i', ('ɛ', ('æ', 'u')))),\n ('u', ('ɛ', ('ɪ', ('e', 'ɑ')))),\n ('ɔ', ('i', ('æ', ('ɑ', 'ɪ')))),\n ('ɑ', ('ɔ', ('ʊ', ('ɛ', 'ə')))),\n ('ɔ', ('ɪ', ('i', ('ɛ', 'ə')))),\n ('ə', ('ɔ', ('e', ('ʊ', 'ɑ')))),\n ('ʊ', ('ɪ', ('ɪ', ('i', 'ə')))),\n ('o', ('ɪ', ('u', ('ɛ', 'ɪ')))),\n ('ɪ', ('e', ('ə', ('ɪ', 'e')))),\n ('ɪ', ('ɔ', ('u', ('ɑ', 'æ')))),\n ('ʊ', ('ə', ('e', ('e', 'e')))),\n ('e', ('ɑ', ('o', ('æ', 'æ')))),\n ('æ', ('u', ('æ', ('i', 'e')))),\n ('ɔ', ('æ', ('ɑ', ('ə', 'æ')))),\n ('ɑ', ('ʊ', ('o', ('e', 'ʊ')))),\n ('ɑ', ('ɪ', ('ʊ', ('ɛ', 'o')))),\n ('i', ('e', ('ə', ('u', 'ʊ')))),\n ('ɪ', ('æ', ('o', ('æ', 'u')))),\n ('ɔ', ('e', ('ə', ('ə', 'u')))),\n ('o', ('ɪ', ('ɛ', ('ɪ', 'ə')))),\n ('i', ('ɪ', ('o', ('æ', 'ɔ')))),\n ('e', ('ɑ', ('ə', ('ɔ', 'o')))),\n ('ɑ', ('ə', ('ɛ', ('ɪ', 'ɔ')))),\n ('ʊ', ('ə', ('u', ('o', 'o')))),\n ('ɔ', ('æ', ('ɪ', ('æ', 'ə')))),\n ('ʊ', ('ɛ', ('ɑ', ('ɪ', 'ɛ')))),\n ('ɛ', ('u', ('u', ('ɪ', 'ɛ')))),\n ('ɔ', ('ə', ('ə', ('ɪ', 'ɛ')))),\n ('ʊ', ('ɪ', ('ɔ', ('ɛ', 'e')))),\n ('ɪ', ('ʊ', ('ə', ('ɛ', 'ɔ')))),\n ('i', ('i', ('ʊ', ('ɑ', 'ə')))),\n ('ə', ('ɪ', ('u', ('æ', 'ɑ')))),\n ('u', ('i', ('æ', ('u', 'o')))),\n ('ɪ', ('ɔ', ('ʊ', ('æ', 'ɛ')))),\n ('u', ('ə', ('u', ('ɔ', 'ɔ')))),\n ('ɪ', ('i', ('ə', ('ɛ', 'ʊ')))),\n ('ə', ('ɔ', ('ʊ', ('o', 'ɔ')))),\n ('ɪ', ('ɪ', ('ɔ', ('o', 'ə')))),\n ('o', ('u', ('æ', ('ɔ', 'ʊ')))),\n ('ɔ', ('e', ('ɑ', ('i', 'æ')))),\n ('ʊ', ('ʊ', ('ʊ', ('ʊ', 'ɪ')))),\n ('u', ('e', ('ɔ', ('ə', 'ə')))),\n ('ɛ', ('e', ('æ', ('ɔ', 'o')))),\n ('ʊ', ('ɪ', ('i', ('i', 'u')))),\n ('ɛ', ('ə', ('i', ('o', 'ɔ')))),\n ('ə', ('e', ('e', ('u', 'ɑ')))),\n ('æ', ('ɑ', ('ɔ', ('u', 'i')))),\n ('ə', ('i', ('e', ('ʊ', 'ɪ')))),\n ('ɛ', ('i', ('æ', ('ə', 'u')))),\n ('ʊ', ('o', ('ɪ', ('e', 'ə')))),\n ('ɑ', ('o', ('o', ('e', 'i')))),\n ('ɛ', ('ɛ', ('e', ('i', 'ə')))),\n ('æ', ('ɑ', ('o', ('o', 'ə')))),\n ('æ', ('ʊ', ('ʊ', ('ɪ', 'æ')))),\n ('ɪ', ('e', ('ʊ', ('ɔ', 'ɪ')))),\n ('æ', ('ə', ('æ', ('e', 'o')))),\n ('ə', ('æ', ('u', ('ə', 'o')))),\n ('ɛ', ('ɛ', ('o', ('e', 'ə')))),\n ('i', ('ʊ', ('æ', ('ɔ', 'e')))),\n ('ɛ', ('ʊ', ('ɔ', ('ɛ', 'æ')))),\n ('o', ('e', ('æ', ('e', 'u')))),\n ('ʊ', ('e', ('ɑ', ('o', 'e')))),\n ('e', ('ɪ', ('u', ('ɛ', 'e')))),\n ('u', ('ɔ', ('ɛ', ('æ', 'ɛ')))),\n ('ɔ', ('u', ('ɔ', ('ɪ', 'i')))),\n ('ɪ', ('ʊ', ('ɪ', ('ʊ', 'e')))),\n ('e', ('ɑ', ('ʊ', ('ɑ', 'ɔ')))),\n ('ʊ', ('i', ('u', ('ə', 'æ')))),\n ('i', ('o', ('i', ('ɪ', 'i')))),\n ('æ', ('u', ('ɛ', ('æ', 'ɛ')))),\n ('o', ('ɑ', ('ʊ', ('ɑ', 'æ')))),\n ('ɪ', ('ɪ', ('æ', ('i', 'ʊ')))),\n ('o', ('i', ('i', ('i', 'ʊ')))),\n ('æ', ('ɛ', ('ɔ', ('ə', 'o')))),\n ('ə', ('u', ('ɑ', ('e', 'i')))),\n ('u', ('e', ('ɛ', ('ɔ', 'ɪ')))),\n ('ɪ', ('u', ('i', ('ɑ', 'ɑ')))),\n ('u', ('o', ('ɪ', ('ʊ', 'o')))),\n ('ɪ', ('e', ('e', ('ə', 'ʊ')))),\n ('ɛ', ('i', ('e', ('ɪ', 'ɛ')))),\n ('æ', ('ə', ('ʊ', ('ɔ', 'æ')))),\n ('ə', ('ɑ', ('ʊ', ('ɑ', 'u')))),\n ('o', ('e', ('o', ('o', 'ɪ')))),\n ('æ', ('e', ('ɛ', ('e', 'o')))),\n ('ɛ', ('ɛ', ('ɛ', ('e', 'ɑ')))),\n ('ɑ', ('o', ('ɛ', ('ɔ', 'ʊ')))),\n ('ɔ', ('i', ('u', ('ə', 'ɑ')))),\n ('ʊ', ('æ', ('ɑ', ('o', 'u')))),\n ('i', ('ɛ', ('ɑ', ('i', 'ɔ')))),\n ('i', ('æ', ('ɪ', ('u', 'ɑ')))),\n ('e', ('ə', ('ɪ', ('ɔ', 'ə')))),\n ('ɪ', ('ɑ', ('æ', ('ʊ', 'ə')))),\n ('u', ('ə', ('ɑ', ('æ', 'ɛ')))),\n ('u', ('ɪ', ('e', ('o', 'o')))),\n ('ɪ', ('ɔ', ('ə', ('o', 'o')))),\n ('e', ('ɪ', ('ɔ', ('i', 'ʊ')))),\n ('æ', ('i', ('u', ('u', 'ʊ')))),\n ('o', ('o', ('ɪ', ('æ', 'e')))),\n ('o', ('o', ('ə', ('ɑ', 'ɑ')))),\n ('æ', ('ʊ', ('i', ('i', 'æ')))),\n ('ə', ('ʊ', ('ɪ', ('o', 'ʊ')))),\n ('æ', ('æ', ('ɪ', ('u', 'u')))),\n ('ə', ('æ', ('u', ('e', 'ə')))),\n ('e', ('ɛ', ('ɑ', ('ʊ', 'ɛ')))),\n ('ɑ', ('e', ('æ', ('ʊ', 'i')))),\n ('ʊ', ('ɑ', ('o', ('o', 'æ')))),\n ('ɪ', ('i', ('ɛ', ('æ', 'ə')))),\n ('ɛ', ('æ', ('ɛ', ('ɔ', 'ɑ')))),\n ('æ', ('ə', ('ɔ', ('o', 'æ')))),\n ('ɛ', ('ɛ', ('ə', ('ɪ', 'i')))),\n ('ʊ', ('ə', ('ə', ('ɑ', 'æ')))),\n ('ɑ', ('i', ('ɛ', ('i', 'e')))),\n ('ɔ', ('u', ('u', ('æ', 'ɔ')))),\n ('ɑ', ('i', ('æ', ('i', 'u')))),\n ('e', ('ə', ('i', ('ɪ', 'ɔ')))),\n ('o', ('i', ('æ', ('u', 'ɑ')))),\n ('æ', ('ɪ', ('o', ('u', 'ʊ')))),\n ('o', ('ɔ', ('ɛ', ('ɛ', 'ɔ')))),\n ('ɑ', ('ɑ', ('ɔ', ('ɪ', 'æ')))),\n ('e', ('ɛ', ('ɪ', ('ɑ', 'ɛ')))),\n ('ʊ', ('æ', ('u', ('ɑ', 'ɪ')))),\n ('ʊ', ('u', ('ɑ', ('ʊ', 'i')))),\n ('i', ('o', ('ɪ', ('ɪ', 'u')))),\n ('i', ('i', ('ɛ', ('ə', 'o')))),\n ('ɔ', ('ɛ', ('ə', ('e', 'ɛ')))),\n ('ɔ', ('ə', ('ɪ', ('æ', 'e')))),\n ('ɪ', ('ɑ', ('o', ('ɛ', 'ɪ')))),\n ('ə', ('o', ('ɛ', ('æ', 'ɪ')))),\n ('ʊ', ('o', ('i', ('æ', 'o')))),\n ('i', ('u', ('ɔ', ('æ', 'ʊ')))),\n ('e', ('ɑ', ('i', ('ɑ', 'ɑ')))),\n ('ɑ', ('ɔ', ('ə', ('i', 'ʊ')))),\n ('i', ('ɪ', ('ʊ', ('o', 'u')))),\n ('ɪ', ('ɑ', ('ə', ('æ', 'ɑ')))),\n ('e', ('u', ('e', ('ʊ', 'ə')))),\n ('o', ('ʊ', ('ɛ', ('u', 'ʊ')))),\n ('ɪ', ('e', ('e', ('ɑ', 'o')))),\n ('u', ('i', ('ɔ', ('i', 'ɛ')))),\n ('æ', ('ə', ('i', ('æ', 'ɔ')))),\n ('æ', ('ɛ', ('ʊ', ('u', 'æ')))),\n ('æ', ('ɪ', ('ɑ', ('æ', 'u')))),\n ('ɪ', ('ə', ('u', ('ɔ', 'u')))),\n ('ɪ', ('u', ('ɛ', ('e', 'ɔ')))),\n ('æ', ('ɛ', ('o', ('ɑ', 'ɔ')))),\n ('æ', ('ə', ('ʊ', ('ɛ', 'ɑ')))),\n ('e', ('i', ('ɛ', ('o', 'u')))),\n ('ɔ', ('ɪ', ('ə', ('ʊ', 'o')))),\n ('o', ('ɛ', ('u', ('ʊ', 'ɔ')))),\n ('ɪ', ('ʊ', ('o', ('ɔ', 'ə')))),\n ('ɪ', ('o', ('e', ('ɔ', 'ə')))),\n ('æ', ('ə', ('ɪ', ('æ', 'i')))),\n ('ɑ', ('ɑ', ('e', ('ɔ', 'ʊ')))),\n ('æ', ('ɔ', ('o', ('ɔ', 'u')))),\n ('i', ('u', ('ɪ', ('u', 'æ')))),\n ('æ', ('æ', ('e', ('ɑ', 'i')))),\n ('ɑ', ('u', ('o', ('i', 'ɛ')))),\n ('e', ('i', ('u', ('ɔ', 'æ')))),\n ('ɑ', ('æ', ('ɔ', ('ɑ', 'u')))),\n ('e', ('i', ('ʊ', ('o', 'i')))),\n ('ɔ', ('ɪ', ('æ', ('u', 'i')))),\n ('ə', ('o', ('e', ('ʊ', 'ə')))),\n ('o', ('ɔ', ('u', ('o', 'ʊ')))),\n ('i', ('æ', ('i', ('ɪ', 'ʊ')))),\n ('æ', ('ɛ', ('e', ('e', 'e')))),\n ('e', ('ʊ', ('ɛ', ('ʊ', 'ʊ')))),\n ('ɛ', ('ɛ', ('o', ('ɪ', 'æ')))),\n ('ə', ('ɔ', ('u', ('ɪ', 'ɔ')))),\n ('ɛ', ('ɔ', ('u', ('ʊ', 'ə')))),\n ('ə', ('e', ('æ', ('i', 'i')))),\n ('ʊ', ('æ', ('i', ('e', 'ə')))),\n ('ʊ', ('ʊ', ('e', ('ɛ', 'æ')))),\n ('e', ('ɪ', ('ɔ', ('i', 'u')))),\n ('ɪ', ('ʊ', ('o', ('ɪ', 'i')))),\n ('o', ('ʊ', ('e', ('ɔ', 'ɑ')))),\n ('o', ('o', ('ə', ('ə', 'ə')))),\n ('ɛ', ('ɔ', ('u', ('ɛ', 'ə')))),\n ('o', ('ɛ', ('ɑ', ('ɪ', 'æ')))),\n ('ə', ('ɔ', ('æ', ('ɔ', 'u')))),\n ('ɔ', ('ɪ', ('ə', ('ʊ', 'ɑ')))),\n ('æ', ('ʊ', ('ɑ', ('æ', 'i')))),\n ('æ', ('u', ('ə', ('ɛ', 'ɛ')))),\n ('i', ('u', ('e', ('ɑ', 'ɛ')))),\n ('ɛ', ('ɛ', ('ɪ', ('ɑ', 'æ')))),\n ('æ', ('æ', ('e', ('ɔ', 'e')))),\n ('u', ('u', ('ɔ', ('æ', 'u')))),\n ('ɪ', ('ɛ', ('i', ('ʊ', 'e')))),\n ('o', ('i', ('ɔ', ('e', 'æ')))),\n ('ɑ', ('o', ('ɔ', ('o', 'ɔ')))),\n ('ɪ', ('ɑ', ('ɪ', ('u', 'æ')))),\n ('ɔ', ('ɛ', ('u', ('ɪ', 'æ')))),\n ('o', ('ɑ', ('ɔ', ('ɔ', 'ɔ')))),\n ('æ', ('ɔ', ('ʊ', ('u', 'ɑ')))),\n ('ɪ', ('u', ('ɪ', ('ɔ', 'ɪ')))),\n ('ʊ', ('æ', ('u', ('e', 'ɪ')))),\n ('ɔ', ('æ', ('ɑ', ('u', 'æ')))),\n ('ɔ', ('ɑ', ('e', ('i', 'ɛ')))),\n ('ə', ('i', ('ɔ', ('e', 'u')))),\n ('i', ('ɑ', ('ɔ', ('i', 'ɑ')))),\n ('ɑ', ('ɑ', ('ɪ', ('e', 'æ')))),\n ('u', ('ɔ', ('æ', ('ə', 'e')))),\n ('æ', ('ɛ', ('e', ('e', 'ʊ')))),\n ('æ', ('i', ('o', ('ɑ', 'ə')))),\n ('ʊ', ('u', ('ɛ', ('ʊ', 'ɛ')))),\n ('o', ('ɔ', ('o', ('i', 'o')))),\n ('ɛ', ('e', ('u', ('u', 'ə')))),\n ('o', ('ɔ', ('ə', ('ɪ', 'o')))),\n ('e', ('i', ('u', ('ʊ', 'ɑ')))),\n ('ɛ', ('ɑ', ('ɪ', ('ɑ', 'i')))),\n ('æ', ('u', ('æ', ('ə', 'e')))),\n ('ə', ('u', ('ɪ', ('ʊ', 'ɪ')))),\n ('ɛ', ('ɪ', ('ɛ', ('i', 'æ')))),\n ('ɔ', ('e', ('ɛ', ('e', 'e')))),\n ('e', ('ɔ', ('o', ('e', 'o')))),\n ('ə', ('ʊ', ('o', ('e', 'ɪ')))),\n ('i', ('ʊ', ('e', ('o', 'ʊ')))),\n ('ɛ', ('ɪ', ('ʊ', ('i', 'i')))),\n ('ə', ('o', ('e', ('e', 'ɪ')))),\n ('i', ('e', ('i', ('ɪ', 'e')))),\n ('i', ('ɪ', ('ɔ', ('ʊ', 'o')))),\n ('o', ('ə', ('o', ('ɔ', 'i')))),\n ('ɔ', ('ʊ', ('ə', ('ɛ', 'ɪ')))),\n ('ɑ', ('ɑ', ('æ', ('ɔ', 'ə')))),\n ('ɔ', ('ɔ', ('e', ('ɔ', 'i')))),\n ('æ', ('ə', ('u', ('ɔ', 'i')))),\n ('u', ('ʊ', ('i', ('ɛ', 'ɔ')))),\n ('ɑ', ('æ', ('o', ('e', 'u')))),\n ('ɛ', ('ɔ', ('o', ('ɪ', 'ɑ')))),\n ('ə', ('ɛ', ('i', ('o', 'ʊ')))),\n ('ə', ('i', ('ɪ', ('ɔ', 'i')))),\n ('ɛ', ('ɔ', ('u', ('e', 'ɪ')))),\n ('ɪ', ('u', ('ɪ', ('u', 'ɔ')))),\n ('e', ('ʊ', ('i', ('e', 'u')))),\n ('i', ('ɪ', ('ʊ', ('o', 'ə')))),\n ('u', ('o', ('ɑ', ('ɛ', 'ɛ')))),\n ('i', ('i', ('ʊ', ('ɪ', 'æ')))),\n ('ɪ', ('ɪ', ('o', ('ɪ', 'ə')))),\n ('ɛ', ('i', ('æ', ('u', 'u')))),\n ('ɑ', ('ʊ', ('ɛ', ('ə', 'e')))),\n ('ə', ('i', ('ʊ', ('æ', 'o')))),\n ('u', ('ɛ', ('o', ('ɪ', 'o')))),\n ('u', ('ə', ('u', ('e', 'ɛ')))),\n ('æ', ('ɪ', ('ɑ', ('æ', 'ə')))),\n ('o', ('i', ('u', ('e', 'o')))),\n ('ɑ', ('e', ('ɑ', ('ə', 'ɛ')))),\n ('e', ('e', ('ɪ', ('ɪ', 'ɪ')))),\n ('i', ('ɑ', ('ɛ', ('i', 'i')))),\n ('e', ('ɪ', ('ɪ', ('ə', 'ɔ')))),\n ('u', ('i', ('ɛ', ('ɔ', 'o')))),\n ('e', ('ɛ', ('æ', ('u', 'i')))),\n ('u', ('ɔ', ('ɔ', ('e', 'ɪ')))),\n ('ɪ', ('ə', ('ə', ('ɪ', 'ə')))),\n ('ɛ', ('ɛ', ('i', ('i', 'o')))),\n ('ɔ', ('ɔ', ('u', ('ɪ', 'ɑ')))),\n ('e', ('ʊ', ('e', ('æ', 'æ')))),\n ('ɪ', ('ɪ', ('æ', ('æ', 'ʊ')))),\n ('æ', ('ʊ', ('ɛ', ('o', 'ɪ')))),\n ('ɔ', ('i', ('ɛ', ('ɑ', 'ɪ')))),\n ('i', ('ɔ', ('ɔ', ('æ', 'æ')))),\n ('ɑ', ('i', ('e', ('ɛ', 'o')))),\n ('e', ('ə', ('ə', ('ɪ', 'ɪ')))),\n ('i', ('ə', ('ɛ', ('e', 'e')))),\n ('i', ('ə', ('æ', ('e', 'u')))),\n ('ɔ', ('i', ('ɑ', ('ɛ', 'o')))),\n ('ɪ', ('ɔ', ('o', ('ə', 'ʊ')))),\n ('ɪ', ('ɔ', ('u', ('ɪ', 'ɛ')))),\n ('æ', ('ɔ', ('i', ('i', 'ɪ')))),\n ('ɪ', ('ɪ', ('æ', ('ɛ', 'ʊ')))),\n ('o', ('æ', ('ɪ', ('ɛ', 'ɪ')))),\n ('i', ('ʊ', ('ɑ', ('ə', 'ə')))),\n ('ə', ('i', ('e', ('ɪ', 'ɑ')))),\n ...}\n\n\nWhile exponentiation is defined in terms of the application of a bunch of binary \\(\\times\\), resulting in pairs of an element of \\(A\\) with pairs of an element of \\(A\\) with pairs of…we can always treat \\(A^N\\) as a set of \\(N\\)-tuples because we can always map elements of \\(A^N\\) to \\(N\\)-tuples.\n\\[\\mathrm{flatten}_A(a) = \\begin{cases}\\langle a \\rangle & \\text{if } a \\in A\\\\\n\\langle x\\;:\\;x \\in \\mathrm{flatten}(y) \\land y \\in a \\rangle & \\text{otherwise}\\end{cases}\\]\n\ndef flatten(t, a):\n    if t in a:\n        return (t,)\n    else:\n        return tuple(x for y in t for x in flatten(y, a))\n \n{flatten(x, vowels) for x in exponentiate(vowels, 2)}\n\n{('e', 'e'),\n ('e', 'i'),\n ('e', 'o'),\n ('e', 'u'),\n ('e', 'æ'),\n ('e', 'ɑ'),\n ('e', 'ɔ'),\n ('e', 'ə'),\n ('e', 'ɛ'),\n ('e', 'ɪ'),\n ('e', 'ʊ'),\n ('i', 'e'),\n ('i', 'i'),\n ('i', 'o'),\n ('i', 'u'),\n ('i', 'æ'),\n ('i', 'ɑ'),\n ('i', 'ɔ'),\n ('i', 'ə'),\n ('i', 'ɛ'),\n ('i', 'ɪ'),\n ('i', 'ʊ'),\n ('o', 'e'),\n ('o', 'i'),\n ('o', 'o'),\n ('o', 'u'),\n ('o', 'æ'),\n ('o', 'ɑ'),\n ('o', 'ɔ'),\n ('o', 'ə'),\n ('o', 'ɛ'),\n ('o', 'ɪ'),\n ('o', 'ʊ'),\n ('u', 'e'),\n ('u', 'i'),\n ('u', 'o'),\n ('u', 'u'),\n ('u', 'æ'),\n ('u', 'ɑ'),\n ('u', 'ɔ'),\n ('u', 'ə'),\n ('u', 'ɛ'),\n ('u', 'ɪ'),\n ('u', 'ʊ'),\n ('æ', 'e'),\n ('æ', 'i'),\n ('æ', 'o'),\n ('æ', 'u'),\n ('æ', 'æ'),\n ('æ', 'ɑ'),\n ('æ', 'ɔ'),\n ('æ', 'ə'),\n ('æ', 'ɛ'),\n ('æ', 'ɪ'),\n ('æ', 'ʊ'),\n ('ɑ', 'e'),\n ('ɑ', 'i'),\n ('ɑ', 'o'),\n ('ɑ', 'u'),\n ('ɑ', 'æ'),\n ('ɑ', 'ɑ'),\n ('ɑ', 'ɔ'),\n ('ɑ', 'ə'),\n ('ɑ', 'ɛ'),\n ('ɑ', 'ɪ'),\n ('ɑ', 'ʊ'),\n ('ɔ', 'e'),\n ('ɔ', 'i'),\n ('ɔ', 'o'),\n ('ɔ', 'u'),\n ('ɔ', 'æ'),\n ('ɔ', 'ɑ'),\n ('ɔ', 'ɔ'),\n ('ɔ', 'ə'),\n ('ɔ', 'ɛ'),\n ('ɔ', 'ɪ'),\n ('ɔ', 'ʊ'),\n ('ə', 'e'),\n ('ə', 'i'),\n ('ə', 'o'),\n ('ə', 'u'),\n ('ə', 'æ'),\n ('ə', 'ɑ'),\n ('ə', 'ɔ'),\n ('ə', 'ə'),\n ('ə', 'ɛ'),\n ('ə', 'ɪ'),\n ('ə', 'ʊ'),\n ('ɛ', 'e'),\n ('ɛ', 'i'),\n ('ɛ', 'o'),\n ('ɛ', 'u'),\n ('ɛ', 'æ'),\n ('ɛ', 'ɑ'),\n ('ɛ', 'ɔ'),\n ('ɛ', 'ə'),\n ('ɛ', 'ɛ'),\n ('ɛ', 'ɪ'),\n ('ɛ', 'ʊ'),\n ('ɪ', 'e'),\n ('ɪ', 'i'),\n ('ɪ', 'o'),\n ('ɪ', 'u'),\n ('ɪ', 'æ'),\n ('ɪ', 'ɑ'),\n ('ɪ', 'ɔ'),\n ('ɪ', 'ə'),\n ('ɪ', 'ɛ'),\n ('ɪ', 'ɪ'),\n ('ɪ', 'ʊ'),\n ('ʊ', 'e'),\n ('ʊ', 'i'),\n ('ʊ', 'o'),\n ('ʊ', 'u'),\n ('ʊ', 'æ'),\n ('ʊ', 'ɑ'),\n ('ʊ', 'ɔ'),\n ('ʊ', 'ə'),\n ('ʊ', 'ɛ'),\n ('ʊ', 'ɪ'),\n ('ʊ', 'ʊ')}\n\n\nAnd we can always map back to the element of \\(A^N\\).\n\\[\\mathrm{reconstruct}_A(a) = \\begin{cases}a & \\text{if } a \\in A\\\\\n\\langle \\mathrm{head}(a), \\mathrm{reconstruct}_A(\\mathrm{tail}(a))\\rangle & \\text{otherwise}\\end{cases}\\]\nwhere \\(\\mathrm{head}\\) returns the first element of a tuple and \\(\\mathrm{tail}\\) returns the tuple with the first element removed."
  },
  {
    "objectID": "formal-and-practical-preliminaries/elementary-mathematical-concepts/relations-and-functions.html",
    "href": "formal-and-practical-preliminaries/elementary-mathematical-concepts/relations-and-functions.html",
    "title": "Relations and Functions",
    "section": "",
    "text": "A relation \\(R\\) is a subset of the product of sets \\(A_1 \\times A_2 \\times \\ldots \\times A_N\\). That means that elements of a relation are \\(N\\)-tuples. Including a particular tuple in the relation represents that the things in the tuple have that relationship to each other.\nFor example, the relation between vowel height \\(H = \\{\\mathrm{high}, \\mathrm{mid}, \\mathrm{low}\\}\\) and the English vowels \\(V = \\{\\mathrm{i}, \\mathrm{u}, ...\\}\\) that have that height and can be represented as a relation \\(R_\\text{height-of}\\).\n\nheight_of: set[tuple[str, str]] = {\n    ('high', 'i'),\n    ('high', 'ɪ'),\n    ('high', 'u'),\n    ('high', 'ʊ'),\n    ('mid', 'e'),\n    ('mid', 'ɛ'),\n    ('mid', 'o'),\n    ('mid', 'ɔ'),\n    ('mid', 'ə'),\n    ('low', 'ɑ'),\n    ('low', 'æ')\n}\n\n\\(R_\\text{height-of}\\) is a relation, since it is the subset of \\(H \\times V\\).\n\\[R_\\text{height-of} \\subseteq H \\times V\\]"
  },
  {
    "objectID": "formal-and-practical-preliminaries/elementary-mathematical-concepts/sequences.html",
    "href": "formal-and-practical-preliminaries/elementary-mathematical-concepts/sequences.html",
    "title": "Sequences",
    "section": "",
    "text": "A sequence \\(S\\) is a partial function from the natural numbers \\(\\mathbb{N}\\) to a set \\(\\Sigma\\).\n\\[\\mathbb{N} = \\{0, 1, 2, 3, \\ldots\\}\\] \\[\\Sigma = \\{\\text{e, i, o, u, æ, ɑ, ɔ, ə, ɛ, ɪ, ʊ, ɹ, d, t}\\}\\] \\[S = \\begin{Bmatrix}\n0 & \\rightarrow & \\text{d}\\\\\n1 & \\rightarrow & \\text{u}\\\\\n2 & \\rightarrow & \\text{d}\\\\\n\\end{Bmatrix}\\]\nThis definition admits of sequences with gaps in the natural numbers.\n\\[\\begin{Bmatrix}\n0 & \\rightarrow & \\text{d}\\\\\n1 & \\rightarrow & \\text{u}\\\\\n205 & \\rightarrow & \\text{d}\\\\\n\\end{Bmatrix}\\]\nWe will generally assume that our sequences map the first \\(|S^{-1}(\\Sigma)|\\) natural numbers to \\(\\Sigma\\), because these “gappy” sequences can always be mapped to one where \\(S^{-1}(\\Sigma) = \\{0, ..., |S^{-1}(\\Sigma)|-1\\}\\). But there are cases—one discussed below—where we don’t necessarily want our sequences to start at 0.\nWe often denote the \\(i^{th}\\) element of a sequence using a subscript rather than function notation.\n\\[s_i \\equiv S(i)\\]\nFunctions can be represented as sets of pairs and therefore sequences can be too.\n\\[S = \\{\\langle 0, \\text{d} \\rangle, \\langle 1, \\text{u} \\rangle, \\langle 2, \\text{d} \\rangle\\} \\subseteq \\mathbb{N}\\times \\Sigma\\]\nWe can also represent sequences as elements of \\(\\Sigma^{|S^{-1}(\\Sigma)|}\\).\n\\[\\mathrm{func2tuple}(S, i) = \\begin{cases}\\langle S(i), \\mathrm{func2tuple}(S, i+1) \\rangle & \\text{if } i + 1 \\in S^{-1}(\\Sigma) \\\\\nS(i) & \\text{otherwise}\n           \\end{cases}\\]\nAnd as we saw, we can always flatten these elements of \\(\\Sigma^{|S^{-1}(\\Sigma)|}\\) to \\(|S^{-1}(\\Sigma)|\\)-tuples. Because of this, we (often) implement sequences in Python using lists and tuples, though we can implement them using dicts as well.\n\nx = [\"d\", \"u\", \"d\"]\ny = (\"d\", \"u\", \"d\")\nz = {0: \"d\",\n     1: \"u\",\n     2: \"d\"}"
  },
  {
    "objectID": "formal-and-practical-preliminaries/elementary-mathematical-concepts/string-and-languages.html",
    "href": "formal-and-practical-preliminaries/elementary-mathematical-concepts/string-and-languages.html",
    "title": "Strings and Languages",
    "section": "",
    "text": "We build strings from some alphabet/lexicon \\(\\Sigma\\).\nStrings of length \\(N\\) are given by \\(\\Sigma^N\\) and the Kleene closure of \\(\\Sigma\\)—notated \\(\\Sigma^*\\)—gives us the set of all such sets.\n\\[\\Sigma^* \\equiv \\bigcup_{i\\in\\mathbb{N}} \\Sigma^i\\]\nHow do we deal with infinite sets like \\(\\Sigma^*\\) in Python? We use generators.\nTwo ways of building generators:\n\nyield statements in iteration\ngenerator comprehensions\n\n\nfrom itertools import product\n\ndef sigma_n(sigma: set, n: int):\n    sigma_repeated = [sigma]*n\n    return product(*sigma_repeated)\n\nsigma = [\"ɹ\", \"d\", \"u\"]\n\n[''.join(s) for s in sigma_n(sigma, 3)]\n\n['ɹɹɹ',\n 'ɹɹd',\n 'ɹɹu',\n 'ɹdɹ',\n 'ɹdd',\n 'ɹdu',\n 'ɹuɹ',\n 'ɹud',\n 'ɹuu',\n 'dɹɹ',\n 'dɹd',\n 'dɹu',\n 'ddɹ',\n 'ddd',\n 'ddu',\n 'duɹ',\n 'dud',\n 'duu',\n 'uɹɹ',\n 'uɹd',\n 'uɹu',\n 'udɹ',\n 'udd',\n 'udu',\n 'uuɹ',\n 'uud',\n 'uuu']\n\n\n\nN = natural_numbers()\n\nfor i in N:\n    if i &lt; 10:\n        print(i, len(list(sigma_n(sigma, i))))\n    else:\n        break\n\n0 1\n1 3\n2 9\n3 27\n4 81\n5 243\n6 729\n7 2187\n8 6561\n9 19683\n\n\n\nnext(N)\n\n11\n\n\n\nN = natural_numbers()\n\nsigma_star = (''.join(s) \n              for i in N \n              for s in sigma_n(sigma, i))\n\nfor s in sigma_star:\n    if len(s) &lt; 5:\n        print(s)\n    else:\n        break\n\n\nɹ\nd\nu\nɹɹ\nɹd\nɹu\ndɹ\ndd\ndu\nuɹ\nud\nuu\nɹɹɹ\nɹɹd\nɹɹu\nɹdɹ\nɹdd\nɹdu\nɹuɹ\nɹud\nɹuu\ndɹɹ\ndɹd\ndɹu\nddɹ\nddd\nddu\nduɹ\ndud\nduu\nuɹɹ\nuɹd\nuɹu\nudɹ\nudd\nudu\nuuɹ\nuud\nuuu\nɹɹɹɹ\nɹɹɹd\nɹɹɹu\nɹɹdɹ\nɹɹdd\nɹɹdu\nɹɹuɹ\nɹɹud\nɹɹuu\nɹdɹɹ\nɹdɹd\nɹdɹu\nɹddɹ\nɹddd\nɹddu\nɹduɹ\nɹdud\nɹduu\nɹuɹɹ\nɹuɹd\nɹuɹu\nɹudɹ\nɹudd\nɹudu\nɹuuɹ\nɹuud\nɹuuu\ndɹɹɹ\ndɹɹd\ndɹɹu\ndɹdɹ\ndɹdd\ndɹdu\ndɹuɹ\ndɹud\ndɹuu\nddɹɹ\nddɹd\nddɹu\ndddɹ\ndddd\ndddu\ndduɹ\nddud\ndduu\nduɹɹ\nduɹd\nduɹu\ndudɹ\ndudd\ndudu\nduuɹ\nduud\nduuu\nuɹɹɹ\nuɹɹd\nuɹɹu\nuɹdɹ\nuɹdd\nuɹdu\nuɹuɹ\nuɹud\nuɹuu\nudɹɹ\nudɹd\nudɹu\nuddɹ\nuddd\nuddu\nuduɹ\nudud\nuduu\nuuɹɹ\nuuɹd\nuuɹu\nuudɹ\nuudd\nuudu\nuuuɹ\nuuud\nuuuu\n\n\n\nnext(sigma_star)\n\n'ɹɹɹɹd'\n\n\nQuestion: How many strings are there in \\(\\Sigma^*\\) (assuming that \\(\\Sigma\\) is finite)? That is, what is \\(|\\Sigma^*| = |\\bigcup_{i\\in\\mathbb{N}} \\Sigma^i|\\)?\nIt must be at least at least as big as \\(|\\mathbb{N}|\\), since we have a nonempty set \\(\\Sigma^i\\) corresponding to each natural number \\(i\\).\nSurprisingly, \\(|\\Sigma^*|\\) turns out to be exactly as big as \\(|\\mathbb{N}|\\), which we can show by demonstrating that there is a bijection from \\(\\mathbb{N}\\) to \\(\\Sigma^*\\): for each \\(i \\in \\mathbb{N}\\) we can map \\(i\\) to a unique string in \\(\\Sigma^*\\) and for each string in \\(\\Sigma^*\\), we can map that string to a unique natural number \\(i\\). This bijection is a total function from \\(\\mathbb{N}\\) to \\(\\Sigma^*\\).\nThe trick is to notice that each \\(\\Sigma^i\\) is itself of finite cardinality. This means that we can always break off a chunk of the natural numbers to allocate for building a sequence of all strings in \\(\\Sigma^i\\). The idea is then that we can then stitch those sequences together to get a sequence of all \\(\\Sigma^*\\) that never repeats strings.\nYou can get an idea for how this works by enumerating the strings we generate from sigma_star.\n\nN = natural_numbers()\n\nsigma_star = (''.join(s) \n              for i in N \n              for s in sigma_n(sigma, i))\n\nfor j, s in enumerate(sigma_star):\n    if len(s) &lt; 5:\n        print(j, s)\n    else:\n        break\n\n0 \n1 ɹ\n2 d\n3 u\n4 ɹɹ\n5 ɹd\n6 ɹu\n7 dɹ\n8 dd\n9 du\n10 uɹ\n11 ud\n12 uu\n13 ɹɹɹ\n14 ɹɹd\n15 ɹɹu\n16 ɹdɹ\n17 ɹdd\n18 ɹdu\n19 ɹuɹ\n20 ɹud\n21 ɹuu\n22 dɹɹ\n23 dɹd\n24 dɹu\n25 ddɹ\n26 ddd\n27 ddu\n28 duɹ\n29 dud\n30 duu\n31 uɹɹ\n32 uɹd\n33 uɹu\n34 udɹ\n35 udd\n36 udu\n37 uuɹ\n38 uud\n39 uuu\n40 ɹɹɹɹ\n41 ɹɹɹd\n42 ɹɹɹu\n43 ɹɹdɹ\n44 ɹɹdd\n45 ɹɹdu\n46 ɹɹuɹ\n47 ɹɹud\n48 ɹɹuu\n49 ɹdɹɹ\n50 ɹdɹd\n51 ɹdɹu\n52 ɹddɹ\n53 ɹddd\n54 ɹddu\n55 ɹduɹ\n56 ɹdud\n57 ɹduu\n58 ɹuɹɹ\n59 ɹuɹd\n60 ɹuɹu\n61 ɹudɹ\n62 ɹudd\n63 ɹudu\n64 ɹuuɹ\n65 ɹuud\n66 ɹuuu\n67 dɹɹɹ\n68 dɹɹd\n69 dɹɹu\n70 dɹdɹ\n71 dɹdd\n72 dɹdu\n73 dɹuɹ\n74 dɹud\n75 dɹuu\n76 ddɹɹ\n77 ddɹd\n78 ddɹu\n79 dddɹ\n80 dddd\n81 dddu\n82 dduɹ\n83 ddud\n84 dduu\n85 duɹɹ\n86 duɹd\n87 duɹu\n88 dudɹ\n89 dudd\n90 dudu\n91 duuɹ\n92 duud\n93 duuu\n94 uɹɹɹ\n95 uɹɹd\n96 uɹɹu\n97 uɹdɹ\n98 uɹdd\n99 uɹdu\n100 uɹuɹ\n101 uɹud\n102 uɹuu\n103 udɹɹ\n104 udɹd\n105 udɹu\n106 uddɹ\n107 uddd\n108 uddu\n109 uduɹ\n110 udud\n111 uduu\n112 uuɹɹ\n113 uuɹd\n114 uuɹu\n115 uudɹ\n116 uudd\n117 uudu\n118 uuuɹ\n119 uuud\n120 uuuu\n\n\nSo for instance, in the above, you can think of the enumeration as setting aside \\(\\{1, 2, 3\\}\\) for the strings of length 1, \\(\\{4, \\ldots, 12\\}\\) for the strings of length 2, and so on.\nMore formally, we’ll set aside a chunk of natural numbers \\(N_i \\equiv \\left\\{\\left[\\max N_{i-1}\\right] + 1, ..., [\\max N_{i-1}] + |\\Sigma^i| + 1\\right\\}\\)–with \\(N_0 \\equiv \\{|\\Sigma^0| - 1\\} = \\{0\\}\\)–for each \\(\\Sigma^i\\). Note that this definition ensures that \\(N_i \\cap N_j = \\emptyset\\) for all \\(i \\neq j\\). That is, the chunk of natural numbers \\(N_i\\) we set aside for \\(\\Sigma^i\\) is disjoint from the chunk of natural numbers \\(N_j\\) we set aside for \\(\\Sigma^j\\) when \\(i \\neq j\\), and \\(|N_i| = |\\Sigma^i|\\).\nWe then use \\(N_i\\) to construct a sequence \\(S_i: N_i \\rightarrow \\Sigma ^i\\). Finally, we can stitch those sequences together by defining \\(S_*: \\mathbb{N} \\rightarrow \\Sigma^*\\) in terms of those \\(S_i\\)s along with a function \\(k: \\mathbb{N} \\rightarrow \\mathbb{N}\\) that satisfies \\(k^{-1}(\\{i\\}) = N_i\\) for all \\(i \\in \\mathbb{N}\\)–i.e. the preimage of \\(\\{i\\}\\) under \\(k\\) is \\(N_i\\).\n\\[S_*(n) = S_{k(n)}(n)\\]\nOne question you might have is how do we know how to build the sequence \\(S_i\\) for an arbitrary set of strings \\(\\Sigma^i\\) of length \\(i\\). As long as the alphabet/lexicon \\(\\Sigma\\) is finite, we can do this by imposing an order on \\(Sigma\\) itself, then use that to order sort the elements of \\(\\Sigma^i\\) in lexicographic order."
  },
  {
    "objectID": "formal-and-practical-preliminaries/regular-expressions/index.html",
    "href": "formal-and-practical-preliminaries/regular-expressions/index.html",
    "title": "Overview",
    "section": "",
    "text": "Reading\n\n\n\nJurafsky and Martin (2023, Ch. 2.1) on regular expressions.\n\n\nIn the last submodule, we defined the set of strings on an alphabet \\(\\Sigma\\) as:\n\\[\\Sigma^* = \\bigcup_{i=0}^\\infty \\Sigma^i\\]\nWe then defined a language \\(L\\) on \\(\\Sigma\\) to be some (possibly improper) subset of the set of strings:\n\\[L \\subseteq \\Sigma^*\\]\nThe set of all languages on \\(\\Sigma\\) is thus the powerset \\(2^{\\Sigma^*}\\) of the set of strings \\(\\Sigma^*\\).\nIn this submodule, we’re going to discuss one way that we can compactly describe (a subset of) the languages in \\(2^{\\Sigma^*}\\): regular expressions.\nRegular expressions are foundational both from an applied and from a scientific perspective. From an applied perspective, they allow us to effectively query and modify text in a compact programmatic way. From a scientific perspective, they provide a way of stating phonological grammars in an efficient way.\n\n\n\n\nReferences\n\nJurafsky, Daniel, and James H. Martin. 2023. Speech and Language Processing."
  },
  {
    "objectID": "formal-and-practical-preliminaries/text-normalization/index.html",
    "href": "formal-and-practical-preliminaries/text-normalization/index.html",
    "title": "Text Normalization",
    "section": "",
    "text": "Caution\n\n\n\nThis submodule will be available around February 5, 2024."
  },
  {
    "objectID": "formal-and-practical-preliminaries/working-with-annotated-corpora/index.html",
    "href": "formal-and-practical-preliminaries/working-with-annotated-corpora/index.html",
    "title": "Working with Annotated Corpora",
    "section": "",
    "text": "Caution\n\n\n\nThis submodule will be available around February 7, 2024."
  },
  {
    "objectID": "formal-and-practical-preliminaries/edit-distance-and-string-alignment/index.html",
    "href": "formal-and-practical-preliminaries/edit-distance-and-string-alignment/index.html",
    "title": "Edit Distance and String Alignment",
    "section": "",
    "text": "Caution\n\n\n\nThis submodule will be available around February 14, 2024."
  },
  {
    "objectID": "finite-state-models/index.html",
    "href": "finite-state-models/index.html",
    "title": "Overview",
    "section": "",
    "text": "Caution\n\n\n\nThis module will be available around February 21, 2024."
  },
  {
    "objectID": "context-free-models/index.html",
    "href": "context-free-models/index.html",
    "title": "Overview",
    "section": "",
    "text": "Caution\n\n\n\nThis module will be available around March 20, 2024."
  },
  {
    "objectID": "mildly-context-sensitive-models/index.html",
    "href": "mildly-context-sensitive-models/index.html",
    "title": "Overview",
    "section": "",
    "text": "Caution\n\n\n\nThis module will be available around April 15, 2024."
  },
  {
    "objectID": "formal-and-practical-preliminaries/elementary-mathematical-concepts/set-relations.html#supersets",
    "href": "formal-and-practical-preliminaries/elementary-mathematical-concepts/set-relations.html#supersets",
    "title": "Set relations",
    "section": "Supersets",
    "text": "Supersets\nThe dual of subset is superset.\n\\[\\{\\text{e, i, o, u, æ, ɑ, ɔ, ə, ɛ, ɪ, ʊ}\\} \\supseteq \\{\\text{i}\\}\\] \\[\\{\\text{e, i, o, u, æ, ɑ, ɔ, ə, ɛ, ɪ, ʊ}\\} \\supseteq \\{\\text{i, u, ɪ, ʊ}\\}\\]\nA set is an improper superset of itself\n\\[\\{\\text{e, i, o, u, æ, ɑ, ɔ, ə, ɛ, ɪ, ʊ}\\} \\supseteq \\{\\text{e, i, o, u, æ, ɑ, ɔ, ə, ɛ, ɪ, ʊ}\\}\\]\nAll other supersets of a set are proper supersets.\n\\[\\{\\text{e, i, o, u, æ, ɑ, ɔ, ə, ɛ, ɪ, ʊ}\\} \\supset \\{\\text{i}\\}\\]"
  },
  {
    "objectID": "formal-and-practical-preliminaries/elementary-mathematical-concepts/relations-and-functions.html#relations",
    "href": "formal-and-practical-preliminaries/elementary-mathematical-concepts/relations-and-functions.html#relations",
    "title": "Relations and Functions",
    "section": "",
    "text": "A relation \\(R\\) is a subset of the product of sets \\(A_1 \\times A_2 \\times \\ldots \\times A_N\\). That means that elements of a relation are \\(N\\)-tuples. Including a particular tuple in the relation represents that the things in the tuple have that relationship to each other.\nFor example, the relation between vowel height \\(H = \\{\\mathrm{high}, \\mathrm{mid}, \\mathrm{low}\\}\\) and the English vowels \\(V = \\{\\mathrm{i}, \\mathrm{u}, ...\\}\\) that have that height and can be represented as a relation \\(R_\\text{height-of}\\).\n\nheight_of: set[tuple[str, str]] = {\n    ('high', 'i'),\n    ('high', 'ɪ'),\n    ('high', 'u'),\n    ('high', 'ʊ'),\n    ('mid', 'e'),\n    ('mid', 'ɛ'),\n    ('mid', 'o'),\n    ('mid', 'ɔ'),\n    ('mid', 'ə'),\n    ('low', 'ɑ'),\n    ('low', 'æ')\n}\n\n\\(R_\\text{height-of}\\) is a relation, since it is the subset of \\(H \\times V\\).\n\\[R_\\text{height-of} \\subseteq H \\times V\\]"
  },
  {
    "objectID": "formal-and-practical-preliminaries/elementary-mathematical-concepts/relations-and-functions.html#functions",
    "href": "formal-and-practical-preliminaries/elementary-mathematical-concepts/relations-and-functions.html#functions",
    "title": "Relations and Functions",
    "section": "Functions",
    "text": "Functions\nFunctions–or more specifically, their graphs–are particular kinds of relations. The (graph of a) function \\(F \\subseteq X \\times Y\\) is a relation s.t. if \\(\\langle x, y \\rangle \\in F \\land \\langle x, z \\rangle \\in F\\), then \\(y = z\\).\nFor instance, the relation \\(R_\\text{height-of}\\) is not a function, but its inverse relation \\(R_\\text{height-of}^{-1} = R_\\text{has-height}\\) is.\n\\[R^{-1}_\\text{height-of} = R_\\text{has-height} = \\{\\langle y, x \\rangle \\;|\\; \\langle x, y \\rangle \\in R_\\text{height-of}\\}\\]\n\nhas_height: set[tuple[str, str]] = {(y, x) for x, y in height_of}\n\nhas_height\n\n{('e', 'mid'),\n ('i', 'high'),\n ('o', 'mid'),\n ('u', 'high'),\n ('æ', 'low'),\n ('ɑ', 'low'),\n ('ɔ', 'mid'),\n ('ə', 'mid'),\n ('ɛ', 'mid'),\n ('ɪ', 'high'),\n ('ʊ', 'high')}\n\n\nWe can check that it is a function by checking that:\n\nlen({x for x, _ in has_height}) == len(has_height)\n\nTrue\n\n\n\nlen({x for x, y in height_of}) == len(height_of)\n\nFalse\n\n\n\nPartiality\nA function is total if \\(X = \\{x \\;|\\; \\langle x, y \\rangle \\in F\\}\\); otherwise it is partial.\n\n\nDomain and codomain\nWe often think of functions as mapping inputs to outputs. The inputs of the function come from its domain and the outputs come from its codomain.\nFor instance, if we view \\(R_\\text{has-height}\\) as a function \\(f_\\text{has-height}\\), the domain of \\(f_\\text{has-height}\\) is the set of vowels \\(V\\) and the codomain is the set of heights \\(H\\). We will often express this using the following notation.\n\\[f_\\text{has-height}: V \\rightarrow H\\]\nSometimes we will express it using two other functions \\(\\text{dom}\\) and \\(\\text{cod}\\).\n\\[\\text{dom}(f_\\text{has-height}) = V\\] \\[\\text{cod}(f_\\text{has-height}) = H\\]\nFor a function \\(f\\) with graph \\(R\\), we denote each \\(y\\) s.t. \\(\\langle x, y \\rangle \\in F\\) as \\(f(x)\\).\n\n\nImage\nThe image of \\(W \\subseteq X\\) under \\(f\\) is \\(f(W) = \\{f(x) \\;|\\; x \\in W\\}\\).\n\nfrom typing import TypeVar\n\nT = TypeVar(\"T\")\n\ndef image(w: set[T], f: set[tuple[T, T]]) -&gt; set[T]:\n    return {y for x, y in f if x in w}\n\nimage({'i'}, has_height)\n\n{'high'}\n\n\n\nimage({'i', 'e'}, has_height)\n\n{'high', 'mid'}\n\n\n\n\nPreimage\nThe preimage of \\(Z \\subseteq Y\\) under \\(f\\) is \\(f^{-1}(Z) = \\{x \\;|\\; f(x) \\in Z\\}\\).\n\ndef preimage(z: set[T], f: set[tuple[T, T]]) -&gt; set[T]:\n    return {x for x, y in f if y in z}\n\npreimage({'high'}, has_height)\n\n{'i', 'u', 'ɪ', 'ʊ'}\n\n\n\nheights: set[str] = {h for h, _ in height_of}\n\npreimage(heights - {'low'}, has_height)\n\n{'e', 'i', 'o', 'u', 'ɔ', 'ə', 'ɛ', 'ɪ', 'ʊ'}\n\n\n\n\nRange\nThe range of \\(X\\) under \\(f\\) is the image of \\(X\\) under \\(f\\): \\(f(X)\\)."
  },
  {
    "objectID": "assignments/assignments-1-and-2.html",
    "href": "assignments/assignments-1-and-2.html",
    "title": "Assignments 1 and 2",
    "section": "",
    "text": "Assignment 1 will consist of Tasks 1-3 and Assignment 2 will consist of Tasks 4-8.\nIn these assignments, you will be implementing and testing a vowel harmony rule system for Turkish. Vowel harmony rule systems are intended to explain the fact that, in some languages, vowels in a word must have the same value on certain phonological features. Your job in this assignment will not be to derive the rule system itself. Rather, I’m going to give you a rule system to implement that works reasonably well, and we’ll ask where it fails."
  },
  {
    "objectID": "assignments/assignments-1-and-2.html#mathematical-objects",
    "href": "assignments/assignments-1-and-2.html#mathematical-objects",
    "title": "Assignments 1 and 2",
    "section": "Mathematical objects",
    "text": "Mathematical objects\nThroughout the assignments, I will be asking you to say what kind of mathematical object you are implementing in a particular task. The kind of answers you might give here are relation and function. If your response is function, it should be as specific as possible–e.g. the function may be partial or total. In addition to specifying partiality and totality, I’d also like you to specify whether a function is injective and/or surjective. An injective function is one where, if \\(f(x) = f(y)\\), then \\(x = y\\) for all \\(x\\) and \\(y\\). A surjective function is one where, if \\(f: X \\rightarrow Y\\), then \\(f(X) = Y\\)—i.e. the range of \\(f\\) is the same as its codomain; or said another way, the image of \\(X\\) under \\(f: X \\rightarrow Y\\) is \\(Y\\)."
  },
  {
    "objectID": "assignments/assignments-1-and-2.html#data",
    "href": "assignments/assignments-1-and-2.html#data",
    "title": "Assignments 1 and 2",
    "section": "Data",
    "text": "Data\nThis assignment uses Bruce Hayes’ phonological features spreadsheet—his FeaturesDoulosSIL.xls sheet, which I have converted into a UTF-8 encoded CSV for easier processing in Python. This file contains the equivalent of the IPA charts familiar to you from LIN110.\nYou do not need the full chart for this assignment, since we will only need access to four features–SYLLABIC, HIGH, FRONT, and ROUND–and the phones that Turkish has. We’ll work with the slightly altered version of the chart below, which only contains the features for these phones and maps 0 to -.\n\nfeatures = '''phone,syllabic,high,front,round\nɑ,+,-,-,-\nb,-,-,-,-\nd͡ʒ,-,-,-,-\nt͡ʃ,-,-,-,-\nd,-,-,-,-\ne,+,-,+,-\nf,-,-,-,-\nɟ,-,+,+,-\nj,-,+,+,-\nh,-,-,-,-\nɯ,+,+,-,-\ni,+,+,+,-\nʒ,-,-,-,-\nc,-,+,+,-\nl,-,-,-,-\nm,-,-,-,-\nn,-,-,-,-\no,+,-,-,+\nø,+,-,+,+\np,-,-,-,-\nɾ,-,-,-,-\ns,-,-,-,-\nʃ,-,-,-,-\nt,-,-,-,-\nu,+,+,-,+\ny,+,+,+,+\nv,-,-,-,-\nj,-,+,+,-\nz,-,-,-,-'''\n\nwith open('features.csv', 'w') as fout:\n    fout.write(features)\n\n\n%%bash\ncat features.csv\n\nphone,syllabic,high,front,round\nɑ,+,-,-,-\nb,-,-,-,-\nd͡ʒ,-,-,-,-\nt͡ʃ,-,-,-,-\nd,-,-,-,-\ne,+,-,+,-\nf,-,-,-,-\nɟ,-,+,+,-\nj,-,+,+,-\nh,-,-,-,-\nɯ,+,+,-,-\ni,+,+,+,-\nʒ,-,-,-,-\nc,-,+,+,-\nl,-,-,-,-\nm,-,-,-,-\nn,-,-,-,-\no,+,-,-,+\nø,+,-,+,+\np,-,-,-,-\nɾ,-,-,-,-\ns,-,-,-,-\nʃ,-,-,-,-\nt,-,-,-,-\nu,+,+,-,+\ny,+,+,+,+\nv,-,-,-,-\nj,-,+,+,-\nz,-,-,-,-\n\n\nIf you are interested in doing further work in computational phonology, you might also check out the panphon package, which provides various tools for working with featurizations of phones."
  },
  {
    "objectID": "assignments/assignments-1-and-2.html#definition",
    "href": "assignments/assignments-1-and-2.html#definition",
    "title": "Assignments 1 and 2",
    "section": "Definition",
    "text": "Definition\nTo represent (e.g. FRONT, ROUND, etc.) and feature values (+, -), we will use two Enum classes: Feature and FeatureValue. Using Enums here allows us to define the set of possible feature names and feature values and thereby constrain the values that can appear in feature valuations. This functionality is useful as an additional check on the correctness of our code–e.g. in the case that we get invalid feature names or feature values.\n\nfrom enum import Enum\n\nclass Feature(Enum):\n    SYLLABIC = \"syllabic\"\n    HIGH = \"high\"\n    FRONT = \"front\"\n    ROUND = \"round\"\n\n    def __repr__(self):\n        return self.value\n\n    def __str__(self):\n        return self.__repr__()\n\nclass FeatureValue(Enum):\n    PLUS = \"+\"\n    MINUS = \"-\"\n\n    def __repr__(self):\n        return self.value\n\n    def __str__(self):\n        return self.__repr__()\n\nTo represent the relationship between feature names and feature values—encoded in the rows of features.csv—we’ll be using FeatureValuation objects, which are just thin wrappers around a dictionary with feature names (e.g. FRONT, ROUND, etc.) as keys and feature values (+, -) as values.\nImportantly, note that, unlike dictionaries, FeatureValuations are hashable, since they implement the __hash__ magic method. Usually, we want hashables to be immutable–e.g. lists and sets are mutable and not hashable while tuples and frozensets are immutable and hashable–though python does not enforce this. In this case, I will demarcate that we want the core data of the feature valuation to be a private instance attribute FeatureValuation._valuation by prepending an underscore to the attribute name: when you see an underscore prepended like this, it is a convention that you should not modify its value from outside the object it is an attribute of. If you need to access the raw dictionary (and you will need to), you should use the FeatureValuation.valuation property.\nThe __hash__ magic method more specifically determines what the hash function from the python standard library outputs when applied to a FeatureValuation object. This output will be an integer that is used in determining how to identify when to instances of the class are the same for the purposes of uniquely identifying them within a collection—e.g. when an element of a set or a dict key.\nThe upshot for our purposes is that, if a class implements __hash__, its objects can be used as dictionary keys. The class also implements comparison between feature valuations: == (__eq__), &gt; (__gt__), &lt; (__lt__), &gt;= (__ge__), and &lt;= (__le__). This behavior will be very useful for some tasks.\n\nclass FeatureValuation:\n    '''A mapping from feature names to feature values\n    \n    Parameters\n    ----------\n    valuation\n        the feature valuation as a dictionary\n    '''\n    \n    def __init__(self, valuation: dict[str, str]):\n        self._valuation = {\n            Feature(f): FeatureValue(v) \n            for f, v in valuation.items()\n        }\n    \n    def __hash__(self) -&gt; int:\n        return hash(tuple(self._valuation.items()))\n    \n    def __getitem__(self, key: Feature) -&gt; FeatureValue:\n        return self._valuation[key]\n    \n    def __eq__(self, other: 'FeatureValuation') -&gt; bool:\n        self.__class__._check_type(other)\n        \n        return self._valuation == other._valuation\n    \n    def __lt__(self, other: 'FeatureValuation') -&gt; bool:\n        self.__class__._check_type(other)\n        \n        if set(self._valuation) &lt; set(other._valuation):\n            return all(other._valuation[k] == v \n                       for k, v in self._valuation.items())\n        else:\n            return False\n    \n    def __gt__(self, other: 'FeatureValuation') -&gt; bool:        \n        return other &lt; self\n\n    def __le__(self, other: 'FeatureValuation') -&gt; bool:\n        return self == other or self &lt; other\n    \n    def __ge__(self, other: 'FeatureValuation') -&gt; bool:\n        return self == other or self &gt; other\n\n    def __repr__(self):\n        return self._valuation.__repr__()\n\n    def __str__(self):\n        return self._valuation.__str__()\n    \n    @property\n    def valuation(self) -&gt; dict[Feature, FeatureValue]:\n        return dict(self._valuation) # makes a copy\n\n    @classmethod\n    def _check_type(cls, obj):\n        try:\n            assert isinstance(obj, cls)\n        except AssertionError:\n            raise ValueError(\n                'can only compute equality between'\n                ' two FeatureValuation objects'\n            )\n\nWe can construct a FeatureValuation by calling its __init__ magic method on a Dict[str, str].\n\nfv1 = FeatureValuation({'syllabic': '+', 'round': '+'})\nfv2 = FeatureValuation({'syllabic': '+', 'round': '+', 'high': '+'})\n\nAnd note that because FeatureValuations are hashable, we can use them as dictionary keys.\n\nv1 = {fv1: {'o', 'ø', 'u', 'y'}}\nv2 = {fv2: {'u', 'y'}}\n\nAnd because we have defined __eq__, __lt__, and __gt__, we can compare FeatureValuations. Make sure you understand what each comparison does. You will need at least one of these operations for the tasks below.\n\nfv1 == fv1, fv1 &lt; fv2, fv1 &gt; fv2\n\n(True, True, False)\n\n\nFinally, to show you that hash works and returns an integer:\n\nhash(fv2)\n\n-2436770590250344338"
  },
  {
    "objectID": "assignments/assignments-1-and-2.html#task-1",
    "href": "assignments/assignments-1-and-2.html#task-1",
    "title": "Assignments 1 and 2",
    "section": "Task 1",
    "text": "Task 1\nLines: 5\nDefine a class method from_csv in the PhonologicalFeatureChart1 class defined below. This method should take as input a string representation of the directory path fpath to features.csv and return a PhonologicalFeatureChart1 object. This object should have a dictionary-valued private attribute _phone_to_features with phones as keys and FeatureValuation objects as values.\n(Note: I’m calling this class PhonologicalFeatureChart1 so that we can subclass it later without a bunch of copying and pasting. This isn’t strictly necessary for subclassing purposes, since you could simply subclass an new version of PhonologicalFeatureChart with an old version; but it’s useful here so that, if you run the cells out of order, you know exactly which version of the class you’re working with.) I’ll do this for other classes below without comment.)\n\nclass PhonologicalFeatureChart1:\n    '''The phonological features of different phones'''\n\n    def __init__(self, phone_to_features: Dict[str, FeatureValuation]):\n        self._phone_to_features = phone_to_features\n\n    def __repr__(self):\n        return self._phone_to_features.__repr__()\n\n    def __str__(self):\n        return self._phone_to_features.__str__()\n\n    @classmethod\n    def from_csv(cls, fpath: str='features.csv') -&gt; 'PhonologicalFeatureChart1':\n        '''Load Hayes' phonological feature chart\n\n        Parameters\n        ----------\n        fpath\n            path to phonological feature chart as a csv\n        '''\n\n        # remove after implementing\n        raise NotImplementedError\n\n    def phone_to_features(self, phone: str) -&gt; FeatureValuation:\n        return self._phone_to_features[phone]\n\nWrite a test that checks for the correctness of from_csv by calling phone_to_features on some phone and making sure that it returns the correct feature valuation. (The fact that feature valuations implement __eq__ will be useful for this.) This (and all future) test should use standard Python exception handling facilities (try-except).\n\ntry:\n    phonological_feature_chart = PhonologicalFeatureChart1.from_csv()\nexcept NotImplementedError:\n    print(\"You still need to implement PhonologicalFeatureChart1.from_csv.\")\n\n# WRITE TESTS HERE\n\nYou still need to implement PhonologicalFeatureChart1.from_csv\n\n\nReferring to the set of feature as \\(F = \\{\\text{FRONT}, \\text{ROUND}, \\text{HIGH}, \\text{SYLLABIC}\\}\\) and the set of feature values as \\(V = \\{+, -\\}\\), explain what kind of mathematical object the feature valuations you just constructed are. If they are functions, say whether they are injective and/or surjective. Note that I am not asking about all possible feature valuations—just the ones constructed in from_csv.\nWRITE YOUR ANSWER HERE"
  },
  {
    "objectID": "assignments/assignments-1-and-2.html#task-2",
    "href": "assignments/assignments-1-and-2.html#task-2",
    "title": "Assignments 1 and 2",
    "section": "Task 2",
    "text": "Task 2\nLines: 2\nDefine an instance method phone_from_features in the PhonologicalFeatureChart2 class that takes as input a FeatureValuation object and returns the set of phones that match that feature valuation. Assume that feature valuations need not specify a feature value for all feature names—e.g. the following should still return something (namely, all the high vowels).\n\ntry:\n    chart = PhonologicalFeatureChart2.from_csv('features.csv')\n    valuation = FeatureValuation({'syllabic': '+', 'high': '+'})\n    chart.phone_from_features(valuation)\nexcept NameError:\n    print(\"You still need to define PhonologicalFeatureChart2.\")\n\nYou still need to define PhonologicalFeatureChart2\n\n\nWe will refer to valuations like this as partial feature valuations.\nNote that you need to return a set because some phones are not uniquely determined by the features in features.csv—e.g. all consonants (besides the semivowels) will be - on these features. Further, it may return an empty set, since some feature combinations do not show up in features.csv—e.g. [-SYLLABIC, +ROUND].\n\nclass PhonologicalFeatureChart2(PhonologicalFeatureChart1):\n    '''The phonological features of different phones'''\n\n    def phone_from_features(self, features: FeatureValuation) -&gt; set[str]:\n        '''The phones that have a particular feature valuation\n\n        Parameters\n        ----------\n        features\n            the feature valuation\n        '''\n\n        # remove after implementing\n        raise NotImplementedError\n\nWrite a test that checks for the correctness of phone_from_features. This test should check at least five cases: (i) one where a singleton set should be returned when a total feature valuation is input; (ii) one where an empty set should be returned when a total feature valuation is input; (iii) one where a non-empty, non-singleton set should be returned when a total feature valuation is input; (iv) one where an empty set should be returned when a partial feature valuation is input; and (v) one where a non-empty, non-singleton set should be returned when a partial feature valuation is input.\n\n# WRITE TESTS HERE\n\nExplain what kind of mathematical object phone_from_features implements and what kind of object a partial feature valuation is, referring to the set of phones as \\(P\\). There are two possible answers here depending on what you take the right side of the relation/function to be.\nWRITE YOUR ANSWER HERE"
  },
  {
    "objectID": "assignments/assignments-1-and-2.html#task-3",
    "href": "assignments/assignments-1-and-2.html#task-3",
    "title": "Assignments 1 and 2",
    "section": "Task 3",
    "text": "Task 3\nLines: 2\nUsing your phone_from_features method, define an instance method alter_features_of_phone in PhonologicalFeatureChart (our final version, so no number) that takes as input a phone and a (partial) feature valuation like valuation above. This function should return the set of phones that correspond to setting that phone’s features to the values listed in the feature valuation. For instance, if I passed this function the phone /u/ and the (partial) feature valuation [-ROUND], the function should return {/ɯ/}, but if I passed it /u/ and the feature valuation [-SYLLABIC, -HIGH, -LOW, -ROUND], it should return the set of consonants.\n\nclass PhonologicalFeatureChart(PhonologicalFeatureChart2):\n    '''The phonological features of different phones'''\n\n    def alter_features_of_phone(\n        self, phone: str, \n        features: FeatureValuation\n    ) -&gt; Set[str]:\n        '''The phones with features altered\n\n        Parameters\n        ----------\n        phone\n            the phone whose features we want to alter\n        features\n            the feature to alter\n        '''\n\n        # remove after implementing\n        raise NotImplementedError\n\nWrite a test that checks for the correctness of alter_features_of_phone. This test should check the same five kinds of cases that your test for Task 2 checked.\n\n# WRITE TESTS HERE\n\nExplain what kind of mathematical object alter_features_of_phone implements. There are two possible answers here depending on what you take the right side of the relation/function to be. Note that the left side of the relation is a tuple.\nWRITE YOUR ANSWER HERE"
  },
  {
    "objectID": "assignments/assignments-1-and-2.html#data-1",
    "href": "assignments/assignments-1-and-2.html#data-1",
    "title": "Assignments 1 and 2",
    "section": "Data",
    "text": "Data\nThe remainder of this assignment is based on data from the UniMorph project – specifically, Turkish UniMorph. The UniMorph project provides a schema for annotating word forms with their root form and the morphological features they express across languages, as well as annotated data for (currently) 168 languages. Take a look at the Turkish dataset. You’ll notice that it consists of three columns.\n    hamsi          hamsiler          N;NOM;PL\n    hamsi          hamsilere         N;DAT;PL\n    hamsi          hamsilerden       N;ABL;PL\n    hamsi          hamsinin          N;GEN;SG\n    hamsi          hamsiye           N;DAT;SG\n    hamsi          hamsiyi           N;ACC;SG\n    hamsi          hamsilerin        N;GEN;PL\n    hamsi          hamsileri         N;ACC;PL\n    hamsi          hamsiden          N;ABL;SG\n    hamsi          hamsilerde        N;LOC;PL\n    hamsi          hamside           N;LOC;SG\n    hamsi          hamsi             N;NOM;SG\nThe second column contains word forms; the first contains the root corresponding to that form; and the third corresponds to the part of speech of and morphological features expressed by that form, separated by ;.\nI have included some code below that should make working with these data easier by loading Turkish Unimorph as an instance of my custom Unimorph class, defined below. Before moving forward, read through this code to make sure you understand what turkish_unimorph is.\n\nfrom collections import defaultdict\n\nclass Unimorph:\n\n    def __init__(self, fpath, pos_filter=lambda x: True, root_filter=lambda x: True,\n                 word_filter=lambda x: True, feature_filter=lambda x: True,\n                 graph_to_phone_map=None):\n\n        self._graph_to_phone_map = graph_to_phone_map\n\n        self._pos_filter = pos_filter\n        self._root_filter = root_filter\n        self._word_filter = word_filter\n        self._feature_filter = feature_filter\n        \n        self._load_unimorph(fpath)\n\n    def __getitem__(self, key):\n        return self._pos_to_word_to_features[key]\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        try:\n            return next(self._gen)\n        except StopIteration:\n            self._initialize_gen()\n            raise\n\n    def _load_unimorph(self, fpath):\n        '''load unimorph file and convert graphs to ipa\n\n        Parameters\n        ----------\n        fpath : str\n            path to unimorph data\n        \n\n        Returns\n        -------\n        tuple(dict)\n        '''\n\n        pos_to_word_to_features = defaultdict(lambda:\n                                              defaultdict(lambda:\n                                                          defaultdict(set)))\n\n        with open(fpath) as f:\n            for line in f:\n                line_split = line.strip().split('\\t')\n\n                if len(line_split) != 3:\n                    continue\n\n                root, word, pos_features = line_split\n\n                pos_features_split = pos_features.split(';')\n\n                pos = pos_features_split[0]\n                features = set(pos_features_split[1:])\n\n                if self._graph_to_phone_map is not None:\n                    try:\n                        root = self._convert_graph_to_phone(root)\n                        word = self._convert_graph_to_phone(word)\n                    except KeyError:\n                        continue\n                else:\n                    root = tuple(root)\n                    word = tuple(word)\n                        \n\n                keep = self._pos_filter(pos)\n                keep &= self._root_filter(root)\n                keep &= self._word_filter(word)\n                keep &= self._feature_filter(features)\n\n                if keep:\n                    pos_to_word_to_features[pos][root][word] = features\n\n        # freeze dict so it is no longer a defaultdict\n        self._pos_to_word_to_features = dict(pos_to_word_to_features)\n\n        self._initialize_gen()\n\n    def _initialize_gen(self):\n        self._gen = ((pos, root, word, features)\n                     for pos, d1 in self._pos_to_word_to_features.items()\n                     for root, d2 in d1.items()\n                     for word, features in d2.items())\n        \n    def _convert_graph_to_phone(self, word):\n        '''map graphs to phones\n\n        Parameters\n        ----------\n        word : str\n            the word as a string of graphs\n\n        Returns\n        -------\n        str\n        '''\n\n        # this takes the last phone in the list\n        # it should maybe create a set of possible words\n        return tuple([self._graph_to_phone_map[graph][-1]\n                      for graph in word])\n\n\ngraph_to_phone_map = {'a': ['ɑ'],\n                      'b': ['b'],\n                      'c': ['d͡ʒ'],\n                      'ç': ['t͡ʃ'],\n                      'd': ['d'],\n                      'e': ['e'],\n                      'f': ['f'],\n                      'g': ['ɡ̟', 'ɟ'],\n                      'ğ': ['ː', '‿', 'j'],\n                      'h': ['h'],\n                      'ı': ['ɯ'],\n                      'i': ['i'],\n                      'j': ['ʒ'],\n                      'k': ['k', 'c'],\n                      'l': ['ɫ', 'l'],\n                      'm': ['m'],\n                      'n': ['n'],\n                      'o': ['o'],\n                      'ö': ['ø'],\n                      'p': ['p'],\n                      'r': ['ɾ'],\n                      's': ['s'],\n                      'ş': ['ʃ'],\n                      't': ['t'],\n                      'u': ['u'],\n                      'ü': ['y'],\n                      'v': ['v'],\n                      'y': ['j'],\n                      'z': ['z'],\n                      ' ': [' ']}\n\n\nimport requests\nfrom io import BytesIO\nfrom zipfile import ZipFile\n\nturkish_unimorph_url = 'https://github.com/unimorph/tur/archive/master.zip'\nturkish_unimorph_zip = requests.get(turkish_unimorph_url).content\n\nwith ZipFile(BytesIO(turkish_unimorph_zip)) as zf:\n    with zf.open('tur-master/tur') as f_in:\n        with open('tur.txt', 'w') as f_out:\n            f_out.write(f_in.read().decode())\n\n\nturkish_unimorph = Unimorph('tur.txt',\n                            pos_filter=lambda x: x == 'N',\n                            root_filter=lambda x: ' ' not in x,\n                            word_filter=lambda x: ' ' not in x,\n                            feature_filter=lambda x: x.issubset({'PL', 'GEN'}),\n                            graph_to_phone_map=graph_to_phone_map)\n\nThere are two important things to notice. First, words and roots are represented as tuples of strings, instead of strings. The reason for this is that (i) I map each root and word in Turkish Unimorph to a phonetic/phonemic representation using a fixed mapping from graphs to phones; and (ii) some phones are represented as digraphs or trigraphs in unicode (e.g. t͡ʃ), so if we mapped from strings of graphs to strings of phones, it would be difficult to recover which characters in a string are a single phone and which are part of a phone that unicode represents with multiple symbols. Second, my Unimorph class allows the user to pass filters to the constructor __init__. In the current case, I have set these filters so our Unimorph instance only contains plural and/or genitive nouns."
  },
  {
    "objectID": "assignments/assignments-1-and-2.html#task-4",
    "href": "assignments/assignments-1-and-2.html#task-4",
    "title": "Assignments 1 and 2",
    "section": "Task 4",
    "text": "Task 4\nLines: 24\nIn standard descriptions of Turkish, the vowel harmony rule system plays out on three features: height [+/-HIGH], frontness [+/-FRONT], and roundedness [+/-ROUND]. Roughly, if a vowel is high, it must match with the immediately previous vowel on both frontness and roundedness; and if it is not high and not round, it must match with the immediately previous vowel on frontness.\nUsing your alter_features_of_phone method, define a class TurkishVowelHarmony1 whose instances take as input a word and applies the vowel harmony rule system to it (implemented using the __call__ magic method). Pay special attention to the fact that this system only looks at the immediately previous vowel.\n\nString = tuple[str]\n\nclass TurkishVowelHarmony1:\n    '''The Turkish vowel harmony system'''\n    \n    def __call__(self, word: String) -&gt; String:\n        '''Apply the vowel harmony rule\n        \n        Parameters\n        ----------\n        word\n            the word to apply the vowel harmony rule to\n        '''\n        \n        # remove after implementing\n        raise NotImplementedError\n\nWrite a test that checks for the correctness of __call__. It should check at least six cases: (i) three randomly selected words found in Turkish Unimorph where the result of applying a TurkishVowelHarmony1 object to those words returns the same word back; and (ii) three randomly selected words found in Turkish Unimorph where it doesn’t.\n\n# WRITE TESTS HERE\n\nExplain what kind of mathematical object turkish_vowel_harmony implements, referring to the set of Turkish phones as \\(\\Sigma\\) and the set of strings over those phones as \\(\\Sigma^*\\). (Remember that \\(\\Sigma^* \\equiv \\bigcup_i^\\infty \\Sigma^i\\).)\nWRITE YOUR ANSWER HERE"
  },
  {
    "objectID": "assignments/assignments-1-and-2.html#task-5",
    "href": "assignments/assignments-1-and-2.html#task-5",
    "title": "Assignments 1 and 2",
    "section": "Task 5",
    "text": "Task 5\nLines: 1\nA disharmonic form is a root/word that does not obey the vowel harmony rule. Write an instance method disharmonic in TurkishVowelHarmony that maps a root or word to a boolean indicating whether or not it that root or word is disharmonic.\n\nclass TurkishVowelHarmony2(TurkishVowelHarmony1):\n    '''The Turkish vowel harmony system'''\n    \n    def disharmonic(self, word: Tuple[str]) -&gt; bool:\n        '''Whether the word is disharmonic\n        \n        Parameters\n        ----------\n        word\n            the word to check for disharmony\n        '''\n        \n        # remove after implementing\n        raise NotImplementedError\n\nWrite a test that checks for the correctness of disharmonic. It should check the same six cases you used to test __call__.\n\n# WRITE TESTS HERE"
  },
  {
    "objectID": "assignments/assignments-1-and-2.html#task-6",
    "href": "assignments/assignments-1-and-2.html#task-6",
    "title": "Assignments 1 and 2",
    "section": "Task 6",
    "text": "Task 6\nLines: 2\nUsing your disharmonic method, write another instance method proportion_disharmonic_roots to compute the proportion of roots that are disharmonic in Turkish Unimorph.\n\nclass TurkishVowelHarmony3(TurkishVowelHarmony2):\n    '''The Turkish vowel harmony system'''\n    \n    def proportion_disharmonic_roots(self, lexicon: Unimorph) -&gt; float:\n        '''The proportion of words that are disharmonic in the lexicon\n        \n        Parameters\n        ----------\n        lexicon\n            the Unimorph lexicon to check for disharmony\n        '''\n        \n        # remove after implementing\n        raise NotImplementedError"
  },
  {
    "objectID": "assignments/assignments-1-and-2.html#task-7",
    "href": "assignments/assignments-1-and-2.html#task-7",
    "title": "Assignments 1 and 2",
    "section": "Task 7",
    "text": "Task 7\nLines: 7\nUsing your disharmonic method, write an instance method xtab_root_word_harmony to cross-tabulate the proportion of words that are disharmonic against whether those words’ roots are disharmonic. The method should print that cross-tabulation as a \\(2 \\times 2\\) table with root (dis)harmony along the rows and word (dis)harmony along the columns.\n\nclass TurkishVowelHarmony4(TurkishVowelHarmony3):\n    '''The Turkish vowel harmony system'''\n    \n    def xtab_root_word_harmony(self, lexicon: Unimorph) -&gt; None:\n        '''Cross-tabulate word disharmony against root disharmony\n        \n        This should print (not return) a table represented as a list of lists:\n        \n                         | harmonic word | disharmonic word |\n                         ------------------------------------\n           harmonic root |               |                  |\n        disharmonic root |               |                  |\n        \n        Parameters\n        ----------\n        lexicon\n            the Unimorph lexicon to check for disharmony\n        '''\n        \n        # remove after implementing\n        raise NotImplementedError\n\nExplain the pattern that you see in this table.\nWRITE YOUR ANSWER HERE"
  },
  {
    "objectID": "assignments/assignments-1-and-2.html#task-8",
    "href": "assignments/assignments-1-and-2.html#task-8",
    "title": "Assignments 1 and 2",
    "section": "Task 8",
    "text": "Task 8\nLines: 1\nUsing your disharmonic function, write an instance method get_disharmonic to find all of the words of some category (e.g. N, V, etc.) with a particular set of features (e.g. {plural, genitive}, etc.). Use that method to find all the plural and/or genitive nouns with disharmonic roots. Note that I’ve prefiltered Turkish Unimorph to just the plural and genitive nouns, but this method should still work for arbitrary categories and morphological features.\n\nclass TurkishVowelHarmony(TurkishVowelHarmony4):\n    '''The Turkish vowel harmony system'''\n    \n    def get_disharmonic(self, \n                        lexicon: Unimorph, \n                        category: str,\n                        features: Set[str]) -&gt; Set[Tuple[str]]:\n        '''Find all of the words of some category with a particular set of features\n        \n        Parameters\n        ----------\n        lexicon\n            the Unimorph lexicon to check for disharmony\n        category\n            some category (e.g. \"N\", \"V\", etc.)\n        features\n            some set of features (e.g. {\"PL\", \"GEN\"}, etc.)\n        '''\n        \n        # remove after implementing\n        raise NotImplementedError\n\nExplain what pattern you see in the vowels of the plural and genitive affixes. (A prerequisite for answering this question is figuring out what the plural and genitive affixes are.)\nWRITE YOUR ANSWER HERE"
  },
  {
    "objectID": "formal-and-practical-preliminaries/regular-expressions/formal-definition.html",
    "href": "formal-and-practical-preliminaries/regular-expressions/formal-definition.html",
    "title": "Formal Definition",
    "section": "",
    "text": "Regular expressions themselves are strings. We formally define these strings recursively, starting with an alphabet \\(\\Sigma\\), a symbol for the empty string \\(\\epsilon\\), and a symbol for the empty set \\(\\emptyset\\). Let’s assume the alphabet is the set of English phonemes:\n\\[\\Sigma \\equiv \\{\\text{ɑ, æ, ʌ, ɔ, aʊ, aɪ, b, tʃ, d, ð,} \\ldots\\}\\]\n\\(\\rho\\) is a regular expression if and only if:\n\n\\(\\rho \\in \\Sigma \\cup \\{\\epsilon, \\emptyset\\}\\)\n\\(\\rho\\) is \\((\\rho_1 \\cup \\rho_2)\\) for some regular expressions \\(\\rho_1\\) and \\(\\rho_2\\)\n\\(\\rho\\) is \\((\\rho_1 \\circ \\rho_2)\\) for some regular expressions \\(\\rho_1\\) and \\(\\rho_2\\)\n\\(\\rho\\) is \\(\\rho_1^*\\) for some regular expression \\(\\rho_1\\)\n\nThus, given the \\(\\Sigma\\) above, the following are all regular expressions.\n\næ\nb\n(æ \\(\\cup\\) b)\n(æ \\(\\circ\\) b\\(^*\\))\n(æ \\(\\circ\\) b)\\(^*\\)\n((æ \\(\\circ\\) b) \\(\\cup\\) b)\n(æ \\(\\circ\\) (b \\(\\cup\\) b))\n\nThe following are not regular expressions.\n\næ \\(\\cup\\) b\næ \\(\\circ\\) b\\(^*\\)\næ \\(\\circ\\) b \\(\\cup\\) b\n\nAnother way of saying this is that the regular expressions on \\(\\Sigma\\) are a language on \\(\\Sigma \\cup\\{\\epsilon, \\emptyset, \\cup, \\circ, (, ), *\\}\\). Note that, based on the recursive definition above, the set of regular expressions is infinite. Thus, the regular expressions on \\(\\Sigma\\) are the first infinite language we’ve described (besides \\(\\Sigma^*\\) itself).\nWe can generate all the regular expressions given an alphabet. Note that because the set of regular expressions is infinite, we need to use a generator.\n\nfrom collections.abc import Iterable\n\ndef regular_expressions(sigma: set[str]) -&gt; Iterable[str]:\n    old_regex_set = frozenset(sigma | {'∅', '𝜖'})\n    \n    for rho in old_regex_set:\n        yield rho\n    \n    while True:\n        new_regex_set = set(old_regex_set)\n            \n        for rho in old_regex_set:\n            elem = rho+'*'\n            new_regex_set |= {elem}\n            yield elem\n            \n        for rho1 in old_regex_set:\n            for rho2 in old_regex_set:\n                elem = '('+rho1+' ∪ '+rho2+')'\n                new_regex_set |= {elem}\n                yield elem\n                \n        for rho1 in old_regex_set:\n            for rho2 in old_regex_set:\n                elem = '('+rho1+' ∘ '+rho2+')'\n                new_regex_set |= {elem}\n                yield elem\n                \n        old_regex_set = frozenset(new_regex_set)\n\n\nenglish_phonemes = {\"ɑ\", \"æ\", \"ə\", \"ʌ\", \"ɔ\", \"aʊ\", \"aɪ\", \"b\", \"tʃ\", \"d\", \"ð\", \"ɛ\", \n                    \"ɝ\", \"eɪ\", \"f\", \"g\", \"h\", \"ɪ\", \"i\", \"dʒ\", \"k\", \"l\", \"m\", \n                    \"n\", \"ŋ\", \"oʊ\", \"ɔɪ\", \"p\", \"ɹ\", \"s\", \"ʃ\", \"t\", \"θ\", \"ʊ\", \n                    \"u\", \"v\", \"w\", \"j\", \"z\", \"ʒ\"}\n\nfor i, r in enumerate(regular_expressions(english_phonemes)):\n    print(r)\n    \n    if i &gt; 100:\n      break\n\nh\ns\nb\nɑ\nf\n∅\nθ\nn\nu\np\ndʒ\nɔɪ\nɛ\n𝜖\neɪ\nŋ\noʊ\nz\ng\nʃ\ntʃ\nl\nɔ\næ\nə\nɝ\nɪ\nʒ\ni\nʊ\nj\nd\nɹ\nð\nt\nʌ\nv\nm\nk\naʊ\nw\naɪ\nh*\ns*\nb*\nɑ*\nf*\n∅*\nθ*\nn*\nu*\np*\ndʒ*\nɔɪ*\nɛ*\n𝜖*\neɪ*\nŋ*\noʊ*\nz*\ng*\nʃ*\ntʃ*\nl*\nɔ*\næ*\nə*\nɝ*\nɪ*\nʒ*\ni*\nʊ*\nj*\nd*\nɹ*\nð*\nt*\nʌ*\nv*\nm*\nk*\naʊ*\nw*\naɪ*\n(h ∪ h)\n(h ∪ s)\n(h ∪ b)\n(h ∪ ɑ)\n(h ∪ f)\n(h ∪ ∅)\n(h ∪ θ)\n(h ∪ n)\n(h ∪ u)\n(h ∪ p)\n(h ∪ dʒ)\n(h ∪ ɔɪ)\n(h ∪ ɛ)\n(h ∪ 𝜖)\n(h ∪ eɪ)\n(h ∪ ŋ)\n(h ∪ oʊ)\n(h ∪ z)\n\n\nRegular expressions (so defined) evaluate to sets of strings on \\(\\Sigma\\)–i.e. languages on \\(\\Sigma\\). Another way of thinking about this is that a regular expression on \\(\\Sigma\\) describes a language on \\(\\Sigma\\).\nWe can define this evaluation procedure formally as a function \\(\\text{eval}: R(\\Sigma) \\rightarrow 2^{\\Sigma^*}\\), where \\(R(\\Sigma)\\) is the set of regular expressions on \\(\\Sigma\\).\n\\(\\text{eval}(\\rho) = \\begin{cases}\\{\\} & \\text{if } \\rho = \\emptyset \\\\\\{\\_\\} & \\text{if } \\rho = \\epsilon \\\\ \\{\\rho\\} & \\text{if } \\rho \\in \\Sigma\\\\ \\text{eval}(\\rho_1) \\times \\text{eval}(\\rho_2) & \\text{if } \\rho = (\\rho_1 \\circ \\rho_2) \\\\ \\text{eval}(\\rho_1) \\cup \\text{eval}(\\rho_2) & \\text{if } \\rho = (\\rho_1 \\cup \\rho_2)\\\\ \\bigcup_{i = 0}^\\infty \\text{eval}(\\rho_1)^i & \\text{if } \\rho = \\rho_1^*\\\\ \\end{cases}\\)\nSo first, we’re going to want to have access to the regular expressions’ structure for the purposes of evaluating them. We could do this by using pyparsing or some hand-built parser to reconstruct the structure of each expression, but we may as well just build retain the structure while generating the expression.\n\ndef regular_expressions_structured(sigma):\n    old_regex_set = frozenset(sigma | {'∅', '𝜖'})\n    \n    for rho in old_regex_set:\n        yield rho\n    \n    while True:\n        new_regex_set = set(old_regex_set)\n            \n        for rho in old_regex_set:\n            elem = (rho, '*')\n            new_regex_set |= {elem}\n            yield elem\n            \n        for rho1 in old_regex_set:\n            for rho2 in old_regex_set:\n                elem = (rho1, '∪', rho2)\n                new_regex_set |= {elem}\n                yield elem\n                \n        for rho1 in old_regex_set:\n            for rho2 in old_regex_set:\n                elem = (rho1, '∘', rho2)\n                new_regex_set |= {elem}\n                yield elem\n                \n        old_regex_set = frozenset(new_regex_set)\n        \n\n\nfor i, r in enumerate(regular_expressions_structured({'ə', 'm'})):\n    print(r)\n    \n    if i &gt; 100:\n        break\n\nm\n∅\nə\n𝜖\n('m', '*')\n('∅', '*')\n('ə', '*')\n('𝜖', '*')\n('m', '∪', 'm')\n('m', '∪', '∅')\n('m', '∪', 'ə')\n('m', '∪', '𝜖')\n('∅', '∪', 'm')\n('∅', '∪', '∅')\n('∅', '∪', 'ə')\n('∅', '∪', '𝜖')\n('ə', '∪', 'm')\n('ə', '∪', '∅')\n('ə', '∪', 'ə')\n('ə', '∪', '𝜖')\n('𝜖', '∪', 'm')\n('𝜖', '∪', '∅')\n('𝜖', '∪', 'ə')\n('𝜖', '∪', '𝜖')\n('m', '∘', 'm')\n('m', '∘', '∅')\n('m', '∘', 'ə')\n('m', '∘', '𝜖')\n('∅', '∘', 'm')\n('∅', '∘', '∅')\n('∅', '∘', 'ə')\n('∅', '∘', '𝜖')\n('ə', '∘', 'm')\n('ə', '∘', '∅')\n('ə', '∘', 'ə')\n('ə', '∘', '𝜖')\n('𝜖', '∘', 'm')\n('𝜖', '∘', '∅')\n('𝜖', '∘', 'ə')\n('𝜖', '∘', '𝜖')\n(('𝜖', '∘', 'm'), '*')\n(('∅', '∘', 'ə'), '*')\n(('∅', '∪', 'm'), '*')\n(('ə', '∘', 'ə'), '*')\n('∅', '*')\n(('m', '∪', '𝜖'), '*')\n(('m', '∪', '∅'), '*')\n(('m', '∪', 'm'), '*')\n(('𝜖', '∪', 'ə'), '*')\n(('m', '∘', 'ə'), '*')\n(('∅', '∪', '∅'), '*')\n(('∅', '∘', '𝜖'), '*')\n(('∅', '∘', '∅'), '*')\n(('∅', '∘', 'm'), '*')\n('𝜖', '*')\n(('ə', '∘', '∅'), '*')\n(('m', '*'), '*')\n(('ə', '∘', '𝜖'), '*')\n(('ə', '*'), '*')\n(('ə', '∘', 'm'), '*')\n(('𝜖', '∪', '𝜖'), '*')\n(('∅', '∪', 'ə'), '*')\n(('ə', '∪', 'ə'), '*')\n(('𝜖', '∪', '∅'), '*')\n(('𝜖', '∘', 'ə'), '*')\n(('𝜖', '∪', 'm'), '*')\n(('𝜖', '*'), '*')\n('ə', '*')\n(('m', '∘', '𝜖'), '*')\n(('∅', '*'), '*')\n(('m', '∘', '∅'), '*')\n(('m', '∘', 'm'), '*')\n(('m', '∪', 'ə'), '*')\n('m', '*')\n(('ə', '∪', '𝜖'), '*')\n(('ə', '∪', '∅'), '*')\n(('𝜖', '∘', '𝜖'), '*')\n(('𝜖', '∘', '∅'), '*')\n(('ə', '∪', 'm'), '*')\n(('∅', '∪', '𝜖'), '*')\n(('𝜖', '∘', 'm'), '∪', ('𝜖', '∘', 'm'))\n(('𝜖', '∘', 'm'), '∪', ('∅', '∘', 'ə'))\n(('𝜖', '∘', 'm'), '∪', ('∅', '∪', 'm'))\n(('𝜖', '∘', 'm'), '∪', ('ə', '∘', 'ə'))\n(('𝜖', '∘', 'm'), '∪', '∅')\n(('𝜖', '∘', 'm'), '∪', ('m', '∪', '𝜖'))\n(('𝜖', '∘', 'm'), '∪', ('m', '∪', '∅'))\n(('𝜖', '∘', 'm'), '∪', ('m', '∪', 'm'))\n(('𝜖', '∘', 'm'), '∪', ('𝜖', '∪', 'ə'))\n(('𝜖', '∘', 'm'), '∪', ('m', '∘', 'ə'))\n(('𝜖', '∘', 'm'), '∪', ('∅', '∪', '∅'))\n(('𝜖', '∘', 'm'), '∪', ('∅', '∘', '𝜖'))\n(('𝜖', '∘', 'm'), '∪', ('∅', '∘', '∅'))\n(('𝜖', '∘', 'm'), '∪', ('∅', '∘', 'm'))\n(('𝜖', '∘', 'm'), '∪', '𝜖')\n(('𝜖', '∘', 'm'), '∪', ('ə', '∘', '∅'))\n(('𝜖', '∘', 'm'), '∪', ('m', '*'))\n(('𝜖', '∘', 'm'), '∪', ('ə', '∘', '𝜖'))\n(('𝜖', '∘', 'm'), '∪', ('ə', '*'))\n(('𝜖', '∘', 'm'), '∪', ('ə', '∘', 'm'))\n(('𝜖', '∘', 'm'), '∪', ('𝜖', '∪', '𝜖'))\n(('𝜖', '∘', 'm'), '∪', ('∅', '∪', 'ə'))\n\n\nNext, we can write a function that recursively evaluates a regular expression.\n\ndef evaluate_regular_expression(regex):\n    if regex == '∅':\n        return\n    \n    elif regex == '𝜖':\n        yield ''\n    \n    elif isinstance(regex, str):\n        yield regex\n    \n    elif regex[1] == '*':\n        i = 0\n        while True:\n            for s in evaluate_regular_expression(regex[0]):\n                yield s*i\n            \n            i += 1\n            \n    elif regex[1] == '∪':\n        for s1 in evaluate_regular_expression(regex[0]):\n            yield s1\n            \n        for s2 in evaluate_regular_expression(regex[2]):\n            yield s2\n            \n    elif regex[1] == '∘':\n        for s1 in evaluate_regular_expression(regex[0]):\n            for s2 in evaluate_regular_expression(regex[2]):\n                yield s1 + s2\n\n\nfor s in evaluate_regular_expression('ə'):\n    print(s)\n\nə\n\n\n\nfor s in evaluate_regular_expression(('ə', '∪', 'm')):\n    print(s)\n\nə\nm\n\n\n\nfor s in evaluate_regular_expression(('ə', '∘', 'm')):\n    print(s)\n\nəm\n\n\n\nfor s in evaluate_regular_expression(('ə', '∘', ('m', '∪', 'g'))):\n    print(s)\n\nəm\nəg\n\n\n\nfor i, s in enumerate(evaluate_regular_expression(('ə', '*'))):\n    print(s)\n    \n    if i &gt; 10:\n        break\n\n\nə\nəə\nəəə\nəəəə\nəəəəə\nəəəəəə\nəəəəəəə\nəəəəəəəə\nəəəəəəəəə\nəəəəəəəəəə\nəəəəəəəəəəə\n\n\n\nfor i, s in enumerate(evaluate_regular_expression((('ə', '∪', 'm'), '*'))):\n    print(s)\n    \n    if i &gt; 10:\n        break\n\n\n\nə\nm\nəə\nmm\nəəə\nmmm\nəəəə\nmmmm\nəəəəə\nmmmmm"
  },
  {
    "objectID": "formal-and-practical-preliminaries/regular-expressions/using-regular-expressions.html",
    "href": "formal-and-practical-preliminaries/regular-expressions/using-regular-expressions.html",
    "title": "Groups and Greediness",
    "section": "",
    "text": "Caution\n\n\n\nThis subsubmodule will be available around Monday, February 5, 2024."
  },
  {
    "objectID": "formal-and-practical-preliminaries/regular-expressions/groups-and-greediness.html",
    "href": "formal-and-practical-preliminaries/regular-expressions/groups-and-greediness.html",
    "title": "Groups and Greediness",
    "section": "",
    "text": "One of the major uses for regular expressions is for extracting substrings from a string. This can be done with groups. For instance, suppose I want all of stems that have the morpheme with the form /ʃən/.\nLoad IPA representation of CMU Pronouncing Dictionary\nwith open(\"cmudict-ipa\") as f:\n    entries: list[tuple[str, str]] = [\n        l.strip().split(\",\") for l in f\n    ]\n    entries: dict[str, list[str]] = {\n        w: ipa.split() for w, ipa in entries\n    }\nimport re\n\nregex_ʃən = '(.+)ʃən'\n\nn_matches = 0\n\nfor w, ipa in entries.items():\n    if re.fullmatch(regex_ʃən, \"\".join(ipa)):\n        if n_matches &lt; 30:\n            n_matches += 1\n            print(\"\".join(ipa), re.findall(regex_ʃən, \"\".join(ipa)), f\"({w})\")\n        else:\n            print(\"...\")\n            break\n\nəbɹivieɪʃən ['əbɹivieɪ'] (abbreviation)\næbdɪkeɪʃən ['æbdɪkeɪ'] (abdication)\næbdəkʃən ['æbdək'] (abduction)\nəbdəkʃən ['əbdək'] (abduction(1))\næbɝeɪʃən ['æbɝeɪ'] (aberration)\nəbleɪʃən ['əbleɪ'] (ablation)\nəbluʃən ['əblu'] (ablution)\næbnɛgeɪʃən ['æbnɛgeɪ'] (abnegation)\næbəlɪʃən ['æbəlɪ'] (abolition)\nəbɑməneɪʃən ['əbɑməneɪ'] (abomination)\nəbɔɹʃən ['əbɔɹ'] (abortion)\næbɹəgeɪʃən ['æbɹəgeɪ'] (abrogation)\næbsəluʃən ['æbsəlu'] (absolution)\nəbzɔɹpʃən ['əbzɔɹp'] (absorption)\nəbsɔɹpʃən ['əbsɔɹp'] (absorption(1))\nəbstɛntʃən ['əbstɛnt'] (abstention)\næbstɛntʃən ['æbstɛnt'] (abstention(1))\næbstɹækʃən ['æbstɹæk'] (abstraction)\nækədəmɪʃən ['ækədəmɪ'] (academician)\næksɛlɝeɪʃən ['æksɛlɝeɪ'] (acceleration)\nəksɛʃən ['əksɛ'] (accession)\nækləmeɪʃən ['ækləmeɪ'] (acclamation)\nækləmeɪʃən ['ækləmeɪ'] (acclimation)\nəkɑmədeɪʃən ['əkɑmədeɪ'] (accommodation)\nəkɹɛdəteɪʃən ['əkɹɛdəteɪ'] (accreditation)\nəkɹiʃən ['əkɹi'] (accretion)\nəkjumjəleɪʃən ['əkjumjəleɪ'] (accumulation)\nækjəzeɪʃən ['ækjəzeɪ'] (accusation)\nækjuzeɪʃən ['ækjuzeɪ'] (accusation(1))\nəsɪdəfəkeɪʃən ['əsɪdəfəkeɪ'] (acidification)\n...\nThis works to some extent, but notice that it will capture cases where /ʃən/ is not a morpheme. For instance, the word passion will get matched. It will also return the wrong stem when the morpheme is realized as /eɪʃən/, such as accreditation.\nre.findall(regex_ʃən, \"\".join(entries[\"passion\"])), re.findall(regex_ʃən, \"\".join(entries[\"accreditation\"]))\n\n(['pæ'], ['əkɹɛdəteɪ'])\nTo handle the second, we might look for /eɪʃən/ and /ʃən/. We can use the quantifier ? to say that /eɪ/ is optional. Because it is a digraph, we need to surround it with parentheses.\nregex_ʃən = '(.+)(eɪ)?ʃən'\n\nn_matches = 0\n\nfor w, ipa in entries.items():\n    if re.fullmatch(regex_ʃən, \"\".join(ipa)):\n        if n_matches &lt; 30:\n            n_matches += 1\n            print(\"\".join(ipa), re.findall(regex_ʃən, \"\".join(ipa)), f\"({w})\")\n        else:\n            print(\"...\")\n            break\n\nəbɹivieɪʃən [('əbɹivieɪ', '')] (abbreviation)\næbdɪkeɪʃən [('æbdɪkeɪ', '')] (abdication)\næbdəkʃən [('æbdək', '')] (abduction)\nəbdəkʃən [('əbdək', '')] (abduction(1))\næbɝeɪʃən [('æbɝeɪ', '')] (aberration)\nəbleɪʃən [('əbleɪ', '')] (ablation)\nəbluʃən [('əblu', '')] (ablution)\næbnɛgeɪʃən [('æbnɛgeɪ', '')] (abnegation)\næbəlɪʃən [('æbəlɪ', '')] (abolition)\nəbɑməneɪʃən [('əbɑməneɪ', '')] (abomination)\nəbɔɹʃən [('əbɔɹ', '')] (abortion)\næbɹəgeɪʃən [('æbɹəgeɪ', '')] (abrogation)\næbsəluʃən [('æbsəlu', '')] (absolution)\nəbzɔɹpʃən [('əbzɔɹp', '')] (absorption)\nəbsɔɹpʃən [('əbsɔɹp', '')] (absorption(1))\nəbstɛntʃən [('əbstɛnt', '')] (abstention)\næbstɛntʃən [('æbstɛnt', '')] (abstention(1))\næbstɹækʃən [('æbstɹæk', '')] (abstraction)\nækədəmɪʃən [('ækədəmɪ', '')] (academician)\næksɛlɝeɪʃən [('æksɛlɝeɪ', '')] (acceleration)\nəksɛʃən [('əksɛ', '')] (accession)\nækləmeɪʃən [('ækləmeɪ', '')] (acclamation)\nækləmeɪʃən [('ækləmeɪ', '')] (acclimation)\nəkɑmədeɪʃən [('əkɑmədeɪ', '')] (accommodation)\nəkɹɛdəteɪʃən [('əkɹɛdəteɪ', '')] (accreditation)\nəkɹiʃən [('əkɹi', '')] (accretion)\nəkjumjəleɪʃən [('əkjumjəleɪ', '')] (accumulation)\nækjəzeɪʃən [('ækjəzeɪ', '')] (accusation)\nækjuzeɪʃən [('ækjuzeɪ', '')] (accusation(1))\nəsɪdəfəkeɪʃən [('əsɪdəfəkeɪ', '')] (acidification)\n...\nThe problem is that this makes Python think we want to capture it. So what we need is a non-capturing group, which we get by putting ?: after the open parenthesis.\nregex_ʃən = '(.+)(?:eɪ)?ʃən'\n\nn_matches = 0\n\nfor w, ipa in entries.items():\n    if re.fullmatch(regex_ʃən, \"\".join(ipa)):\n        if n_matches &lt; 30:\n            n_matches += 1\n            print(\"\".join(ipa), re.findall(regex_ʃən, \"\".join(ipa)), f\"({w})\")\n        else:\n            print(\"...\")\n            break\n\nəbɹivieɪʃən ['əbɹivieɪ'] (abbreviation)\næbdɪkeɪʃən ['æbdɪkeɪ'] (abdication)\næbdəkʃən ['æbdək'] (abduction)\nəbdəkʃən ['əbdək'] (abduction(1))\næbɝeɪʃən ['æbɝeɪ'] (aberration)\nəbleɪʃən ['əbleɪ'] (ablation)\nəbluʃən ['əblu'] (ablution)\næbnɛgeɪʃən ['æbnɛgeɪ'] (abnegation)\næbəlɪʃən ['æbəlɪ'] (abolition)\nəbɑməneɪʃən ['əbɑməneɪ'] (abomination)\nəbɔɹʃən ['əbɔɹ'] (abortion)\næbɹəgeɪʃən ['æbɹəgeɪ'] (abrogation)\næbsəluʃən ['æbsəlu'] (absolution)\nəbzɔɹpʃən ['əbzɔɹp'] (absorption)\nəbsɔɹpʃən ['əbsɔɹp'] (absorption(1))\nəbstɛntʃən ['əbstɛnt'] (abstention)\næbstɛntʃən ['æbstɛnt'] (abstention(1))\næbstɹækʃən ['æbstɹæk'] (abstraction)\nækədəmɪʃən ['ækədəmɪ'] (academician)\næksɛlɝeɪʃən ['æksɛlɝeɪ'] (acceleration)\nəksɛʃən ['əksɛ'] (accession)\nækləmeɪʃən ['ækləmeɪ'] (acclamation)\nækləmeɪʃən ['ækləmeɪ'] (acclimation)\nəkɑmədeɪʃən ['əkɑmədeɪ'] (accommodation)\nəkɹɛdəteɪʃən ['əkɹɛdəteɪ'] (accreditation)\nəkɹiʃən ['əkɹi'] (accretion)\nəkjumjəleɪʃən ['əkjumjəleɪ'] (accumulation)\nækjəzeɪʃən ['ækjəzeɪ'] (accusation)\nækjuzeɪʃən ['ækjuzeɪ'] (accusation(1))\nəsɪdəfəkeɪʃən ['əsɪdəfəkeɪ'] (acidification)\n...\nIt still seems to be capturing /eɪ/ in accreditation. What gives? The reason this is happening is that quantifiers like + are greedy by default. That means they will match as much as they can. And because /eɪ/ is optional, (.+) can match it.\nTo make sure it doesn’t match it if it doesn’t need to, we can make the quantifier non-greedy by appending a ?.\nregex_ʃən = '(.+?)(?:eɪ)?ʃən'\n\nn_matches = 0\n\nfor w, ipa in entries.items():\n    if re.fullmatch(regex_ʃən, \"\".join(ipa)):\n        if n_matches &lt; 30:\n            n_matches += 1\n            print(\"\".join(ipa), re.findall(regex_ʃən, \"\".join(ipa)), f\"({w})\")\n        else:\n            print(\"...\")\n            break\n\nəbɹivieɪʃən ['əbɹivi'] (abbreviation)\næbdɪkeɪʃən ['æbdɪk'] (abdication)\næbdəkʃən ['æbdək'] (abduction)\nəbdəkʃən ['əbdək'] (abduction(1))\næbɝeɪʃən ['æbɝ'] (aberration)\nəbleɪʃən ['əbl'] (ablation)\nəbluʃən ['əblu'] (ablution)\næbnɛgeɪʃən ['æbnɛg'] (abnegation)\næbəlɪʃən ['æbəlɪ'] (abolition)\nəbɑməneɪʃən ['əbɑmən'] (abomination)\nəbɔɹʃən ['əbɔɹ'] (abortion)\næbɹəgeɪʃən ['æbɹəg'] (abrogation)\næbsəluʃən ['æbsəlu'] (absolution)\nəbzɔɹpʃən ['əbzɔɹp'] (absorption)\nəbsɔɹpʃən ['əbsɔɹp'] (absorption(1))\nəbstɛntʃən ['əbstɛnt'] (abstention)\næbstɛntʃən ['æbstɛnt'] (abstention(1))\næbstɹækʃən ['æbstɹæk'] (abstraction)\nækədəmɪʃən ['ækədəmɪ'] (academician)\næksɛlɝeɪʃən ['æksɛlɝ'] (acceleration)\nəksɛʃən ['əksɛ'] (accession)\nækləmeɪʃən ['ækləm'] (acclamation)\nækləmeɪʃən ['ækləm'] (acclimation)\nəkɑmədeɪʃən ['əkɑməd'] (accommodation)\nəkɹɛdəteɪʃən ['əkɹɛdət'] (accreditation)\nəkɹiʃən ['əkɹi'] (accretion)\nəkjumjəleɪʃən ['əkjumjəl'] (accumulation)\nækjəzeɪʃən ['ækjəz'] (accusation)\nækjuzeɪʃən ['ækjuz'] (accusation(1))\nəsɪdəfəkeɪʃən ['əsɪdəfək'] (acidification)\n...\nOkay. So how do we deal with cases where /ʃən/ is not a morpheme? One thing we can do is to look for stems that show up without /ʃən/. This will exclude passion, since /pæ/ is not a word.\nregex_ʃən = '(.+?)(?:eɪ)?ʃən'\n\nn_matches = 0\nseen = set()\n\nfor w1, ipa1 in entries.items():\n    possible_morpheme = re.findall(regex_ʃən, \"\".join(ipa1))\n    if possible_morpheme:\n        for w2, ipa2 in entries.items():\n            if re.fullmatch(possible_morpheme[0], \"\".join(ipa2)):\n                if n_matches &lt; 20 and \"\".join(ipa2) not in seen:\n                    n_matches += 1\n                    seen |= {\"\".join(ipa2)}\n                    print(\"\".join(ipa2), f\"({w2})\", \"+\", \"ʃən\", \"=\", \"\".join(ipa1), f\"({w1})\")\n                else:\n                    break\n\n    if n_matches &gt;= 20:   \n        print(\"...\")\n        break\n\nəbɔɹ (abor) + ʃən = əbɔɹʃən (abortion)\nəkɹi (acree) + ʃən = əkɹiʃən (accretion)\næk (ack) + ʃən = ækʃən (action)\nædɝ (adder) + ʃən = ædɝeɪʃən (adoration)\nædʒəl (agile) + ʃən = ædʒəleɪʃən (adulation)\neɪliən (alien) + ʃən = eɪliəneɪʃən (alienation)\nɔltɝ (altar) + ʃən = ɔltɝeɪʃən (alteration)\nəmælgəm (amalgam) + ʃən = əmælgəmeɪʃən (amalgamation)\neɪnt (ain't) + ʃən = eɪntʃənt (ancient)\neɪn (aine) + ʃən = eɪnʃənt (ancient(1))\nænəm (annum) + ʃən = ænəmeɪʃən (animation)\nænɛks (annex) + ʃən = ænɛkseɪʃən (annexation)\næn (ahn) + ʃən = ænʃən (anshan)\næpəl (appel) + ʃən = æpəleɪʃən (appalachian(1))\næspɝ (asper) + ʃən = æspɝeɪʃən (aspiration)\nəsæsən (assassin) + ʃən = əsæsəneɪʃən (assassination)\nɑk (och) + ʃən = ɑkʃən (auction)\nɔtəm (autumn) + ʃən = ɔtəmeɪʃən (automation)\neɪvi (av) + ʃən = eɪvieɪʃən (aviacion)\nbæt (bat) + ʃən = bætʃənd (bachand)\n...\nAn issue here is that /ʃən/ doesn’t simply get appended to a stem. There is an additional phonological process that deletes a portion of that stem–e.g. /æbstɹækt/ + /ʃən/ is /æbstɹækʃən/, not /æbstɹæktʃən/. So we need to consider cases where a final consonant–usually a t–was deleted. But we need to make sure we do so only when the morpheme wasn’t realized as /eɪʃən/, so we need to go back to capturing it.\nregex_ʃən = '(.+?)(eɪ)?ʃən'\n\nn_matches = 0\n\nseen = set()\n\nfor w1, ipa1 in entries.items():\n    possible_morpheme = re.findall(regex_ʃən, \"\".join(ipa1))\n    if possible_morpheme:\n        for w2, ipa2 in entries.items():\n            if possible_morpheme[0][1]:\n                regex_stem = possible_morpheme[0][0]\n            else:\n                regex_stem = possible_morpheme[0][0] + \"t\"\n            \n            if re.fullmatch(regex_stem, \"\".join(ipa2)):\n                if n_matches &lt; 20 and \"\".join(ipa2) not in seen:\n                    n_matches += 1\n                    seen |= {\"\".join(ipa2)}\n                    print(\"\".join(ipa2), f\"({w2})\", \"+\", \"ʃən\", \"=\", \"\".join(ipa1), f\"({w1})\")\n                else:\n                    break\n\n    if n_matches &gt;= 20:   \n        print(\"...\")\n        break\n\næbdəkt (abduct) + ʃən = æbdəkʃən (abduction)\nəbɔɹt (abort) + ʃən = əbɔɹʃən (abortion)\næbsəlut (absolut) + ʃən = æbsəluʃən (absolution)\næbstɹækt (abstract) + ʃən = æbstɹækʃən (abstraction)\nækt (act) + ʃən = ækʃən (action)\nədɪkt (addict) + ʃən = ədɪkʃən (addiction)\nədmɪt (admit) + ʃən = ədmɪʃən (admission(1))\nədɑpt (adopt) + ʃən = ədɑpʃən (adoption)\nædɝ (adder) + ʃən = ædɝeɪʃən (adoration)\nædʒəl (agile) + ʃən = ædʒəleɪʃən (adulation)\nəfɛkt (affect) + ʃən = əfɛkʃən (affection)\nəflɪkt (afflict) + ʃən = əflɪkʃən (affliction)\neɪliən (alien) + ʃən = eɪliəneɪʃən (alienation)\nɔltɝ (altar) + ʃən = ɔltɝeɪʃən (alteration)\nəmælgəm (amalgam) + ʃən = əmælgəmeɪʃən (amalgamation)\neɪnt (ain't) + ʃən = eɪnʃənt (ancient(1))\nænəm (annum) + ʃən = ænəmeɪʃən (animation)\nænɛks (annex) + ʃən = ænɛkseɪʃən (annexation)\nænt (ant) + ʃən = ænʃən (anshan)\næpəl (appel) + ʃən = æpəleɪʃən (appalachian(1))\n...\nThere’s still some wonky stuff in here–e.g. ancient coming from ain’t and ashen coming from at–but we’re getting closer. We can’t really deal with cases like ashen coming from at, but we can deal with ancient coming from ain’t, which reveals a behavior of re.findall: it functions like re.match, rather than re.fullmatch, in that it matches the beginning of a string. If we want it to match the entire string, we have to explicitly specify that in the regular expression. To do this, we can use a $, which means “end of string”.1\nregex_ʃən = '(.+?)(eɪ)?ʃən$'\n\nn_matches = 0\n\nseen = set()\n\nfor w1, ipa1 in entries.items():\n    possible_morpheme = re.findall(regex_ʃən, \"\".join(ipa1))\n    if possible_morpheme:\n        for w2, ipa2 in entries.items():\n            if possible_morpheme[0][1]:\n                regex_stem = possible_morpheme[0][0]\n            else:\n                regex_stem = possible_morpheme[0][0] + \"t\"\n            \n            if re.fullmatch(regex_stem, \"\".join(ipa2)):\n                if n_matches &lt; 20 and \"\".join(ipa2) not in seen:\n                    n_matches += 1\n                    seen |= {\"\".join(ipa2)}\n                    print(\"\".join(ipa2), f\"({w2})\", \"+\", \"ʃən\", \"=\", \"\".join(ipa1), f\"({w1})\")\n                else:\n                    break\n\n    if n_matches &gt;= 20:   \n        print(\"...\")\n        break\n\næbdəkt (abduct) + ʃən = æbdəkʃən (abduction)\nəbɔɹt (abort) + ʃən = əbɔɹʃən (abortion)\næbsəlut (absolut) + ʃən = æbsəluʃən (absolution)\næbstɹækt (abstract) + ʃən = æbstɹækʃən (abstraction)\nækt (act) + ʃən = ækʃən (action)\nədɪkt (addict) + ʃən = ədɪkʃən (addiction)\nədmɪt (admit) + ʃən = ədmɪʃən (admission(1))\nədɑpt (adopt) + ʃən = ədɑpʃən (adoption)\nædɝ (adder) + ʃən = ædɝeɪʃən (adoration)\nædʒəl (agile) + ʃən = ædʒəleɪʃən (adulation)\nəfɛkt (affect) + ʃən = əfɛkʃən (affection)\nəflɪkt (afflict) + ʃən = əflɪkʃən (affliction)\neɪliən (alien) + ʃən = eɪliəneɪʃən (alienation)\nɔltɝ (altar) + ʃən = ɔltɝeɪʃən (alteration)\nəmælgəm (amalgam) + ʃən = əmælgəmeɪʃən (amalgamation)\nænəm (annum) + ʃən = ænəmeɪʃən (animation)\nænɛks (annex) + ʃən = ænɛkseɪʃən (annexation)\nænt (ant) + ʃən = ænʃən (anshan)\næpəl (appel) + ʃən = æpəleɪʃən (appalachian(1))\nəsɛnt (ascent) + ʃən = əsɛnʃən (ascension)\n...\nTo get much better than this, we’d need to start matching on the orthographic representation as well–e.g. matching the ion at the end of the orthographic representation of the word, thus filtering things like /æt/ + /ʃən/ = /æʃən/. One thing we’ll still miss are cases like adoration, where there is a vowel quality change (which is consequently why we get adder + ion = adoration currently). To handle those cases, we would need to account for the conditions under which vowel quality changes, which we could do in principle using regular expressions but which I won’t do here."
  },
  {
    "objectID": "formal-and-practical-preliminaries/regular-expressions/quantifiers.html",
    "href": "formal-and-practical-preliminaries/regular-expressions/quantifiers.html",
    "title": "Quantifiers",
    "section": "",
    "text": "Note that ., the character ranges, and the escape characters match only a single character, and so to match more than one, we need more than one of whichever we are interested in matching.\n\n\nLoad IPA representation of CMU Pronouncing Dictionary\nwith open(\"cmudict-ipa\") as f:\n    entries: list[tuple[str, str]] = [\n        l.strip().split(\",\") for l in f\n    ]\n    entries: dict[str, list[str]] = {\n        w: ipa.split() for w, ipa in entries\n    }\n\n\n\nimport re\n\nregex_dot_stɹ_dot_kʃən = '.bstɹ.kʃən'\nregex_dot_dot_tɹ_dot_kʃən = '..stɹ.kʃən'\n\nprint(regex_dot_stɹ_dot_kʃən, \"matches:\")\nprint()\n\nfor w, ipa in entries.items():    \n    if re.fullmatch(regex_dot_stɹ_dot_kʃən, \"\".join(ipa)):\n        print(regex_dot_stɹ_dot_kʃən, \"matches\", \"\".join(ipa), f\"({w})\")\n\nprint()\n\nprint(regex_dot_dot_tɹ_dot_kʃən, \"matches:\")\nprint()\n\nfor w, ipa in entries.items():\n    if re.fullmatch(regex_dot_dot_tɹ_dot_kʃən, \"\".join(ipa)):\n        print(\"\".join(ipa), f\"({w})\")\n\n.bstɹ.kʃən matches:\n\n.bstɹ.kʃən matches æbstɹækʃən (abstraction)\n.bstɹ.kʃən matches əbstɹəkʃən (obstruction)\n\n..stɹ.kʃən matches:\n\næbstɹækʃən (abstraction)\ndɪstɹəkʃən (destruction)\ndɪstɹækʃən (distraction)\nɛkstɹækʃən (extraction)\nɪnstɹəkʃən (instruction)\nəbstɹəkʃən (obstruction)\nɹistɹɪkʃən (restriction)\n\n\nWe can avoid writing out multiple by using a quantifier. There are a few different quantifiers. For instance, if you have an exact number in mind:\n\nregex_dot2_tɹ_dot_kʃən = '.{2}stɹ.kʃən'\n\nfor w, ipa in entries.items():\n    if re.fullmatch(regex_dot2_tɹ_dot_kʃən, \"\".join(ipa)):\n        print(\"\".join(ipa), f\"({w})\")\n\næbstɹækʃən (abstraction)\ndɪstɹəkʃən (destruction)\ndɪstɹækʃən (distraction)\nɛkstɹækʃən (extraction)\nɪnstɹəkʃən (instruction)\nəbstɹəkʃən (obstruction)\nɹistɹɪkʃən (restriction)\n\n\nOr if you had a range of numbers in mind:\n\nregex_dot2_tɹæk_dot13 = '.{2}stɹək.{1,3}'\n\nfor w, ipa in entries.items():\n    if re.fullmatch(regex_dot2_tɹæk_dot13, \"\".join(ipa)):\n        print(\"\".join(ipa), f\"({w})\")\n\ndɪstɹəkt (destruct)\ndɪstɹəktɪd (destructed)\ndɪstɹəktɪŋ (destructing)\ndɪstɹəkʃən (destruction)\ndɪstɹəktɪv (destructive)\ndɪstɹəkts (destructs)\nɛkstɹəkeɪt (extricate)\nɪnstɹəkt (instruct)\nɪnstɹəktəd (instructed)\nɪnstɹəktɪd (instructed(1))\nɪnstɹəktɪŋ (instructing)\nɪnstɹəkʃən (instruction)\nɪnstɹəktɪv (instructive)\nɪnstɹəktɝ (instructor)\nɪnstɹəktɝz (instructors)\nɪnstɹəkts (instructs)\nəbstɹəkt (obstruct)\nəbstɹəktɪd (obstructed)\nəbstɹəktɪŋ (obstructing)\nəbstɹəkʃən (obstruction)\nəbstɹəktɪv (obstructive)\nəbstɹəkts (obstructs)\nɹistɹəktʃɝ (restructure)\nənstɹəkʃɝd (unstructured)\n\n\nYou can also leave off one bound:\n\nregex_dot2_tɹæk_dot03 = '.{2}stɹək.{,3}'\nregex_dot2_tɹæk_dot1inf = '.{2}stɹək.{1,}'\n\nprint(regex_dot2_tɹæk_dot03, \"matches:\")\nprint()\n\nn_matches = 0\n\nfor w, ipa in entries.items():\n    if re.fullmatch(regex_dot2_tɹæk_dot03, \"\".join(ipa)):\n        if n_matches &lt; 10:\n            n_matches += 1\n            print(\"\".join(ipa), f\"({w})\")\n        else:\n            print(\"...\")\n            break\n\nprint()\nprint(regex_dot2_tɹæk_dot1inf, \"matches:\")\nprint()\n\nn_matches = 0\n\nfor w, ipa in entries.items():\n    if re.fullmatch(regex_dot2_tɹæk_dot1inf, \"\".join(ipa)):\n        if n_matches &lt; 10:\n            n_matches += 1\n            print(\"\".join(ipa), f\"({w})\")\n        else:\n            print(\"...\")\n            break\n\n.{2}stɹək.{,3} matches:\n\ndɪstɹəkt (destruct)\ndɪstɹəktɪd (destructed)\ndɪstɹəktɪŋ (destructing)\ndɪstɹəkʃən (destruction)\ndɪstɹəktɪv (destructive)\ndɪstɹəkts (destructs)\nɛkstɹəkeɪt (extricate)\nɪnstɹəkt (instruct)\nɪnstɹəktəd (instructed)\nɪnstɹəktɪd (instructed(1))\n...\n\n.{2}stɹək.{1,} matches:\n\ndɪstɹəkt (destruct)\ndɪstɹəktəbəl (destructable)\ndɪstɹəktɪd (destructed)\ndɪstɹəktɪŋ (destructing)\ndɪstɹəkʃən (destruction)\ndɪstɹəktɪv (destructive)\ndɪstɹəktɪvnɪs (destructiveness)\ndɪstɹəkts (destructs)\nɛkstɹəkɝɪkjəlɝ (extracurricular)\nɛkstɹəkeɪt (extricate)\n...\n\n\nNote that {,} is equivalent to *. There is also a special quantifier symbol for {1,}: +\nAnd if you wanted at least one character ot come after Aaron, but didn’t care after that you could use +.\n\nregex_dot2_tɹæk_dotplus = '.{2}stɹək.+'\n\nn_matches = 0\n\nfor w, ipa in entries.items():\n    if re.fullmatch(regex_dot2_tɹæk_dotplus, \"\".join(ipa)):\n        if n_matches &lt; 10:\n            n_matches += 1\n            print(\"\".join(ipa), f\"({w})\")\n        else:\n            print(\"...\")\n            break\n\ndɪstɹəkt (destruct)\ndɪstɹəktəbəl (destructable)\ndɪstɹəktɪd (destructed)\ndɪstɹəktɪŋ (destructing)\ndɪstɹəkʃən (destruction)\ndɪstɹəktɪv (destructive)\ndɪstɹəktɪvnɪs (destructiveness)\ndɪstɹəkts (destructs)\nɛkstɹəkɝɪkjəlɝ (extracurricular)\nɛkstɹəkeɪt (extricate)\n...\n\n\nNote that none of these quantifiers increase the expressive power of the regular expressions. We can always write their equivalents as a vanilla regular expression (in the sense of the formal definition we gave above); it would just be tedious in many cases.\n\nSet complement\nFor any of these cases where we escape a lowercase alphabetic character to get a character set, the set complement can generally be gotten with by the uppercase version—e.g. \\w goes to \\W.\n\nregex_notw_bstɹækt = '\\Wbstɹəkt'\n\n(re.fullmatch(regex_notw_bstɹækt, \"\".join(entries[\"obstruct\"])),\n re.fullmatch(regex_notw_bstɹækt, '\\n'+\"\".join(entries[\"obstruct\"])[1:]))\n\n(None, &lt;re.Match object; span=(0, 8), match='\\nbstɹəkt'&gt;)\n\n\nSometimes you want the complement of a set that doesn’t have an associated escaped alphabetic character. For that you can use the same square bracket set notation but put a ^ after the first bracket.\n\nregex_notæ_bstɹ_notæ_kt = '[^æ][^b]stɹ[^æ]kt'\n\nfor w, ipa in entries.items():    \n    if re.fullmatch(regex_notæ_bstɹ_notæ_kt, \"\".join(ipa)):\n        print(\"\".join(ipa), f\"({w})\")\n\ndɪstɹəkt (destruct)\ndɪstɹɪkt (district)\nɪnstɹəkt (instruct)\nmɑstɹɪkt (maastricht)\nɹistɹɪkt (restrict)\n\n\nThe placement of this ^ is really important, since it only has the negation interpretation directly after [."
  },
  {
    "objectID": "formal-and-practical-preliminaries/regular-expressions/wild-cards-and-character-ranges.html",
    "href": "formal-and-practical-preliminaries/regular-expressions/wild-cards-and-character-ranges.html",
    "title": "Wild cards and character ranges",
    "section": "",
    "text": "We can represent all simple regular expressions according to our formal definition, but in certain cases, doing so would be tedious. For instance, suppose I want to represent the set of all English phonemes \\(\\Sigma\\). Using our formal definition, we would need to list out all of the phonemes joined by \\(\\cup\\): \\((\\text{i} \\cup (\\text{ɝ} \\cup (\\text{a} \\cup (\\text{ɪ} \\cup \\ldots))))\\).\nTo make this less tedious, Python (and many other languages) introduce additional special characters into the definition of \\(R(\\Sigma)\\). The most basic is the wildcard ., which matches any single character (alphanumeric or otherwise) except the newline \\n.\n\n\nLoad IPA representation of CMU Pronouncing Dictionary\nwith open(\"cmudict-ipa\") as f:\n    entries: list[tuple[str, str]] = [\n        l.strip().split(\",\") for l in f\n    ]\n    entries: dict[str, list[str]] = {\n        w: ipa.split() for w, ipa in entries\n    }\n\n\n\nimport re\n\nregex_dot_bstɹ_dot_kʃən = '.bstɹ.kʃən'\n\nfor w, ipa in entries.items():\n    if re.fullmatch(regex_dot_bstɹ_dot_kʃən, \"\".join(ipa)):\n        print(\"\".join(ipa), f\"({w})\")\n\nabstraction æbstɹækʃən\nobstruction əbstɹəkʃən\n\n\nIf you want to match the . itself (or any special character we introduce below), you need to escape it.\n\nregex_period_bstɹækʃən = '\\.bstɹækʃən'\n\nre.fullmatch(regex_period_bstɹækʃən, '.' + string_æbstɹækʃən[1:])\n\n&lt;re.Match object; span=(0, 10), match='.bstɹækʃən'&gt;\n\n\nBesides ., we can also use character ranges to target more specific sets, like upper- and lower-case alphabetic characters ([A-z]), lower-case alphabetic character ([a-z]), numerals [0-9].\n\nregex_numeric_bstɹækʃən = '[0-9]bstɹækʃən'\nstring_4bstɹækʃən = '4bstɹækʃən'\n\nre.fullmatch(regex_numeric_bstɹækʃən, string_4bstɹækʃən)\n\n&lt;re.Match object; span=(0, 10), match='4bstɹækʃən'&gt;\n\n\nIn addition to ranges, there are even more compact escape characters. For instance, alphanumeric characters plus _ can be gotten with \\w (the same as the range [A-z0-9_]).\n\nregex_alphanumeric_bstɹækʃən = '\\wbstɹækʃən'\n\nre.fullmatch(regex_alphanumeric_bstɹækʃən, string_æbstɹækʃən)\n\n&lt;re.Match object; span=(0, 10), match='æbstɹækʃən'&gt;"
  },
  {
    "objectID": "formal-and-practical-preliminaries/regular-expressions/implementing-the-regular-operations.html",
    "href": "formal-and-practical-preliminaries/regular-expressions/implementing-the-regular-operations.html",
    "title": "Implementing the Regular Operations",
    "section": "",
    "text": "So far, we’ve seen only a trivial regular expression: one containing a single character æ, which evaluates to the language {æ} \\(\\in 2^{\\Sigma^*}\\). How do we represent other kinds of regular expressions?"
  },
  {
    "objectID": "formal-and-practical-preliminaries/regular-expressions/implementing-the-regular-operations.html#concatenation",
    "href": "formal-and-practical-preliminaries/regular-expressions/implementing-the-regular-operations.html#concatenation",
    "title": "Implementing the Regular Operations",
    "section": "Concatenation",
    "text": "Concatenation\nThe operation of concatenation, which we represented using \\(\\circ\\), is implicit in putting two characters next to each other. For instance, to represent the regular expression \\((\\text{æ} \\circ (\\text{b} \\circ (\\text{s} \\circ (\\text{t} \\circ (\\text{ɹ} \\circ (\\text{æ} \\circ (\\text{k} \\circ (\\text{ʃ} \\circ (\\text{ə} \\circ \\text{n})))))))))\\), we can simply write æbstɹækʃən.\n\n\nLoad IPA representation of CMU Pronouncing Dictionary\nwith open(\"cmudict-ipa\") as f:\n    entries: list[tuple[str, str]] = [\n        l.strip().split(\",\") for l in f\n    ]\n    entries: dict[str, list[str]] = {\n        w: ipa.split() for w, ipa in entries\n    }\n\n\n\nimport re\n\nregex_æbstɹækʃən = \"æbstɹækʃən\"\n\nstring_æbstɹækʃən = \"\".join(entries[\"abstraction\"])\n\nre.fullmatch(regex_æbstɹækʃən, string_æbstɹækʃən)\n\n&lt;re.Match object; span=(0, 10), match='æbstɹækʃən'&gt;"
  },
  {
    "objectID": "formal-and-practical-preliminaries/regular-expressions/implementing-the-regular-operations.html#union",
    "href": "formal-and-practical-preliminaries/regular-expressions/implementing-the-regular-operations.html#union",
    "title": "Implementing the Regular Operations",
    "section": "Union",
    "text": "Union\nIn contrast, to represent the regular expression \\(((\\text{æ} \\cup \\text{ə}) \\circ (\\text{b} \\circ (\\text{s} \\circ (\\text{t} \\circ (\\text{ɹ} \\circ ((\\text{æ} \\cup \\text{ə}) \\circ (\\text{k} \\circ (\\text{ʃ} \\circ (\\text{ə} \\circ \\text{n})))))))))\\), which evaluates to {æbstɹækʃən, əbstɹækʃən, æbstɹəkʃən, əbstɹəkʃən}, we either use []…\n\nregex_æəbstɹæəkʃən = \"[æə]bstɹ[æə]kʃən\"\n\nstring_əbstɹəkʃən = \"\".join(entries[\"obstruction\"])\nstring_æbstɹəkʃən = \"æbstɹəkʃən\"\nstring_əbstɹækʃən = \"əbstɹækʃən\"\n\n(re.fullmatch(regex_æəbstɹæəkʃən, string_æbstɹækʃən),\n re.fullmatch(regex_æəbstɹæəkʃən, string_æbstɹəkʃən),\n re.fullmatch(regex_æəbstɹæəkʃən, string_əbstɹækʃən), \n re.fullmatch(regex_æəbstɹæəkʃən, string_əbstɹəkʃən))\n\n(&lt;re.Match object; span=(0, 10), match='æbstɹækʃən'&gt;,\n &lt;re.Match object; span=(0, 10), match='æbstɹəkʃən'&gt;,\n &lt;re.Match object; span=(0, 10), match='əbstɹækʃən'&gt;,\n &lt;re.Match object; span=(0, 10), match='əbstɹəkʃən'&gt;)\n\n\n…or an explicit |.\n\nregex_æəbstɹæəkʃən = \"(æ|ə)bstɹ(æ|ə)kʃən\"\n\n(re.fullmatch(regex_æəbstɹæəkʃən, string_æbstɹækʃən),\n re.fullmatch(regex_æəbstɹæəkʃən, string_æbstɹəkʃən),\n re.fullmatch(regex_æəbstɹæəkʃən, string_əbstɹækʃən), \n re.fullmatch(regex_æəbstɹæəkʃən, string_əbstɹəkʃən))\n\n(&lt;re.Match object; span=(0, 10), match='æbstɹækʃən'&gt;,\n &lt;re.Match object; span=(0, 10), match='æbstɹəkʃən'&gt;,\n &lt;re.Match object; span=(0, 10), match='əbstɹækʃən'&gt;,\n &lt;re.Match object; span=(0, 10), match='əbstɹəkʃən'&gt;)\n\n\nNote that the () are important in the latter case!\n\nregex_æəbstɹæəkʃən = \"æ|əbstɹæ|əkʃən\"\n\n(re.fullmatch(regex_æəbstɹæəkʃən, string_æbstɹækʃən),\n re.fullmatch(regex_æəbstɹæəkʃən, string_æbstɹəkʃən),\n re.fullmatch(regex_æəbstɹæəkʃən, string_əbstɹækʃən), \n re.fullmatch(regex_æəbstɹæəkʃən, string_əbstɹəkʃən))\n\n(None, None, None, None)"
  },
  {
    "objectID": "formal-and-practical-preliminaries/regular-expressions/implementing-the-regular-operations.html#kleene-star",
    "href": "formal-and-practical-preliminaries/regular-expressions/implementing-the-regular-operations.html#kleene-star",
    "title": "Implementing the Regular Operations",
    "section": "Kleene star",
    "text": "Kleene star\nFinally, the Kleene star works the way you would expect.\n\nregex_ææææbstɹækʃən = \"æ*bstɹækʃən\"\n\nfor i in range(10):\n    print(re.fullmatch(regex_ææææbstɹækʃən, \"æ\"*i + string_æbstɹækʃən[1:]))\n\n&lt;re.Match object; span=(0, 9), match='bstɹækʃən'&gt;\n&lt;re.Match object; span=(0, 10), match='æbstɹækʃən'&gt;\n&lt;re.Match object; span=(0, 11), match='ææbstɹækʃən'&gt;\n&lt;re.Match object; span=(0, 12), match='æææbstɹækʃən'&gt;\n&lt;re.Match object; span=(0, 13), match='ææææbstɹækʃən'&gt;\n&lt;re.Match object; span=(0, 14), match='æææææbstɹækʃən'&gt;\n&lt;re.Match object; span=(0, 15), match='ææææææbstɹækʃən'&gt;\n&lt;re.Match object; span=(0, 16), match='æææææææbstɹækʃən'&gt;\n&lt;re.Match object; span=(0, 17), match='ææææææææbstɹækʃən'&gt;\n&lt;re.Match object; span=(0, 18), match='æææææææææbstɹækʃən'&gt;\n\n\nTo apply the Kleene star to a complex regular expression, we need ().\n\nregex_reæbstɹækʃən = \"(ɹi|di)*æbstɹækʃən\"\n\nfor i in range(3):\n    print(re.fullmatch(regex_reæbstɹækʃən, \"ɹi\"*i + string_æbstɹækʃən))\n    print(re.fullmatch(regex_reæbstɹækʃən, \"di\"*i + string_æbstɹækʃən))\n    print(re.fullmatch(regex_reæbstɹækʃən, \"ɹidi\"*i + string_æbstɹækʃən))\n    print(re.fullmatch(regex_reæbstɹækʃən, \"diɹi\"*i + string_æbstɹækʃən))\n\n&lt;re.Match object; span=(0, 10), match='æbstɹækʃən'&gt;\n&lt;re.Match object; span=(0, 10), match='æbstɹækʃən'&gt;\n&lt;re.Match object; span=(0, 10), match='æbstɹækʃən'&gt;\n&lt;re.Match object; span=(0, 10), match='æbstɹækʃən'&gt;\n&lt;re.Match object; span=(0, 12), match='ɹiæbstɹækʃən'&gt;\n&lt;re.Match object; span=(0, 12), match='diæbstɹækʃən'&gt;\n&lt;re.Match object; span=(0, 14), match='ɹidiæbstɹækʃən'&gt;\n&lt;re.Match object; span=(0, 14), match='diɹiæbstɹækʃən'&gt;\n&lt;re.Match object; span=(0, 14), match='ɹiɹiæbstɹækʃən'&gt;\n&lt;re.Match object; span=(0, 14), match='didiæbstɹækʃən'&gt;\n&lt;re.Match object; span=(0, 18), match='ɹidiɹidiæbstɹækʃən'&gt;\n&lt;re.Match object; span=(0, 18), match='diɹidiɹiæbstɹækʃən'&gt;"
  },
  {
    "objectID": "formal-and-practical-preliminaries/regular-expressions/implementing-the-regular-operations.html#groups-and-greediness",
    "href": "formal-and-practical-preliminaries/regular-expressions/implementing-the-regular-operations.html#groups-and-greediness",
    "title": "Implementing the Regular Operations",
    "section": "Groups and greediness",
    "text": "Groups and greediness\nOne of the major uses for regular expressions is for extracting substrings from a string. This can be done with groups. For instance, suppose I want all of the last names of people named Aaron in some text (if such a last name is mentioned). I would put parentheses around what I think is the last name and use the findall function.\n\nregex = 'Aaron ([A-Z][a-z]*)'\nstring = 'Aaron White'\n\n#re.fullmatch(regex, string)\nre.findall(regex, string)\n\n['White']\n\n\nThis particular pattern could be problematic if a middle name is listed.\n\nregex = 'Aaron ([A-Z][a-z]*)'\nstring = 'Aaron Steven White'\n\nre.findall(regex, string)\n\n['Steven']\n\n\nTo handle this, we could explicitly assume that there is always a middle name.\n\nregex = 'Aaron [A-Z][a-z]* ([A-Z][a-z]*)'\nstring = 'Aaron Steven White'\n\nre.findall(regex, string)\n\n['White']\n\n\nBut then what about the cases where there’s not?\n\nstring = 'Aaron Steven White'\n\nre.findall(regex, string)\n\n['White']\n\n\nIn this case, we can use the quantifier ?, which matches zero or one instances of a character before it.\n\nstring = 'Aaron Steven White'\nregex = 'Aaron ([A-Z]?[a-z]+ ?)+'\n\nre.findall(regex, string)\n\n['White']\n\n\nWe don’t always want to have to list out all the possible matches we might find. For instance, suppose we’re parsing a CSV.\n\ncsv = 'c1,c2,c3,c4,c5,c6,c7,c8\\nd1,d2,d3,d4,d5,d6,d7,d8'\n\nprint(csv)\n\nc1,c2,c3,c4,c5,c6,c7,c8\nd1,d2,d3,d4,d5,d6,d7,d8\n\n\nFor this, we want to be able to repeat a pattern an arbitrary number of times.\nYou’d think you might be able to use the following:\n\nregex = '((.*),)*'\n\nre.findall(regex, csv)\n\n[('c1,c2,c3,c4,c5,c6,c7,', 'c1,c2,c3,c4,c5,c6,c7'),\n ('', ''),\n ('', ''),\n ('', ''),\n ('d1,d2,d3,d4,d5,d6,d7,', 'd1,d2,d3,d4,d5,d6,d7'),\n ('', ''),\n ('', ''),\n ('', '')]\n\n\nWhy doesn’t this work? The problem is that quantifiers are greedy by default: thy will match as much as they can before stopping. We can use ? to ensure that the quantifier is not intepreted greedily.\n\nregex = '((.*?),)+?'\n\nre.findall(regex, csv)\n\n[('c1,', 'c1'),\n ('c2,', 'c2'),\n ('c3,', 'c3'),\n ('c4,', 'c4'),\n ('c5,', 'c5'),\n ('c6,', 'c6'),\n ('c7,', 'c7'),\n ('d1,', 'd1'),\n ('d2,', 'd2'),\n ('d3,', 'd3'),\n ('d4,', 'd4'),\n ('d5,', 'd5'),\n ('d6,', 'd6'),\n ('d7,', 'd7')]\n\n\nThat’s almost right, but what’s the problem? We’re capturing more than we want, and we’re missing the last column. To partially handle the first problem, we can use non-capturing groups, which place a ?: right after the left (.\n\nregex = r'(?:(.+?)(?:,|\\n))+?'\n\nre.findall(regex, csv)\n\n['c1',\n 'c2',\n 'c3',\n 'c4',\n 'c5',\n 'c6',\n 'c7',\n 'c8',\n 'd1',\n 'd2',\n 'd3',\n 'd4',\n 'd5',\n 'd6',\n 'd7']\n\n\nHow do we make sure we capture the last column?\n\nregex = r'(?:(.+?)(?:,|(?=\\n)|(?=$)))+?'\n\nre.findall(regex, csv)\n\n['c1',\n 'c2',\n 'c3',\n 'c4',\n 'c5',\n 'c6',\n 'c7',\n 'c8',\n 'd1',\n 'd2',\n 'd3',\n 'd4',\n 'd5',\n 'd6',\n 'd7',\n 'd8']\n\n\nTo get a format that represents each row in the CSV as its own list, we might then restructure this result into a list of lists. In actual practice, you could do this in an number of ways—e.g. first matching each row up to a newline, then matching the above regex with (?=\\n) part against the list or eschewing regexes and using Python’s str.split() methods or the csv library (which, by the way, would be very useful for Assignment 1).\n\nA note on raw (r) strings\nOne thing I haven’t addressed here is that you’ll often seen an odd-looking r directly before the first quote in the string in a lot of Python regular expressions. This is because, as explained here…\n\nRegular expressions use the backslash character (‘\\’) to indicate special forms or to allow special characters to be used without invoking their special meaning. This collides with Python’s usage of the same character for the same purpose in string literals; for example, to match a literal backslash, one might have to write ‘\\\\\\\\’ as the pattern string, because the regular expression must be \\\\, and each backslash must be expressed as \\\\ inside a regular Python string literal.\n\n\nThe solution is to use Python’s raw string notation for regular expression patterns; backslashes are not handled in any special way in a string literal prefixed with ‘r’. So r”” is a two-character string containing ‘\\’ and ‘n’, while “” is a one-character string containing a newline. Usually patterns will be expressed in Python code using this raw string notation.\n\nSo it only really matters when you’re using special escape characters, but you should just get in the habit of using it more generally."
  },
  {
    "objectID": "formal-and-practical-preliminaries/regular-expressions/implementing-the-regular-operations.html#querying-a-lexicon",
    "href": "formal-and-practical-preliminaries/regular-expressions/implementing-the-regular-operations.html#querying-a-lexicon",
    "title": "Implementing the Regular Operations",
    "section": "Querying a lexicon",
    "text": "Querying a lexicon\nOne use case for regular expressions in the context of computational linguistics is querying a lexicon. To look at this use case, we will use the lexicon of word forms found in the CMU Pronouncing Dictionary.\n\n!wget https://raw.githubusercontent.com/Alexir/CMUdict/master/cmudict-0.7b\n\n--2024-01-29 12:13:08--  https://raw.githubusercontent.com/Alexir/CMUdict/master/cmudict-0.7b\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3865710 (3.7M) [text/plain]\nSaving to: ‘cmudict-0.7b.6’\n\ncmudict-0.7b.6      100%[===================&gt;]   3.69M  12.2MB/s    in 0.3s    \n\n2024-01-29 12:13:09 (12.2 MB/s) - ‘cmudict-0.7b.6’ saved [3865710/3865710]\n\n\n\n\n!head -n 200 cmudict-0.7b\n\n;;; # CMUdict  --  Major Version: 0.07\n;;; \n;;; # $HeadURL: https://svn.code.sf.net/p/cmusphinx/code/branches/cmudict/cmudict-0.7b $\n;;; # $Date:: 2015-07-15 12:34:30 -0400 (Wed, 15 Jul 2015)      $:\n;;; # $Id:: cmudict-0.7b 13083 2015-07-15 16:34:30Z air         $:\n;;; # $Rev:: 13083                                              $: \n;;; # $Author:: air                                             $:\n;;;\n;;; #\n;;; # ========================================================================\n;;; # Copyright (C) 1993-2015 Carnegie Mellon University. All rights reserved.\n;;; #\n;;; # Redistribution and use in source and binary forms, with or without\n;;; # modification, are permitted provided that the following conditions\n;;; # are met:\n;;; #\n;;; # 1. Redistributions of source code must retain the above copyright\n;;; #    notice, this list of conditions and the following disclaimer.\n;;; #    The contents of this file are deemed to be source code.\n;;; #\n;;; # 2. Redistributions in binary form must reproduce the above copyright\n;;; #    notice, this list of conditions and the following disclaimer in\n;;; #    the documentation and/or other materials provided with the\n;;; #    distribution.\n;;; #\n;;; # This work was supported in part by funding from the Defense Advanced\n;;; # Research Projects Agency, the Office of Naval Research and the National\n;;; # Science Foundation of the United States of America, and by member\n;;; # companies of the Carnegie Mellon Sphinx Speech Consortium. We acknowledge\n;;; # the contributions of many volunteers to the expansion and improvement of\n;;; # this dictionary.\n;;; #\n;;; # THIS SOFTWARE IS PROVIDED BY CARNEGIE MELLON UNIVERSITY ``AS IS'' AND\n;;; # ANY EXPRESSED OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,\n;;; # THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\n;;; # PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL CARNEGIE MELLON UNIVERSITY\n;;; # NOR ITS EMPLOYEES BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n;;; # SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n;;; # LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n;;; # DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n;;; # THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n;;; # (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n;;; # OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n;;; #\n;;; # ========================================================================\n;;; #\n;;;\n;;;  NOTES  ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n;;; \n;;;  [20080401] (air)  New dict file format introduced \n;;;   - comments (like this section) are allowed\n;;;   - file name is major version; vers/rev information is now in the header\n;;;\n;;; \n;;; ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n;;; \n!EXCLAMATION-POINT  EH2 K S K L AH0 M EY1 SH AH0 N P OY2 N T\n\"CLOSE-QUOTE  K L OW1 Z K W OW1 T\n\"DOUBLE-QUOTE  D AH1 B AH0 L K W OW1 T\n\"END-OF-QUOTE  EH1 N D AH0 V K W OW1 T\n\"END-QUOTE  EH1 N D K W OW1 T\n\"IN-QUOTES  IH1 N K W OW1 T S\n\"QUOTE  K W OW1 T\n\"UNQUOTE  AH1 N K W OW1 T\n#HASH-MARK  HH AE1 M AA2 R K\n#POUND-SIGN  P AW1 N D S AY2 N\n#SHARP-SIGN  SH AA1 R P S AY2 N\n%PERCENT  P ER0 S EH1 N T\n&AMPERSAND  AE1 M P ER0 S AE2 N D\n'ALLO  AA2 L OW1\n'APOSTROPHE  AH0 P AA1 S T R AH0 F IY0\n'BOUT  B AW1 T\n'CAUSE  K AH0 Z\n'COURSE  K AO1 R S\n'CUSE  K Y UW1 Z\n'EM  AH0 M\n'END-INNER-QUOTE  EH1 N D IH1 N ER0 K W OW1 T\n'END-QUOTE  EH1 N D K W OW1 T\n'FRISCO  F R IH1 S K OW0\n'GAIN  G EH1 N\n'INNER-QUOTE  IH1 N ER0 K W OW1 T\n'KAY  K EY1\n'M  AH0 M\n'N  AH0 N\n'QUOTE  K W OW1 T\n'ROUND  R AW1 N D\n'S  EH1 S\n'SINGLE-QUOTE  S IH1 NG G AH0 L K W OW1 T\n'TIL  T IH1 L\n'TIS  T IH1 Z\n'TWAS  T W AH1 Z\n(BEGIN-PARENS  B IH0 G IH1 N P ER0 EH1 N Z\n(IN-PARENTHESES  IH1 N P ER0 EH1 N TH AH0 S IY2 Z\n(LEFT-PAREN  L EH1 F T P ER0 EH1 N\n(OPEN-PARENTHESES  OW1 P AH0 N P ER0 EH1 N TH AH0 S IY2 Z\n(PAREN  P ER0 EH1 N\n(PARENS  P ER0 EH1 N Z\n(PARENTHESES  P ER0 EH1 N TH AH0 S IY2 Z\n)CLOSE-PAREN  K L OW1 Z P ER0 EH1 N\n)CLOSE-PARENTHESES  K L OW1 Z P ER0 EH1 N TH AH0 S IY2 Z\n)END-PAREN  EH1 N D P ER0 EH1 N\n)END-PARENS  EH1 N D P ER0 EH1 N Z\n)END-PARENTHESES  EH1 N D P ER0 EH1 N TH AH0 S IY2 Z\n)END-THE-PAREN  EH1 N D DH AH0 P ER0 EH1 N\n)PAREN  P ER0 EH1 N\n)PARENS  P ER0 EH1 N Z\n)RIGHT-PAREN  R AY1 T P EH2 R AH0 N\n)UN-PARENTHESES  AH1 N P ER0 EH1 N TH AH0 S IY1 Z\n+PLUS  P L UH1 S\n,COMMA  K AA1 M AH0\n--DASH  D AE1 SH\n-DASH  D AE1 SH\n-HYPHEN  HH AY1 F AH0 N\n...ELLIPSIS  IH2 L IH1 P S IH0 S\n.DECIMAL  D EH1 S AH0 M AH0 L\n.DOT  D AA1 T\n.FULL-STOP  F UH1 L S T AA1 P\n.PERIOD  P IH1 R IY0 AH0 D\n.POINT  P OY1 N T\n/SLASH  S L AE1 SH\n3-D  TH R IY1 D IY2\n3D  TH R IY1 D IY2\n:COLON  K OW1 L AH0 N\n;SEMI-COLON  S EH1 M IY0 K OW1 L AH0 N\n;SEMI-COLON(1)  S EH1 M IH0 K OW2 L AH0 N\n?QUESTION-MARK  K W EH1 S CH AH0 N M AA1 R K\nA  AH0\nA(1)  EY1\nA'S  EY1 Z\nA.  EY1\nA.'S  EY1 Z\nA.D.  EY2 D IY1\nA.M.  EY2 EH1 M\nA.S  EY1 Z\nA42128  EY1 F AO1 R T UW1 W AH1 N T UW1 EY1 T\nAA  EY2 EY1\nAAA  T R IH2 P AH0 L EY1\nAAAI  T R IH2 P AH0 L EY2 AY1\nAABERG  AA1 B ER0 G\nAACHEN  AA1 K AH0 N\nAACHENER  AA1 K AH0 N ER0\nAAH  AA1\nAAKER  AA1 K ER0\nAALIYAH  AA2 L IY1 AA2\nAALSETH  AA1 L S EH0 TH\nAAMODT  AA1 M AH0 T\nAANCOR  AA1 N K AO2 R\nAARDEMA  AA0 R D EH1 M AH0\nAARDVARK  AA1 R D V AA2 R K\nAARDVARKS  AA1 R D V AA2 R K S\nAARGH  AA1 R G\nAARHUS  AA2 HH UW1 S\nAARON  EH1 R AH0 N\nAARON'S  EH1 R AH0 N Z\nAARONS  EH1 R AH0 N Z\nAARONSON  EH1 R AH0 N S AH0 N\nAARONSON(1)  AA1 R AH0 N S AH0 N\nAARONSON'S  EH1 R AH0 N S AH0 N Z\nAARONSON'S(1)  AA1 R AH0 N S AH0 N Z\nAARTI  AA1 R T IY2\nAASE  AA1 S\nAASEN  AA1 S AH0 N\nAB  AE1 B\nABA  EY2 B IY2 EY1\nABABA  AH0 B AA1 B AH0\nABABA(1)  AA1 B AH0 B AH0\nABACHA  AE1 B AH0 K AH0\nABACK  AH0 B AE1 K\nABACO  AE1 B AH0 K OW2\nABACUS  AE1 B AH0 K AH0 S\nABAD  AH0 B AA1 D\nABADAKA  AH0 B AE1 D AH0 K AH0\nABADI  AH0 B AE1 D IY0\nABADIE  AH0 B AE1 D IY0\nABAIR  AH0 B EH1 R\nABALKIN  AH0 B AA1 L K IH0 N\nABALONE  AE2 B AH0 L OW1 N IY0\nABALONES  AE2 B AH0 L OW1 N IY0 Z\nABALOS  AA0 B AA1 L OW0 Z\nABANDON  AH0 B AE1 N D AH0 N\nABANDONED  AH0 B AE1 N D AH0 N D\nABANDONING  AH0 B AE1 N D AH0 N IH0 NG\nABANDONMENT  AH0 B AE1 N D AH0 N M AH0 N T\nABANDONMENTS  AH0 B AE1 N D AH0 N M AH0 N T S\nABANDONS  AH0 B AE1 N D AH0 N Z\nABANTO  AH0 B AE1 N T OW0\nABARCA  AH0 B AA1 R K AH0\nABARE  AA0 B AA1 R IY0\nABASCAL  AE1 B AH0 S K AH0 L\nABASH  AH0 B AE1 SH\nABASHED  AH0 B AE1 SH T\nABASIA  AH0 B EY1 ZH Y AH0\nABATE  AH0 B EY1 T\nABATED  AH0 B EY1 T IH0 D\nABATEMENT  AH0 B EY1 T M AH0 N T\nABATEMENTS  AH0 B EY1 T M AH0 N T S\nABATES  AH0 B EY1 T S\nABATING  AH0 B EY1 T IH0 NG\nABATTOIR  AE2 B AH0 T W AA1 R\nABBA  AE1 B AH0\n\n\n\nwith open('cmudict-0.7b', encoding = \"ISO-8859-1\") as f:\n    cmudict = [l.split() for l in f if l[:3] != \";;;\"]\n    cmudict = {w[0].lower(): w[1:] for w in cmudict}\n    \ncmudict[\"abstraction\"]\n\n['AE0', 'B', 'S', 'T', 'R', 'AE1', 'K', 'SH', 'AH0', 'N']\n\n\nThis dictionary uses what’s known as the ARPABET and represents stress using numeric indicators: 0 for no stress, 1 for primary stress, and 2 for secondary stress. The ARPABET maps to more recognizable phonemes.\n\narpabet_to_phoneme = {'AA': 'ɑ', \n                      'AE': 'æ', \n                      'AH': 'ʌ', \n                      'AO': 'ɔ', \n                      'AW': 'aʊ', \n                      'AY': 'aɪ', \n                      'B': 'b', \n                      'CH': 'tʃ', \n                      'D': 'd', \n                      'DH': 'ð', \n                      'EH': 'ɛ',\n                      'ER': 'ɝ', \n                      'EY': 'eɪ', \n                      'F': 'f', \n                      'G': 'g', \n                      'HH': 'h', \n                      'IH': 'ɪ', \n                      'IY': 'i', \n                      'JH': 'dʒ', \n                      'K': 'k', \n                      'L': 'l', \n                      'M': 'm', \n                      'N': 'n',\n                      'NG': 'ŋ', \n                      'OW': 'oʊ', \n                      'OY': 'ɔɪ', \n                      'P': 'p', \n                      'R': 'ɹ', \n                      'S': 's', \n                      'SH': 'ʃ', \n                      'T': 't', \n                      'TH': 'θ', \n                      'UH': 'ʊ', \n                      'UW': 'u', \n                      'V': 'v',\n                      'W': 'w', \n                      'Y': 'j', \n                      'Z': 'z', \n                      'ZH': 'ʒ'}\n\n\nimport re\n\nentries: dict[str, list[str]] = {\n    w: [arpabet_to_phoneme[''.join(re.findall('[A-z]', phoneme))]\n        for phoneme in transcription]\n        for w, transcription in cmudict.items()\n        if len({c for c in w})&gt;1\n        if len(transcription)&gt;1 \n        if not re.findall('[^A-z]', w[0])\n}\n\nentries[\"abstraction\"]\n\n['æ', 'b', 's', 't', 'ɹ', 'æ', 'k', 'ʃ', 'ʌ', 'n']\n\n\nFor instance, one thing we might be interested in is investigating ablaut patterns—e.g. cases where the verb inflects for some tense or aspect by a vowel change rather than a regular “-ed” ending. For instance, the past tense of sing is sang, rather than singed.\nExercise: how would we find all cases of this sort of ablaut using English UniMorph? Does your solution handle cases like fight to fought.\n\n# implement regex-based solution here\n\nExercise: how might we discover cases that are similar to think, whose past is thought? Note that this case is intuitively different in nature from verbs that are fully irregular in their inflection, like be.\n\n# implement regex-based solution here"
  },
  {
    "objectID": "formal-and-practical-preliminaries/regular-expressions/loading-a-lexicon.html",
    "href": "formal-and-practical-preliminaries/regular-expressions/loading-a-lexicon.html",
    "title": "Loading a Lexicon",
    "section": "",
    "text": "One use case for regular expressions in the context of computational linguistics is querying a lexicon. To look at this use case, we will use the lexicon of word forms found in the CMU Pronouncing Dictionary.\n\n!wget https://raw.githubusercontent.com/Alexir/CMUdict/master/cmudict-0.7b\n\n--2024-01-31 12:13:47--  https://raw.githubusercontent.com/Alexir/CMUdict/master/cmudict-0.7b\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3865710 (3.7M) [text/plain]\nSaving to: ‘cmudict-0.7b.1’\n\ncmudict-0.7b.1      100%[===================&gt;]   3.69M  14.0MB/s    in 0.3s    \n\n2024-01-31 12:13:48 (14.0 MB/s) - ‘cmudict-0.7b.1’ saved [3865710/3865710]\n\n\n\n\n!head -n 200 cmudict-0.7b\n\n;;; # CMUdict  --  Major Version: 0.07\n;;; \n;;; # $HeadURL: https://svn.code.sf.net/p/cmusphinx/code/branches/cmudict/cmudict-0.7b $\n;;; # $Date:: 2015-07-15 12:34:30 -0400 (Wed, 15 Jul 2015)      $:\n;;; # $Id:: cmudict-0.7b 13083 2015-07-15 16:34:30Z air         $:\n;;; # $Rev:: 13083                                              $: \n;;; # $Author:: air                                             $:\n;;;\n;;; #\n;;; # ========================================================================\n;;; # Copyright (C) 1993-2015 Carnegie Mellon University. All rights reserved.\n;;; #\n;;; # Redistribution and use in source and binary forms, with or without\n;;; # modification, are permitted provided that the following conditions\n;;; # are met:\n;;; #\n;;; # 1. Redistributions of source code must retain the above copyright\n;;; #    notice, this list of conditions and the following disclaimer.\n;;; #    The contents of this file are deemed to be source code.\n;;; #\n;;; # 2. Redistributions in binary form must reproduce the above copyright\n;;; #    notice, this list of conditions and the following disclaimer in\n;;; #    the documentation and/or other materials provided with the\n;;; #    distribution.\n;;; #\n;;; # This work was supported in part by funding from the Defense Advanced\n;;; # Research Projects Agency, the Office of Naval Research and the National\n;;; # Science Foundation of the United States of America, and by member\n;;; # companies of the Carnegie Mellon Sphinx Speech Consortium. We acknowledge\n;;; # the contributions of many volunteers to the expansion and improvement of\n;;; # this dictionary.\n;;; #\n;;; # THIS SOFTWARE IS PROVIDED BY CARNEGIE MELLON UNIVERSITY ``AS IS'' AND\n;;; # ANY EXPRESSED OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,\n;;; # THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\n;;; # PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL CARNEGIE MELLON UNIVERSITY\n;;; # NOR ITS EMPLOYEES BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n;;; # SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n;;; # LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n;;; # DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n;;; # THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n;;; # (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n;;; # OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n;;; #\n;;; # ========================================================================\n;;; #\n;;;\n;;;  NOTES  ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n;;; \n;;;  [20080401] (air)  New dict file format introduced \n;;;   - comments (like this section) are allowed\n;;;   - file name is major version; vers/rev information is now in the header\n;;;\n;;; \n;;; ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n;;; \n!EXCLAMATION-POINT  EH2 K S K L AH0 M EY1 SH AH0 N P OY2 N T\n\"CLOSE-QUOTE  K L OW1 Z K W OW1 T\n\"DOUBLE-QUOTE  D AH1 B AH0 L K W OW1 T\n\"END-OF-QUOTE  EH1 N D AH0 V K W OW1 T\n\"END-QUOTE  EH1 N D K W OW1 T\n\"IN-QUOTES  IH1 N K W OW1 T S\n\"QUOTE  K W OW1 T\n\"UNQUOTE  AH1 N K W OW1 T\n#HASH-MARK  HH AE1 M AA2 R K\n#POUND-SIGN  P AW1 N D S AY2 N\n#SHARP-SIGN  SH AA1 R P S AY2 N\n%PERCENT  P ER0 S EH1 N T\n&AMPERSAND  AE1 M P ER0 S AE2 N D\n'ALLO  AA2 L OW1\n'APOSTROPHE  AH0 P AA1 S T R AH0 F IY0\n'BOUT  B AW1 T\n'CAUSE  K AH0 Z\n'COURSE  K AO1 R S\n'CUSE  K Y UW1 Z\n'EM  AH0 M\n'END-INNER-QUOTE  EH1 N D IH1 N ER0 K W OW1 T\n'END-QUOTE  EH1 N D K W OW1 T\n'FRISCO  F R IH1 S K OW0\n'GAIN  G EH1 N\n'INNER-QUOTE  IH1 N ER0 K W OW1 T\n'KAY  K EY1\n'M  AH0 M\n'N  AH0 N\n'QUOTE  K W OW1 T\n'ROUND  R AW1 N D\n'S  EH1 S\n'SINGLE-QUOTE  S IH1 NG G AH0 L K W OW1 T\n'TIL  T IH1 L\n'TIS  T IH1 Z\n'TWAS  T W AH1 Z\n(BEGIN-PARENS  B IH0 G IH1 N P ER0 EH1 N Z\n(IN-PARENTHESES  IH1 N P ER0 EH1 N TH AH0 S IY2 Z\n(LEFT-PAREN  L EH1 F T P ER0 EH1 N\n(OPEN-PARENTHESES  OW1 P AH0 N P ER0 EH1 N TH AH0 S IY2 Z\n(PAREN  P ER0 EH1 N\n(PARENS  P ER0 EH1 N Z\n(PARENTHESES  P ER0 EH1 N TH AH0 S IY2 Z\n)CLOSE-PAREN  K L OW1 Z P ER0 EH1 N\n)CLOSE-PARENTHESES  K L OW1 Z P ER0 EH1 N TH AH0 S IY2 Z\n)END-PAREN  EH1 N D P ER0 EH1 N\n)END-PARENS  EH1 N D P ER0 EH1 N Z\n)END-PARENTHESES  EH1 N D P ER0 EH1 N TH AH0 S IY2 Z\n)END-THE-PAREN  EH1 N D DH AH0 P ER0 EH1 N\n)PAREN  P ER0 EH1 N\n)PARENS  P ER0 EH1 N Z\n)RIGHT-PAREN  R AY1 T P EH2 R AH0 N\n)UN-PARENTHESES  AH1 N P ER0 EH1 N TH AH0 S IY1 Z\n+PLUS  P L UH1 S\n,COMMA  K AA1 M AH0\n--DASH  D AE1 SH\n-DASH  D AE1 SH\n-HYPHEN  HH AY1 F AH0 N\n...ELLIPSIS  IH2 L IH1 P S IH0 S\n.DECIMAL  D EH1 S AH0 M AH0 L\n.DOT  D AA1 T\n.FULL-STOP  F UH1 L S T AA1 P\n.PERIOD  P IH1 R IY0 AH0 D\n.POINT  P OY1 N T\n/SLASH  S L AE1 SH\n3-D  TH R IY1 D IY2\n3D  TH R IY1 D IY2\n:COLON  K OW1 L AH0 N\n;SEMI-COLON  S EH1 M IY0 K OW1 L AH0 N\n;SEMI-COLON(1)  S EH1 M IH0 K OW2 L AH0 N\n?QUESTION-MARK  K W EH1 S CH AH0 N M AA1 R K\nA  AH0\nA(1)  EY1\nA'S  EY1 Z\nA.  EY1\nA.'S  EY1 Z\nA.D.  EY2 D IY1\nA.M.  EY2 EH1 M\nA.S  EY1 Z\nA42128  EY1 F AO1 R T UW1 W AH1 N T UW1 EY1 T\nAA  EY2 EY1\nAAA  T R IH2 P AH0 L EY1\nAAAI  T R IH2 P AH0 L EY2 AY1\nAABERG  AA1 B ER0 G\nAACHEN  AA1 K AH0 N\nAACHENER  AA1 K AH0 N ER0\nAAH  AA1\nAAKER  AA1 K ER0\nAALIYAH  AA2 L IY1 AA2\nAALSETH  AA1 L S EH0 TH\nAAMODT  AA1 M AH0 T\nAANCOR  AA1 N K AO2 R\nAARDEMA  AA0 R D EH1 M AH0\nAARDVARK  AA1 R D V AA2 R K\nAARDVARKS  AA1 R D V AA2 R K S\nAARGH  AA1 R G\nAARHUS  AA2 HH UW1 S\nAARON  EH1 R AH0 N\nAARON'S  EH1 R AH0 N Z\nAARONS  EH1 R AH0 N Z\nAARONSON  EH1 R AH0 N S AH0 N\nAARONSON(1)  AA1 R AH0 N S AH0 N\nAARONSON'S  EH1 R AH0 N S AH0 N Z\nAARONSON'S(1)  AA1 R AH0 N S AH0 N Z\nAARTI  AA1 R T IY2\nAASE  AA1 S\nAASEN  AA1 S AH0 N\nAB  AE1 B\nABA  EY2 B IY2 EY1\nABABA  AH0 B AA1 B AH0\nABABA(1)  AA1 B AH0 B AH0\nABACHA  AE1 B AH0 K AH0\nABACK  AH0 B AE1 K\nABACO  AE1 B AH0 K OW2\nABACUS  AE1 B AH0 K AH0 S\nABAD  AH0 B AA1 D\nABADAKA  AH0 B AE1 D AH0 K AH0\nABADI  AH0 B AE1 D IY0\nABADIE  AH0 B AE1 D IY0\nABAIR  AH0 B EH1 R\nABALKIN  AH0 B AA1 L K IH0 N\nABALONE  AE2 B AH0 L OW1 N IY0\nABALONES  AE2 B AH0 L OW1 N IY0 Z\nABALOS  AA0 B AA1 L OW0 Z\nABANDON  AH0 B AE1 N D AH0 N\nABANDONED  AH0 B AE1 N D AH0 N D\nABANDONING  AH0 B AE1 N D AH0 N IH0 NG\nABANDONMENT  AH0 B AE1 N D AH0 N M AH0 N T\nABANDONMENTS  AH0 B AE1 N D AH0 N M AH0 N T S\nABANDONS  AH0 B AE1 N D AH0 N Z\nABANTO  AH0 B AE1 N T OW0\nABARCA  AH0 B AA1 R K AH0\nABARE  AA0 B AA1 R IY0\nABASCAL  AE1 B AH0 S K AH0 L\nABASH  AH0 B AE1 SH\nABASHED  AH0 B AE1 SH T\nABASIA  AH0 B EY1 ZH Y AH0\nABATE  AH0 B EY1 T\nABATED  AH0 B EY1 T IH0 D\nABATEMENT  AH0 B EY1 T M AH0 N T\nABATEMENTS  AH0 B EY1 T M AH0 N T S\nABATES  AH0 B EY1 T S\nABATING  AH0 B EY1 T IH0 NG\nABATTOIR  AE2 B AH0 T W AA1 R\nABBA  AE1 B AH0\n\n\n\nwith open('cmudict-0.7b', encoding = \"ISO-8859-1\") as f:\n    cmudict = [l.split() for l in f if l[:3] != \";;;\"]\n    cmudict = {w[0].lower(): w[1:] for w in cmudict}\n    \ncmudict[\"abstraction\"]\n\n['AE0', 'B', 'S', 'T', 'R', 'AE1', 'K', 'SH', 'AH0', 'N']\n\n\nThis dictionary uses what’s known as the ARPABET and represents stress using numeric indicators: 0 for no stress, 1 for primary stress, and 2 for secondary stress. The ARPABET maps to more recognizable IPA representations in the following way.\n\narpabet_to_phoneme = {'AA': 'ɑ', \n                      'AE': 'æ', \n                      'AH': 'ə', \n                      'AO': 'ɔ', \n                      'AW': 'aʊ', \n                      'AY': 'aɪ', \n                      'B': 'b', \n                      'CH': 'tʃ', \n                      'D': 'd', \n                      'DH': 'ð', \n                      'EH': 'ɛ',\n                      'ER': 'ɝ', \n                      'EY': 'eɪ', \n                      'F': 'f', \n                      'G': 'g', \n                      'HH': 'h', \n                      'IH': 'ɪ', \n                      'IY': 'i', \n                      'JH': 'dʒ', \n                      'K': 'k', \n                      'L': 'l', \n                      'M': 'm', \n                      'N': 'n',\n                      'NG': 'ŋ', \n                      'OW': 'oʊ', \n                      'OY': 'ɔɪ', \n                      'P': 'p', \n                      'R': 'ɹ', \n                      'S': 's', \n                      'SH': 'ʃ', \n                      'T': 't', \n                      'TH': 'θ', \n                      'UH': 'ʊ', \n                      'UW': 'u', \n                      'V': 'v',\n                      'W': 'w', \n                      'Y': 'j', \n                      'Z': 'z', \n                      'ZH': 'ʒ'}\n\nWe’ll use this mapping to construct the IPA representation from the ARPABET representation.\n\nimport re\n\nentries: dict[str, list[str]] = {\n    w: [arpabet_to_phoneme[''.join(re.findall('[A-z]', phoneme))]\n        for phoneme in transcription]\n        for w, transcription in cmudict.items()\n        if len({c for c in w})&gt;1\n        if len(transcription)&gt;1 \n        if not re.findall('[^A-z]', w[0])\n}\n\nFor instance, the IPA representation for the word abstraction can be accessed in the following way.\n\nentries[\"abstraction\"]\n\n['æ', 'b', 's', 't', 'ɹ', 'æ', 'k', 'ʃ', 'ʌ', 'n']\n\n\n\n\nDump IPA representation to file\nwith open(\"cmudict-ipa\", \"w\") as f:\n    for w, ipa in entries.items():\n        ipa = \" \".join(ipa)\n        f.write(f\"{w},{ipa}\\n\")"
  },
  {
    "objectID": "formal-and-practical-preliminaries/regular-expressions/basic-matching.html",
    "href": "formal-and-practical-preliminaries/regular-expressions/basic-matching.html",
    "title": "Basic Matching",
    "section": "",
    "text": "We mainly use regular expressions for searching, extracting from, and modifying strings. Each such use is underwritten by a string being in the set of strings that a regular expression evaluates to.\nOne core use of regular expressions is basic matching, which checks whether a string falls into the language that a regular expression evaluates to. We can describe matching formally in a couple ways. One is to view it as a function from a regular expression and a string to a boolean.\n\\[\\text{match}: R(\\Sigma)\\;\\times\\;\\Sigma^*  \\rightarrow \\{\\top, \\bot\\}\\]\n\\[\\text{match}(\\rho, \\sigma) = \\begin{cases}\\top & \\text{if } \\sigma \\in \\text{eval}(\\rho) \\\\\n\\bot & \\text{otherwise}\\end{cases}\\]\nWe can compute this function with fullmatch from the re module.\n\nimport re\n\nregex_æ = 'æ'\nstring_æ = 'æ'\n\nre.fullmatch(regex_æ, string_æ)\n\n&lt;re.Match object; span=(0, 1), match='æ'&gt;\n\n\nAnother is to view it as a function from strings to booleans parameterized by a regular expression \\(\\rho\\).\n\\[\\text{match}_\\rho: \\Sigma^*  \\rightarrow \\{\\top, \\bot\\}\\]\n\\[\\text{match}_\\rho(\\sigma) = \\begin{cases}\\top & \\text{if } \\sigma \\in \\text{eval}(\\rho) \\\\\n\\bot & \\text{otherwise}\\end{cases}\\]\nI’m pointing out this seemingly trivial distinction because it will be important when we discuss the concept of a grammar recognizing a string, where we will define a recognition algorithm for a particular class of grammars that we parameterize by grammars in that class.\nWe can compute this function by compiling the regular expression to a Pattern object…\n\nmatch_æ = re.compile(regex_æ)\n\ntype(match_æ)\n\nre.Pattern\n\n\n…then call the fullmatch instance method on this object.\n\nmatch_æ.fullmatch(string_æ)\n\n&lt;re.Match object; span=(0, 1), match='æ'&gt;\n\n\nBoth return a Match object (so its not a perfect implementation of the formal definition).\n\ntype(re.fullmatch(regex_æ, string_æ)), type(match_æ.fullmatch(string_æ))\n\n(re.Match, re.Match)\n\n\nBut if we try to cast this object to a bool we get True.\n\nbool(re.fullmatch(regex_æ, string_æ))\n\nTrue\n\n\nIn contrast, match returns None if there is no match.\n\nstring_æbstɹækʃən = 'æbstɹækʃən'\n\ntype(re.fullmatch(regex_æ, string_æbstɹækʃən))\n\nNoneType\n\n\nThis means that casting a non-match to a bool returns False.\n\nbool(re.fullmatch(regex_æ, string_æbstɹækʃən))\n\nFalse\n\n\nI point this out because you might expect that fullmatch would return a bool, but it doesn’t. This can be a problem if you’re not calling match within some if-else statement. Nonetheless, this is probably the most straightforward way to check whether a particularly pattern is matched by a string.\nYou might have noticed that there is another function match. It might seem like this functon would be simpler, but it has some odd behavior: it matches characters at the beginning of the string and ignores the rest of the string.\n\nre.match(regex_æ, string_æbstɹækʃən)\n\n&lt;re.Match object; span=(0, 1), match='æ'&gt;\n\n\nThe reason this is annoying is that this “beginning of the string” matching behavior is already built into regular expressions, which we’ll see in a second. It also means that re.match is not an implementation of the formal definition above."
  },
  {
    "objectID": "formal-and-practical-preliminaries/regular-expressions/groups-and-greediness.html#footnotes",
    "href": "formal-and-practical-preliminaries/regular-expressions/groups-and-greediness.html#footnotes",
    "title": "Groups and Greediness",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe dual of $ for the beginning of the string is ^. Note that this looks like the negation symbol we saw earlier. It is different in that that symbol must be preceded by [ to be interpreted as negation. Anywhere else ^ means the beginning of a string. That in turn means that putting a bare ^ anywhere besides the beginning of a regular expression is going to result in a regular expression that evaluates to the empty set.↩︎"
  },
  {
    "objectID": "formal-and-practical-preliminaries/elementary-mathematical-concepts/multisets.html#footnotes",
    "href": "formal-and-practical-preliminaries/elementary-mathematical-concepts/multisets.html#footnotes",
    "title": "Multisets",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNote that I’m passing the vowels in the multiset as a list to Counter. We crucially don’t want to pass them as a set, because that would destroy the multiplicities of the items.↩︎"
  },
  {
    "objectID": "formal-and-practical-preliminaries/elementary-mathematical-concepts/sets.html#footnotes",
    "href": "formal-and-practical-preliminaries/elementary-mathematical-concepts/sets.html#footnotes",
    "title": "Sets",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThere is a correlation between hashability and immutability, but they are not the same thing.↩︎"
  }
]