[
  {
    "objectID": "finite-state-models/formal-definition/index.html",
    "href": "finite-state-models/formal-definition/index.html",
    "title": "Overview",
    "section": "",
    "text": "Availability\n\n\n\nThis module will be available around March 4, 2024."
  },
  {
    "objectID": "finite-state-models/generative-capacity/index.html",
    "href": "finite-state-models/generative-capacity/index.html",
    "title": "Overview",
    "section": "",
    "text": "Availability\n\n\n\nThis module will be available around March 20, 2024."
  },
  {
    "objectID": "finite-state-models/recognition-and-parsing/index.html",
    "href": "finite-state-models/recognition-and-parsing/index.html",
    "title": "Overview",
    "section": "",
    "text": "Availability\n\n\n\nThis module will be available around March 18, 2024."
  },
  {
    "objectID": "finite-state-models/phonological-rules-as-fsas/index.html",
    "href": "finite-state-models/phonological-rules-as-fsas/index.html",
    "title": "Overview",
    "section": "",
    "text": "Availability\n\n\n\nThis module will be available around March 25, 2024."
  },
  {
    "objectID": "context-free-models/index.html",
    "href": "context-free-models/index.html",
    "title": "Overview",
    "section": "",
    "text": "Availability\n\n\n\nThis module will be available around March 27, 2024."
  },
  {
    "objectID": "mildly-context-sensitive-models/index.html",
    "href": "mildly-context-sensitive-models/index.html",
    "title": "Overview",
    "section": "",
    "text": "Availability\n\n\n\nThis module will be available around April 15, 2024."
  },
  {
    "objectID": "assignments/assignments-1-and-2.html",
    "href": "assignments/assignments-1-and-2.html",
    "title": "Assignments 1 and 2",
    "section": "",
    "text": "Assignment 1 will consist of Tasks 1-3 and Assignment 2 will consist of Tasks 4-8.\nIn these assignments, you will be implementing and testing a vowel harmony rule system for Turkish. Vowel harmony rule systems are intended to explain the fact that, in some languages, vowels in a word must have the same value on certain phonological features. Your job in this assignment will not be to derive the rule system itself. Rather, I’m going to give you a rule system to implement that works reasonably well, and we’ll ask where it fails."
  },
  {
    "objectID": "assignments/assignments-1-and-2.html#mathematical-objects",
    "href": "assignments/assignments-1-and-2.html#mathematical-objects",
    "title": "Assignments 1 and 2",
    "section": "Mathematical objects",
    "text": "Mathematical objects\nThroughout the assignments, I will be asking you to say what kind of mathematical object you are implementing in a particular task. The kind of answers you might give here are relation and function. If your response is function, it should be as specific as possible–e.g. the function may be partial or total. In addition to specifying partiality and totality, I’d also like you to specify whether a function is injective and/or surjective. An injective function is one where, if \\(f(x) = f(y)\\), then \\(x = y\\) for all \\(x\\) and \\(y\\). A surjective function is one where, if \\(f: X \\rightarrow Y\\), then \\(f(X) = Y\\)—i.e. the range of \\(f\\) is the same as its codomain; or said another way, the image of \\(X\\) under \\(f: X \\rightarrow Y\\) is \\(Y\\)."
  },
  {
    "objectID": "assignments/assignments-1-and-2.html#data",
    "href": "assignments/assignments-1-and-2.html#data",
    "title": "Assignments 1 and 2",
    "section": "Data",
    "text": "Data\nThis assignment uses Bruce Hayes’ phonological features spreadsheet—his FeaturesDoulosSIL.xls sheet, which I have converted into a UTF-8 encoded CSV for easier processing in Python. This file contains the equivalent of the IPA charts familiar to you from LIN110.\nYou do not need the full chart for this assignment, since we will only need access to four features–SYLLABIC, HIGH, FRONT, and ROUND–and the phones that Turkish has. We’ll work with the slightly altered version of the chart below, which only contains the features for these phones and maps 0 to -.\n\nfeatures = '''phone,syllabic,high,front,round\nɑ,+,-,-,-\nb,-,-,-,-\nd͡ʒ,-,-,-,-\nt͡ʃ,-,-,-,-\nd,-,-,-,-\ne,+,-,+,-\nf,-,-,-,-\nɟ,-,+,+,-\nj,-,+,+,-\nh,-,-,-,-\nɯ,+,+,-,-\ni,+,+,+,-\nʒ,-,-,-,-\nc,-,+,+,-\nl,-,-,-,-\nm,-,-,-,-\nn,-,-,-,-\no,+,-,-,+\nø,+,-,+,+\np,-,-,-,-\nɾ,-,-,-,-\ns,-,-,-,-\nʃ,-,-,-,-\nt,-,-,-,-\nu,+,+,-,+\ny,+,+,+,+\nv,-,-,-,-\nj,-,+,+,-\nz,-,-,-,-'''\n\nwith open('features.csv', 'w') as fout:\n    fout.write(features)\n\n\n%%bash\ncat features.csv\n\nphone,syllabic,high,front,round\nɑ,+,-,-,-\nb,-,-,-,-\nd͡ʒ,-,-,-,-\nt͡ʃ,-,-,-,-\nd,-,-,-,-\ne,+,-,+,-\nf,-,-,-,-\nɟ,-,+,+,-\nj,-,+,+,-\nh,-,-,-,-\nɯ,+,+,-,-\ni,+,+,+,-\nʒ,-,-,-,-\nc,-,+,+,-\nl,-,-,-,-\nm,-,-,-,-\nn,-,-,-,-\no,+,-,-,+\nø,+,-,+,+\np,-,-,-,-\nɾ,-,-,-,-\ns,-,-,-,-\nʃ,-,-,-,-\nt,-,-,-,-\nu,+,+,-,+\ny,+,+,+,+\nv,-,-,-,-\nj,-,+,+,-\nz,-,-,-,-\n\n\nIf you are interested in doing further work in computational phonology, you might also check out the panphon package, which provides various tools for working with featurizations of phones."
  },
  {
    "objectID": "assignments/assignments-1-and-2.html#definition",
    "href": "assignments/assignments-1-and-2.html#definition",
    "title": "Assignments 1 and 2",
    "section": "Definition",
    "text": "Definition\nTo represent (e.g. FRONT, ROUND, etc.) and feature values (+, -), we will use two Enum classes: Feature and FeatureValue. Using Enums here allows us to define the set of possible feature names and feature values and thereby constrain the values that can appear in feature valuations. This functionality is useful as an additional check on the correctness of our code–e.g. in the case that we get invalid feature names or feature values.\n\nfrom enum import Enum\n\nclass Feature(Enum):\n    SYLLABIC = \"syllabic\"\n    HIGH = \"high\"\n    FRONT = \"front\"\n    ROUND = \"round\"\n\n    def __repr__(self):\n        return self.value\n\n    def __str__(self):\n        return self.__repr__()\n\nclass FeatureValue(Enum):\n    PLUS = \"+\"\n    MINUS = \"-\"\n\n    def __repr__(self):\n        return self.value\n\n    def __str__(self):\n        return self.__repr__()\n\nTo represent the relationship between feature names and feature values—encoded in the rows of features.csv—we’ll be using FeatureValuation objects, which are just thin wrappers around a dictionary with feature names (e.g. FRONT, ROUND, etc.) as keys and feature values (+, -) as values.\nImportantly, note that, unlike dictionaries, FeatureValuations are hashable, since they implement the __hash__ magic method. Usually, we want hashables to be immutable–e.g. lists and sets are mutable and not hashable while tuples and frozensets are immutable and hashable–though python does not enforce this. In this case, I will demarcate that we want the core data of the feature valuation to be a private instance attribute FeatureValuation._valuation by prepending an underscore to the attribute name: when you see an underscore prepended like this, it is a convention that you should not modify its value from outside the object it is an attribute of. If you need to access the raw dictionary (and you will need to), you should use the FeatureValuation.valuation property.\nThe __hash__ magic method more specifically determines what the hash function from the python standard library outputs when applied to a FeatureValuation object. This output will be an integer that is used in determining how to identify when to instances of the class are the same for the purposes of uniquely identifying them within a collection—e.g. when an element of a set or a dict key.\nThe upshot for our purposes is that, if a class implements __hash__, its objects can be used as dictionary keys. The class also implements comparison between feature valuations: == (__eq__), &gt; (__gt__), &lt; (__lt__), &gt;= (__ge__), and &lt;= (__le__). This behavior will be very useful for some tasks.\n\nclass FeatureValuation:\n    '''A mapping from feature names to feature values\n    \n    Parameters\n    ----------\n    valuation\n        the feature valuation as a dictionary\n    '''\n    \n    def __init__(self, valuation: dict[str, str]):\n        self._valuation = {\n            Feature(f): FeatureValue(v) \n            for f, v in valuation.items()\n        }\n    \n    def __hash__(self) -&gt; int:\n        return hash(tuple(self._valuation.items()))\n    \n    def __getitem__(self, key: Feature) -&gt; FeatureValue:\n        return self._valuation[key]\n    \n    def __eq__(self, other: 'FeatureValuation') -&gt; bool:\n        self.__class__._check_type(other)\n        \n        return self._valuation == other._valuation\n    \n    def __lt__(self, other: 'FeatureValuation') -&gt; bool:\n        self.__class__._check_type(other)\n        \n        if set(self._valuation) &lt; set(other._valuation):\n            return all(other._valuation[k] == v \n                       for k, v in self._valuation.items())\n        else:\n            return False\n    \n    def __gt__(self, other: 'FeatureValuation') -&gt; bool:        \n        return other &lt; self\n\n    def __le__(self, other: 'FeatureValuation') -&gt; bool:\n        return self == other or self &lt; other\n    \n    def __ge__(self, other: 'FeatureValuation') -&gt; bool:\n        return self == other or self &gt; other\n\n    def __repr__(self):\n        return self._valuation.__repr__()\n\n    def __str__(self):\n        return self._valuation.__str__()\n    \n    @property\n    def valuation(self) -&gt; dict[Feature, FeatureValue]:\n        return dict(self._valuation) # makes a copy\n\n    @classmethod\n    def _check_type(cls, obj):\n        try:\n            assert isinstance(obj, cls)\n        except AssertionError:\n            raise ValueError(\n                'can only compute equality between'\n                ' two FeatureValuation objects'\n            )\n\nWe can construct a FeatureValuation by calling its __init__ magic method on a Dict[str, str].\n\nfv1 = FeatureValuation({'syllabic': '+', 'round': '+'})\nfv2 = FeatureValuation({'syllabic': '+', 'round': '+', 'high': '+'})\n\nAnd note that because FeatureValuations are hashable, we can use them as dictionary keys.\n\nv1 = {fv1: {'o', 'ø', 'u', 'y'}}\nv2 = {fv2: {'u', 'y'}}\n\nAnd because we have defined __eq__, __lt__, and __gt__, we can compare FeatureValuations. Make sure you understand what each comparison does. You will need at least one of these operations for the tasks below.\n\nfv1 == fv1, fv1 &lt; fv2, fv1 &gt; fv2\n\n(True, True, False)\n\n\nFinally, to show you that hash works and returns an integer:\n\nhash(fv2)\n\n-2436770590250344338"
  },
  {
    "objectID": "assignments/assignments-1-and-2.html#task-1",
    "href": "assignments/assignments-1-and-2.html#task-1",
    "title": "Assignments 1 and 2",
    "section": "Task 1",
    "text": "Task 1\nLines: 5\nDefine a class method from_csv in the PhonologicalFeatureChart1 class defined below. This method should take as input a string representation of the directory path fpath to features.csv and return a PhonologicalFeatureChart1 object. This object should have a dictionary-valued private attribute _phone_to_features with phones as keys and FeatureValuation objects as values.\n(Note: I’m calling this class PhonologicalFeatureChart1 so that we can subclass it later without a bunch of copying and pasting. This isn’t strictly necessary for subclassing purposes, since you could simply subclass an new version of PhonologicalFeatureChart with an old version; but it’s useful here so that, if you run the cells out of order, you know exactly which version of the class you’re working with.) I’ll do this for other classes below without comment.)\n\nclass PhonologicalFeatureChart1:\n    '''The phonological features of different phones'''\n\n    def __init__(self, phone_to_features: Dict[str, FeatureValuation]):\n        self._phone_to_features = phone_to_features\n\n    def __repr__(self):\n        return self._phone_to_features.__repr__()\n\n    def __str__(self):\n        return self._phone_to_features.__str__()\n\n    @classmethod\n    def from_csv(cls, fpath: str='features.csv') -&gt; 'PhonologicalFeatureChart1':\n        '''Load Hayes' phonological feature chart\n\n        Parameters\n        ----------\n        fpath\n            path to phonological feature chart as a csv\n        '''\n\n        # remove after implementing\n        raise NotImplementedError\n\n    def phone_to_features(self, phone: str) -&gt; FeatureValuation:\n        return self._phone_to_features[phone]\n\nWrite a test that checks for the correctness of from_csv by calling phone_to_features on some phone and making sure that it returns the correct feature valuation. (The fact that feature valuations implement __eq__ will be useful for this.) This (and all future) test should use standard Python exception handling facilities (try-except).\n\ntry:\n    phonological_feature_chart = PhonologicalFeatureChart1.from_csv()\nexcept NotImplementedError:\n    print(\"You still need to implement PhonologicalFeatureChart1.from_csv.\")\n\n# WRITE TESTS HERE\n\nYou still need to implement PhonologicalFeatureChart1.from_csv\n\n\nReferring to the set of feature as \\(F = \\{\\text{FRONT}, \\text{ROUND}, \\text{HIGH}, \\text{SYLLABIC}\\}\\) and the set of feature values as \\(V = \\{+, -\\}\\), explain what kind of mathematical object the feature valuations you just constructed are. If they are functions, say whether they are injective and/or surjective. Note that I am not asking about all possible feature valuations—just the ones constructed in from_csv.\nWRITE YOUR ANSWER HERE"
  },
  {
    "objectID": "assignments/assignments-1-and-2.html#task-2",
    "href": "assignments/assignments-1-and-2.html#task-2",
    "title": "Assignments 1 and 2",
    "section": "Task 2",
    "text": "Task 2\nLines: 2\nDefine an instance method phone_from_features in the PhonologicalFeatureChart2 class that takes as input a FeatureValuation object and returns the set of phones that match that feature valuation. Assume that feature valuations need not specify a feature value for all feature names—e.g. the following should still return something (namely, all the high vowels).\n\ntry:\n    chart = PhonologicalFeatureChart2.from_csv('features.csv')\n    valuation = FeatureValuation({'syllabic': '+', 'high': '+'})\n    chart.phone_from_features(valuation)\nexcept NameError:\n    print(\"You still need to define PhonologicalFeatureChart2.\")\n\nYou still need to define PhonologicalFeatureChart2\n\n\nWe will refer to valuations like this as partial feature valuations.\nNote that you need to return a set because some phones are not uniquely determined by the features in features.csv—e.g. all consonants (besides the semivowels) will be - on these features. Further, it may return an empty set, since some feature combinations do not show up in features.csv—e.g. [-SYLLABIC, +ROUND].\n\nclass PhonologicalFeatureChart2(PhonologicalFeatureChart1):\n    '''The phonological features of different phones'''\n\n    def phone_from_features(self, features: FeatureValuation) -&gt; set[str]:\n        '''The phones that have a particular feature valuation\n\n        Parameters\n        ----------\n        features\n            the feature valuation\n        '''\n\n        # remove after implementing\n        raise NotImplementedError\n\nWrite a test that checks for the correctness of phone_from_features. This test should check at least five cases: (i) one where a singleton set should be returned when a total feature valuation is input; (ii) one where an empty set should be returned when a total feature valuation is input; (iii) one where a non-empty, non-singleton set should be returned when a total feature valuation is input; (iv) one where an empty set should be returned when a partial feature valuation is input; and (v) one where a non-empty, non-singleton set should be returned when a partial feature valuation is input.\n\n# WRITE TESTS HERE\n\nExplain what kind of mathematical object phone_from_features implements and what kind of object a partial feature valuation is, referring to the set of phones as \\(P\\). There are two possible answers here depending on what you take the right side of the relation/function to be.\nWRITE YOUR ANSWER HERE"
  },
  {
    "objectID": "assignments/assignments-1-and-2.html#task-3",
    "href": "assignments/assignments-1-and-2.html#task-3",
    "title": "Assignments 1 and 2",
    "section": "Task 3",
    "text": "Task 3\nLines: 2\nUsing your phone_from_features method, define an instance method alter_features_of_phone in PhonologicalFeatureChart (our final version, so no number) that takes as input a phone and a (partial) feature valuation like valuation above. This function should return the set of phones that correspond to setting that phone’s features to the values listed in the feature valuation. For instance, if I passed this function the phone /u/ and the (partial) feature valuation [-ROUND], the function should return {/ɯ/}, but if I passed it /u/ and the feature valuation [-SYLLABIC, -HIGH, -LOW, -ROUND], it should return the set of consonants.\n\nclass PhonologicalFeatureChart(PhonologicalFeatureChart2):\n    '''The phonological features of different phones'''\n\n    def alter_features_of_phone(\n        self, phone: str, \n        features: FeatureValuation\n    ) -&gt; Set[str]:\n        '''The phones with features altered\n\n        Parameters\n        ----------\n        phone\n            the phone whose features we want to alter\n        features\n            the feature to alter\n        '''\n\n        # remove after implementing\n        raise NotImplementedError\n\nWrite a test that checks for the correctness of alter_features_of_phone. This test should check the same five kinds of cases that your test for Task 2 checked.\n\n# WRITE TESTS HERE\n\nExplain what kind of mathematical object alter_features_of_phone implements. There are two possible answers here depending on what you take the right side of the relation/function to be. Note that the left side of the relation is a tuple.\nWRITE YOUR ANSWER HERE"
  },
  {
    "objectID": "assignments/assignments-1-and-2.html#data-1",
    "href": "assignments/assignments-1-and-2.html#data-1",
    "title": "Assignments 1 and 2",
    "section": "Data",
    "text": "Data\nThe remainder of this assignment is based on data from the UniMorph project – specifically, Turkish UniMorph. The UniMorph project provides a schema for annotating word forms with their root form and the morphological features they express across languages, as well as annotated data for (currently) 168 languages. Take a look at the Turkish dataset. You’ll notice that it consists of three columns.\n    hamsi          hamsiler          N;NOM;PL\n    hamsi          hamsilere         N;DAT;PL\n    hamsi          hamsilerden       N;ABL;PL\n    hamsi          hamsinin          N;GEN;SG\n    hamsi          hamsiye           N;DAT;SG\n    hamsi          hamsiyi           N;ACC;SG\n    hamsi          hamsilerin        N;GEN;PL\n    hamsi          hamsileri         N;ACC;PL\n    hamsi          hamsiden          N;ABL;SG\n    hamsi          hamsilerde        N;LOC;PL\n    hamsi          hamside           N;LOC;SG\n    hamsi          hamsi             N;NOM;SG\nThe second column contains word forms; the first contains the root corresponding to that form; and the third corresponds to the part of speech of and morphological features expressed by that form, separated by ;.\nI have included some code below that should make working with these data easier by loading Turkish Unimorph as an instance of my custom Unimorph class, defined below. Before moving forward, read through this code to make sure you understand what turkish_unimorph is.\n\nfrom collections import defaultdict\n\nclass Unimorph:\n\n    def __init__(self, fpath, pos_filter=lambda x: True, root_filter=lambda x: True,\n                 word_filter=lambda x: True, feature_filter=lambda x: True,\n                 graph_to_phone_map=None):\n\n        self._graph_to_phone_map = graph_to_phone_map\n\n        self._pos_filter = pos_filter\n        self._root_filter = root_filter\n        self._word_filter = word_filter\n        self._feature_filter = feature_filter\n        \n        self._load_unimorph(fpath)\n\n    def __getitem__(self, key):\n        return self._pos_to_word_to_features[key]\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        try:\n            return next(self._gen)\n        except StopIteration:\n            self._initialize_gen()\n            raise\n\n    def _load_unimorph(self, fpath):\n        '''load unimorph file and convert graphs to ipa\n\n        Parameters\n        ----------\n        fpath : str\n            path to unimorph data\n        \n\n        Returns\n        -------\n        tuple(dict)\n        '''\n\n        pos_to_word_to_features = defaultdict(lambda:\n                                              defaultdict(lambda:\n                                                          defaultdict(set)))\n\n        with open(fpath) as f:\n            for line in f:\n                line_split = line.strip().split('\\t')\n\n                if len(line_split) != 3:\n                    continue\n\n                root, word, pos_features = line_split\n\n                pos_features_split = pos_features.split(';')\n\n                pos = pos_features_split[0]\n                features = set(pos_features_split[1:])\n\n                if self._graph_to_phone_map is not None:\n                    try:\n                        root = self._convert_graph_to_phone(root)\n                        word = self._convert_graph_to_phone(word)\n                    except KeyError:\n                        continue\n                else:\n                    root = tuple(root)\n                    word = tuple(word)\n                        \n\n                keep = self._pos_filter(pos)\n                keep &= self._root_filter(root)\n                keep &= self._word_filter(word)\n                keep &= self._feature_filter(features)\n\n                if keep:\n                    pos_to_word_to_features[pos][root][word] = features\n\n        # freeze dict so it is no longer a defaultdict\n        self._pos_to_word_to_features = dict(pos_to_word_to_features)\n\n        self._initialize_gen()\n\n    def _initialize_gen(self):\n        self._gen = ((pos, root, word, features)\n                     for pos, d1 in self._pos_to_word_to_features.items()\n                     for root, d2 in d1.items()\n                     for word, features in d2.items())\n        \n    def _convert_graph_to_phone(self, word):\n        '''map graphs to phones\n\n        Parameters\n        ----------\n        word : str\n            the word as a string of graphs\n\n        Returns\n        -------\n        str\n        '''\n\n        # this takes the last phone in the list\n        # it should maybe create a set of possible words\n        return tuple([self._graph_to_phone_map[graph][-1]\n                      for graph in word])\n\n\ngraph_to_phone_map = {'a': ['ɑ'],\n                      'b': ['b'],\n                      'c': ['d͡ʒ'],\n                      'ç': ['t͡ʃ'],\n                      'd': ['d'],\n                      'e': ['e'],\n                      'f': ['f'],\n                      'g': ['ɡ̟', 'ɟ'],\n                      'ğ': ['ː', '‿', 'j'],\n                      'h': ['h'],\n                      'ı': ['ɯ'],\n                      'i': ['i'],\n                      'j': ['ʒ'],\n                      'k': ['k', 'c'],\n                      'l': ['ɫ', 'l'],\n                      'm': ['m'],\n                      'n': ['n'],\n                      'o': ['o'],\n                      'ö': ['ø'],\n                      'p': ['p'],\n                      'r': ['ɾ'],\n                      's': ['s'],\n                      'ş': ['ʃ'],\n                      't': ['t'],\n                      'u': ['u'],\n                      'ü': ['y'],\n                      'v': ['v'],\n                      'y': ['j'],\n                      'z': ['z'],\n                      ' ': [' ']}\n\n\nimport requests\nfrom io import BytesIO\nfrom zipfile import ZipFile\n\nturkish_unimorph_url = 'https://github.com/unimorph/tur/archive/master.zip'\nturkish_unimorph_zip = requests.get(turkish_unimorph_url).content\n\nwith ZipFile(BytesIO(turkish_unimorph_zip)) as zf:\n    with zf.open('tur-master/tur') as f_in:\n        with open('tur.txt', 'w') as f_out:\n            f_out.write(f_in.read().decode())\n\n\nturkish_unimorph = Unimorph('tur.txt',\n                            pos_filter=lambda x: x == 'N',\n                            root_filter=lambda x: ' ' not in x,\n                            word_filter=lambda x: ' ' not in x,\n                            feature_filter=lambda x: x.issubset({'PL', 'GEN'}),\n                            graph_to_phone_map=graph_to_phone_map)\n\nThere are two important things to notice. First, words and roots are represented as tuples of strings, instead of strings. The reason for this is that (i) I map each root and word in Turkish Unimorph to a phonetic/phonemic representation using a fixed mapping from graphs to phones; and (ii) some phones are represented as digraphs or trigraphs in unicode (e.g. t͡ʃ), so if we mapped from strings of graphs to strings of phones, it would be difficult to recover which characters in a string are a single phone and which are part of a phone that unicode represents with multiple symbols. Second, my Unimorph class allows the user to pass filters to the constructor __init__. In the current case, I have set these filters so our Unimorph instance only contains plural and/or genitive nouns."
  },
  {
    "objectID": "assignments/assignments-1-and-2.html#task-4",
    "href": "assignments/assignments-1-and-2.html#task-4",
    "title": "Assignments 1 and 2",
    "section": "Task 4",
    "text": "Task 4\nLines: 24\nIn standard descriptions of Turkish, the vowel harmony rule system plays out on three features: height [+/-HIGH], frontness [+/-FRONT], and roundedness [+/-ROUND]. Roughly, if a vowel is high, it must match with the immediately previous vowel on both frontness and roundedness; and if it is not high and not round, it must match with the immediately previous vowel on frontness.\nUsing your alter_features_of_phone method, define a class TurkishVowelHarmony1 whose instances take as input a word and applies the vowel harmony rule system to it (implemented using the __call__ magic method). Pay special attention to the fact that this system only looks at the immediately previous vowel.\n\nString = tuple[str]\n\nclass TurkishVowelHarmony1:\n    '''The Turkish vowel harmony system'''\n    \n    def __call__(self, word: String) -&gt; String:\n        '''Apply the vowel harmony rule\n        \n        Parameters\n        ----------\n        word\n            the word to apply the vowel harmony rule to\n        '''\n        \n        # remove after implementing\n        raise NotImplementedError\n\nWrite a test that checks for the correctness of __call__. It should check at least six cases: (i) three randomly selected words found in Turkish Unimorph where the result of applying a TurkishVowelHarmony1 object to those words returns the same word back; and (ii) three randomly selected words found in Turkish Unimorph where it doesn’t.\n\n# WRITE TESTS HERE\n\nExplain what kind of mathematical object turkish_vowel_harmony implements, referring to the set of Turkish phones as \\(\\Sigma\\) and the set of strings over those phones as \\(\\Sigma^*\\). (Remember that \\(\\Sigma^* \\equiv \\bigcup_i^\\infty \\Sigma^i\\).)\nWRITE YOUR ANSWER HERE"
  },
  {
    "objectID": "assignments/assignments-1-and-2.html#task-5",
    "href": "assignments/assignments-1-and-2.html#task-5",
    "title": "Assignments 1 and 2",
    "section": "Task 5",
    "text": "Task 5\nLines: 1\nA disharmonic form is a root/word that does not obey the vowel harmony rule. Write an instance method disharmonic in TurkishVowelHarmony that maps a root or word to a boolean indicating whether or not it that root or word is disharmonic.\n\nclass TurkishVowelHarmony2(TurkishVowelHarmony1):\n    '''The Turkish vowel harmony system'''\n    \n    def disharmonic(self, word: Tuple[str]) -&gt; bool:\n        '''Whether the word is disharmonic\n        \n        Parameters\n        ----------\n        word\n            the word to check for disharmony\n        '''\n        \n        # remove after implementing\n        raise NotImplementedError\n\nWrite a test that checks for the correctness of disharmonic. It should check the same six cases you used to test __call__.\n\n# WRITE TESTS HERE"
  },
  {
    "objectID": "assignments/assignments-1-and-2.html#task-6",
    "href": "assignments/assignments-1-and-2.html#task-6",
    "title": "Assignments 1 and 2",
    "section": "Task 6",
    "text": "Task 6\nLines: 2\nUsing your disharmonic method, write another instance method proportion_disharmonic_roots to compute the proportion of roots that are disharmonic in Turkish Unimorph.\n\nclass TurkishVowelHarmony3(TurkishVowelHarmony2):\n    '''The Turkish vowel harmony system'''\n    \n    def proportion_disharmonic_roots(self, lexicon: Unimorph) -&gt; float:\n        '''The proportion of words that are disharmonic in the lexicon\n        \n        Parameters\n        ----------\n        lexicon\n            the Unimorph lexicon to check for disharmony\n        '''\n        \n        # remove after implementing\n        raise NotImplementedError"
  },
  {
    "objectID": "assignments/assignments-1-and-2.html#task-7",
    "href": "assignments/assignments-1-and-2.html#task-7",
    "title": "Assignments 1 and 2",
    "section": "Task 7",
    "text": "Task 7\nLines: 7\nUsing your disharmonic method, write an instance method xtab_root_word_harmony to cross-tabulate the proportion of words that are disharmonic against whether those words’ roots are disharmonic. The method should print that cross-tabulation as a \\(2 \\times 2\\) table with root (dis)harmony along the rows and word (dis)harmony along the columns.\n\nclass TurkishVowelHarmony4(TurkishVowelHarmony3):\n    '''The Turkish vowel harmony system'''\n    \n    def xtab_root_word_harmony(self, lexicon: Unimorph) -&gt; None:\n        '''Cross-tabulate word disharmony against root disharmony\n        \n        This should print (not return) a table represented as a list of lists:\n        \n                         | harmonic word | disharmonic word |\n                         ------------------------------------\n           harmonic root |               |                  |\n        disharmonic root |               |                  |\n        \n        Parameters\n        ----------\n        lexicon\n            the Unimorph lexicon to check for disharmony\n        '''\n        \n        # remove after implementing\n        raise NotImplementedError\n\nExplain the pattern that you see in this table.\nWRITE YOUR ANSWER HERE"
  },
  {
    "objectID": "assignments/assignments-1-and-2.html#task-8",
    "href": "assignments/assignments-1-and-2.html#task-8",
    "title": "Assignments 1 and 2",
    "section": "Task 8",
    "text": "Task 8\nLines: 1\nUsing your disharmonic function, write an instance method get_disharmonic to find all of the words of some category (e.g. N, V, etc.) with a particular set of features (e.g. {plural, genitive}, etc.). Use that method to find all the plural and/or genitive nouns with disharmonic roots. Note that I’ve prefiltered Turkish Unimorph to just the plural and genitive nouns, but this method should still work for arbitrary categories and morphological features.\n\nclass TurkishVowelHarmony(TurkishVowelHarmony4):\n    '''The Turkish vowel harmony system'''\n    \n    def get_disharmonic(self, \n                        lexicon: Unimorph, \n                        category: str,\n                        features: Set[str]) -&gt; Set[Tuple[str]]:\n        '''Find all of the words of some category with a particular set of features\n        \n        Parameters\n        ----------\n        lexicon\n            the Unimorph lexicon to check for disharmony\n        category\n            some category (e.g. \"N\", \"V\", etc.)\n        features\n            some set of features (e.g. {\"PL\", \"GEN\"}, etc.)\n        '''\n        \n        # remove after implementing\n        raise NotImplementedError\n\nExplain what pattern you see in the vowels of the plural and genitive affixes. (A prerequisite for answering this question is figuring out what the plural and genitive affixes are.)\nWRITE YOUR ANSWER HERE"
  },
  {
    "objectID": "assignments/assignments-3-and-4.html",
    "href": "assignments/assignments-3-and-4.html",
    "title": "Assignments 3 and 4",
    "section": "",
    "text": "Like Assignments 1 and 2, Assignments 3 and 4 are bundled together. You only need to do Task 1 for Assignment 3 and Tasks 2 and 3 for Assignment 4.\nThese assignments focus on implementing fuzzy tree search. In class, we developed various tree search algorithms that look for an exact match between a query and the data contained in particular trees. I’ve copied in the relevant class below as TreeOld.\nimport pyparsing\nfrom typing import TypeVar, Union\nfrom rdflib import Graph, URIRef\n\nDataType = TypeVar(\"DataType\")\nTreeList = list[str | tuple[Union[str, 'TreeList']]]\n\nclass TreeOld:\n    \"\"\"A tree\n    \n    Parameters\n    ----------\n    data\n    children\n    \"\"\"\n    \n    RDF_TYPES = {}\n    RDF_EDGES = {'is': URIRef('is-a'),\n                 'parent': URIRef('is-the-parent-of'),\n                 'child': URIRef('is-a-child-of'),\n                 'sister': URIRef('is-a-sister-of')}\n    \n    LPAR = pyparsing.Suppress('(')\n    RPAR = pyparsing.Suppress(')')\n    DATA = pyparsing.Regex(r'[^\\(\\)\\s]+')\n\n    PARSER = pyparsing.Forward()\n    SUBTREE = pyparsing.ZeroOrMore(PARSER)\n    PARSERLIST = pyparsing.Group(LPAR + DATA + SUBTREE + RPAR)\n    PARSER &lt;&lt;= DATA | PARSERLIST\n    \n    def __init__(self, data: DataType, children: list['TreeOld'] = []):\n        self._data = data\n        self._children = children\n        \n        self._validate()\n  \n    def __str__(self):\n        if self._children:\n            return ' '.join(c.__str__() for c in self._children)\n        else:\n            return str(self._data)\n        \n    def __repr__(self):\n        return self.to_string()\n     \n    def to_string(self, depth: int = 0) -&gt; str:\n        s = (depth - 1) * '  ' +\\\n            int(depth &gt; 0) * '--' +\\\n            self._data + '\\n'\n        s += ''.join(c.to_string(depth+1)\n                     for c in self._children)\n        \n        return s\n\n    def __contains__(self, data: DataType) -&gt; bool:\n        # pre-order depth-first search\n        if self._data == data:\n            return True\n        else:\n            for child in self._children:\n                if data in child:\n                    return True\n                \n            return False\n        \n    def __getitem__(self, idx: tuple[int]) -&gt; DataType:\n        if isinstance(idx, int):\n            return self._children[idx]\n        elif len(idx) == 1:\n            return self._children[idx[0]]\n        elif idx:\n            return self._children[idx[0]].__getitem__(idx[1:])\n        else:\n            return self\n        \n    @property\n    def data(self) -&gt; DataType:\n        return self._data \n    \n    @property\n    def children(self) -&gt; list['TreeOld']:\n        return self._children\n        \n    def _validate(self):\n        try:\n            assert all(isinstance(c, Tree)\n                       for c in self._children)\n        except AssertionError:\n            msg = 'all children must be trees'\n            raise TypeError(msg)\n            \n    def index(self, data: DataType, index_path: tuple[int] = tuple()):\n        indices = [index_path] if self._data==data else []\n        root_path = [] if index_path == -1 else index_path\n        \n        indices += [j \n                    for i, c in enumerate(self._children) \n                    for j in c.index(data, root_path+(i,))]\n\n        return indices\n            \n    def to_rdf(\n        self, \n        graph: Graph | None=None, \n        nodes: dict[int, URIRef] = {}, \n        idx: tuple[int] = tuple()\n    ) -&gt; Graph: \n        graph = Graph() if graph is None else graph\n        \n        idxstr = '_'.join(str(i) for i in idx)\n        nodes[idx] = URIRef(idxstr)\n            \n        if self._data not in self.RDF_TYPES:\n            self.RDF_TYPES[self._data] = URIRef(self._data)\n\n        typetriple = (nodes[idx], \n                      self.RDF_EDGES['is'],\n                      self.RDF_TYPES[self.data])\n\n        graph.add(typetriple)\n\n        for i, child in enumerate(self._children):\n            childidx = idx+(i,)\n            child.to_rdf(graph, nodes, childidx)\n                \n            partriple = (nodes[idx], \n                         self.RDF_EDGES['parent'],\n                         nodes[childidx])\n            chitriple = (nodes[childidx], \n                         self.RDF_EDGES['child'],\n                         nodes[idx])\n            \n            graph.add(partriple)\n            graph.add(chitriple)\n            \n        for i, child1 in enumerate(self._children):\n            for j, child2 in enumerate(self._children):\n                child1idx = idx+(i,)\n                child2idx = idx+(j,)\n                sistriple = (nodes[child1idx], \n                             Tree.RDF_EDGES['sister'],\n                             nodes[child2idx])\n                \n                graph.add(sistriple)\n        \n        self._rdf_nodes = nodes\n        \n        return graph\n    \n    @property\n    def rdf(self) -&gt; Graph:\n        return self.to_rdf()\n    \n    def find(self, query):\n        return [tuple([int(i) \n                       for i in str(res[0]).split('_')]) \n                for res in self.rdf.query(query)]\n    \n    @classmethod\n    def from_string(cls, treestr: str) -&gt; 'TreeOld':\n        treelist = cls.PARSER.parseString(treestr[2:-2])[0]\n        \n        return cls.from_list(treelist)\n    \n    @classmethod\n    def from_list(cls, treelist: TreeList):\n        if isinstance(treelist, str):\n            return cls(treelist[0])\n        elif isinstance(treelist[1], str):\n            return cls(treelist[0], [cls(treelist[1])])\n        else:\n            return cls(treelist[0], [cls.from_list(l) for l in treelist[1:]])\nIn fuzzy search, we allow this exact matching restriction to be loosened by instead allowing that matches be (i) within some fixed edit distance; and/or (ii) closest (in terms of edit distance) to the query among all pieces of data. I’ve copied the relevant edit distance class that we developed in class below as EditDistance.\nimport numpy as np\n\nclass EditDistance:\n    '''Distance between strings\n\n\n    Parameters\n    ----------\n    insertion_cost\n    deletion_cost\n    substitution_cost\n    '''\n    \n    def __init__(self, insertion_cost: float = 1., \n                 deletion_cost: float = 1., \n                 substitution_cost: float | None = None):\n        self._insertion_cost = insertion_cost\n        self._deletion_cost = deletion_cost\n\n        if substitution_cost is None:\n            self._substitution_cost = insertion_cost + deletion_cost\n        else:\n            self._substitution_cost = substitution_cost\n\n    def __call__(self, source: str | list[str], target: str | list[str]) -&gt;  float:\n        '''The edit distance between the source and target\n        \n        The use of lists enables digraphs to be identified\n        \n        Parameters\n        ----------\n        source\n        target\n        '''\n        \n        # coerce to list if not a list\n        if isinstance(source, str):\n            source = list(source)\n            \n        if isinstance(target, str):\n            target = list(target)\n        \n        n, m = len(source), len(target)\n        source, target = ['#']+source, ['#']+target\n\n        distance = np.zeros([n+1, m+1], dtype=float)\n        \n        for i in range(1,n+1):\n            distance[i,0] = distance[i-1,0]+self._deletion_cost\n\n        for j in range(1,m+1):\n            distance[0,j] = distance[0,j-1]+self._insertion_cost\n            \n        for i in range(1,n+1):\n            for j in range(1,m+1):\n                if source[i] == target[j]:\n                    substitution_cost = 0.\n                else:\n                    substitution_cost = self._substitution_cost\n                    \n                costs = np.array([distance[i-1,j]+self._deletion_cost,\n                                  distance[i-1,j-1]+substitution_cost,\n                                  distance[i,j-1]+self._insertion_cost])\n                    \n                distance[i,j] = costs.min()\n                \n        return distance[n,m]"
  },
  {
    "objectID": "assignments/assignments-3-and-4.html#task-1",
    "href": "assignments/assignments-3-and-4.html#task-1",
    "title": "Assignments 3 and 4",
    "section": "Task 1",
    "text": "Task 1\nLines: 14\nDefine an instance method fuzzy_find. This method should take a piece of query data and optionally a distance and return all of the nodes that have data that is within edit distance distance from data; and/or if , closest is True, it should return all of the nodes closest to data among all nodes in the tree.\nFor instance:\n\nfuzzy_find('review', distance=3., closest=False) will return a tuple of every piece of data in the tree within edit distance 3 from review (e.g. view, reviewer, reviews, etc.), its distance to review, and its index; if there is nothing within that edit distance, an empty list will be returned\nfuzzy_find('review', distance=3., closest=True) will return a tuple of the closest pieces of data in the tree that are also within edit distance 3 from review (e.g. view, reviewer, reviews, etc.), its distance to review, and its index; if there is nothing within that edit distance, an empty list will be returned\nfuzzy_find('review', distance=np.inf, closest=True) will return a tuple of the closest pieces of data in the tree to review (e.g. view, reviewer, reviews, etc.), regardless of edit distance, its distance to review, and its index; this will always return something\nfuzzy_find('review', distance=np.inf, closest=False) will return a tuple of every piece of data in the tree to review (e.g. view, reviewer, reviews, etc.), regardless of edit distance, its distance to review, and its index; this will always return a list with as many elements as there are nodes in the tree\n\nThis method should also support only searching the terminal nodes (leaves) of the tree with the flag terminals_only.\nHint: you should look back at the methods we defined for searching and indexing the tree above. Specifically, to understand why you might want something like index_path defaulting to the empty tuple, look at the index method of TreeOld.\n\nFuzzyFindResult = tuple[tuple, str | list[str], float]\n\nclass Tree(TreeOld):\n    \n    DIST = EditDistance(1., 1.)\n    \n    def fuzzy_find(self, data: Union[str, List[str]], \n                   closest: bool = True, \n                   distance: float = np.inf,\n                   case_fold: bool = True,\n                   terminals_only: bool = True,\n                   index_path: tuple = tuple()) -&gt; list[FuzzyFindResult]:\n        \n        '''Find the (closest) strings within a certain distance\n        \n        Defaults to computing the closest strings among the terminals and ignoring case\n        \n        The format of the things returned is [((0,1,0), \"view\", 2.0), ...]. Note that \n        edit distance can be computed on either a `str` or `List[str]`; that's why\n        the middle element of each tuple might be either.\n        \n        Parameters\n        ----------\n        data\n            the data to match against\n        closest\n            whether to return only the closest strings or all strings within distance\n        distance\n            the distance within which a string must be\n        case_fold\n            whether to lower-case the data\n        terminals_only\n            whether to only search the terminals\n        index_path\n        '''\n        raise NotImplementedError\n\nWrite tests that use the following tree as input data.\n\ntreestr = '( (SBARQ (WHNP-1 (WP What)) (SQ (NP-SBJ-1 (-NONE- *T*)) (VP (VBZ is) (NP-PRD (NP (DT the) (JJS best) (NN place)) (SBAR (WHADVP-2 (-NONE- *0*)) (S (NP-SBJ (-NONE- *PRO*)) (VP (TO to) (VP (VB get) (NP (NP (NNS discounts)) (PP (IN for) (NP (NML (NNP San) (NNP Francisco)) (NNS restaurants)))) (ADVP-LOC-2 (-NONE- *T*))))))))) (. ?)) )'\n\ntesttree = Tree.from_string(treestr)\n\ntesttree\n\nSBARQ\n--WHNP-1\n  --WP\n    --What\n--SQ\n  --NP-SBJ-1\n    ---NONE-\n      --*T*\n  --VP\n    --VBZ\n      --is\n    --NP-PRD\n      --NP\n        --DT\n          --the\n        --JJS\n          --best\n        --NN\n          --place\n      --SBAR\n        --WHADVP-2\n          ---NONE-\n            --*0*\n        --S\n          --NP-SBJ\n            ---NONE-\n              --*PRO*\n          --VP\n            --TO\n              --to\n            --VP\n              --VB\n                --get\n              --NP\n                --NP\n                  --NNS\n                    --discounts\n                --PP\n                  --IN\n                    --for\n                  --NP\n                    --NML\n                      --NNP\n                        --San\n                      --NNP\n                        --Francisco\n                    --NNS\n                      --restaurants\n              --ADVP-LOC-2\n                ---NONE-\n                  --*T*\n--.\n  --?\n\n\nThe tests should test the four combinations of distance and closest listed above with the same query data, both with and without terminals_only=True and terminals_only=False (eight tests in total). Two further tests should test distance=np.inf, closest=True, terminals_only=True for a case where only a single element should be returned and a case where multiple elements in the tree should be returned.\n\n# write tests here\n\nRemember that we talked in class about what it would mean to take the distance between a string and a collection of strings: basically, the minimum of the edit distances between the string and each string in that set.\nWe can use this concept in two ways here. The first is to view the tree as a container for some data and to compute the minimum distance between a query and any data contained in the tree. Alternatively, we can think of the query itself as determining a set and compute the minimum distance of each piece of data in the tree to that set. Task 2 will implement the former and Task 3 the latter.\nI’ve copied the corpus reader we developed for the English Web Treebank in class below. We’ll make use of this for Task 2. (You’ll need to grab LDC2012T13.tgz from the course Google drive.)\n\n!wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1ygMIl1w6wz6A24oxkLwirunSKXb9EW12' -O 'LDC2012T13.tgz'\n\n\nimport tarfile\nfrom collections import defaultdict\n\nclass EnglishWebTreebankOld:\n    \n    def __init__(self, root='LDC2012T13.tgz'):\n        \n        def trees():\n            with tarfile.open(root) as corpus:\n                for fname in corpus.getnames():\n                    if '.xml.tree' in fname:\n                        with corpus.extractfile(fname) as treefile:\n                            treestr = treefile.readline().decode()\n                            yield fname, Tree.from_string(treestr)\n                        \n        self._trees = trees()\n                        \n    def items(self):\n        for fn, tlist in self._trees:\n              yield fn, tlist"
  },
  {
    "objectID": "assignments/assignments-3-and-4.html#task-2",
    "href": "assignments/assignments-3-and-4.html#task-2",
    "title": "Assignments 3 and 4",
    "section": "Task 2",
    "text": "Task 2\nLines: 3\nDefine an instance method fuzzy_find for the corpus reader class that computes the minimum distance between a query and a tree for all trees in the corpus. It should return a list of tuples with the first element a tree ID, the second an index in that tree, the third the data at that index and the fourth the distance between the query and that index. A tuple should be included in the returned list only if the distance is equal to the minimum across trees in the corpus.\nHint: this should be very straightforward using a particular parameterization for Tree1.fuzzy_find. Which one?\n\nclass EnglishWebTreebank(EnglishWebTreebankOld):\n    \n    def fuzzy_find(self, data: str | list[str]) -&gt; list[FuzzyFindResult]:\n        '''Find the trees in the corpus closest to the query data\n        \n        Parameters\n        ----------\n        data\n        '''\n        raise NotImplementedError\n\nNow, load this corpus.\n\newt = EnglishWebTreebank()\n\nWrite a single test for a piece of data you know exists in some tree in the corpus. (Determiners or auxiliary verbs are good candidates.) Thus, the minimum distance will be zero and your method should return only trees that contain that element. Note that this test should use some already existing method to produce the correct set of trees.\nHint: such a method already exists in the TreeOld class.\n\n# write test here\n\nThe next task will look at computing distance between the elements of a tree and a query set defined by a regular expression. Here is a regular expression class based on the formal definition of regular expressions I gave you in class.\n\nfrom itertools import product\n\nclass Regex:\n    \"\"\"A regular expression\n    \n    Parameters\n    ----------\n    regex_parsed\n    maxlength\n    \"\"\"\n\n    CHAR = pyparsing.Word(pyparsing.alphas, exact=1).setName(\"character\") # &lt;- use 'exact', not 'max'\n\n    LPAR = pyparsing.Suppress('(')\n    RPAR = pyparsing.Suppress(')')\n\n    PARSER = pyparsing.Forward()\n    GROUP = pyparsing.Group(LPAR + PARSER + RPAR)\n    QUANT = pyparsing.oneOf(\"* ? +\")\n    DSJ = '|'\n\n    ITEM = pyparsing.Group((CHAR | GROUP) + QUANT) | pyparsing.Group(CHAR + DSJ + CHAR) | CHAR | GROUP\n    ITEMSEQ = pyparsing.OneOrMore(ITEM)\n\n    PARSER &lt;&lt;= pyparsing.delimitedList(ITEMSEQ, pyparsing.Empty())\n    \n    def __init__(self, regex_parsed: List[Union[str, List]], maxlength: int):\n        self._regex_parsed = regex_parsed\n        self._maxlength = maxlength\n    \n    @classmethod\n    def from_string(cls, regexstr: str, maxlength: int = 30):\n        if regexstr[0] != '(':\n            regexstr = '(' + regexstr\n            \n        if regexstr[-1] != ')':\n            regexstr = regexstr +')'\n            \n        regex_parsed = cls.PARSER.parseString(regexstr)[0]\n        \n        return cls(regex_parsed, maxlength)\n    \n    def __iter__(self):\n        self._gen = self._construct_regex_generator()\n        return self\n    \n    def __next__(self):\n        return next(self._gen)\n        \n    def _construct_regex_generator(self, regex=None):\n        if regex is None:\n            regex = self._regex_parsed\n        \n        if isinstance(regex, str):\n            if len(regex) &gt; self._maxlength:\n                raise StopIteration\n\n            yield regex\n        \n        elif regex[1] in ['*', '+']:\n            i = 0 if regex[1] == '*' else 1\n            while True:\n                for s in self._construct_regex_generator(regex[0]):\n                    yield s*i\n\n                i += 1\n                \n                if i &gt; self._maxlength:\n                    break\n                    \n        elif regex[1] == '?':\n            yield ''\n            yield regex[0]\n\n        elif regex[1] == '|':\n            left = self._construct_regex_generator(regex[0])\n            right = self._construct_regex_generator(regex[2])\n            \n            s1 = s2 = ''\n            \n            while True:\n                if len(s1) &lt;= self._maxlength:                \n                    s1 = next(left)\n                    yield s1\n                \n                if len(s2) &lt;= self._maxlength:\n                    s2 = next(right)\n                    yield s2\n\n                if len(s1) &gt; self._maxlength and len(s2) &gt; self._maxlength:\n                    break\n        \n        else:\n            evaluated = [self._construct_regex_generator(r) for r in regex]\n            for p in product(*evaluated):\n                c = ''.join(p)\n                \n                if len(c) &lt;= self._maxlength:\n                    yield c\n\nThe way to use this class to generate the set of strings associated with a regular expression is tree an instance of the Regex class as a generator.\nImportantly, I’ve include a way of only generating strings of less than some length threshold maxlength in the case that your regular expression evaluates to an infinite set.\n\nfor s in Regex.from_string('co+lou?r', 20):\n    print(s)"
  },
  {
    "objectID": "assignments/assignments-3-and-4.html#task-3",
    "href": "assignments/assignments-3-and-4.html#task-3",
    "title": "Assignments 3 and 4",
    "section": "Task 3",
    "text": "Task 3\nLines: 15\nDefine a new version of fuzzy_find that behaves exactly the same as your version from Task 1 except that it allows the query data to be a regular expression parsable by Regex.from_string. Make sure that you correctly handle infinite sets.\nHint: your new fuzzy_find will be nearly identical to the old one. My implementation only has a single additional line.\n\nclass Tree(TreeOld):\n    \n    DIST = EditDistance(1., 1., 1.)\n    \n    def fuzzy_find(self, data: str | list[str], \n                   closest: bool = True, \n                   distance: float = np.inf,\n                   case_fold: bool = True,\n                   terminals_only: bool = True,\n                   index_path: tuple[int] = tuple()) -&gt; list[FuzzyFindResult]:\n        \n        '''Find the (closest) strings within a distance of the set defined by a regex\n        \n        Defaults to computing the closest strings among the terminals and ignoring case\n        \n        Parameters\n        ----------\n        data\n            the regex to match against\n        closest\n            whether to return only the closest strings or all strings within distance\n        distance\n            the distance within which a string must be\n        case_fold\n            whether to lower-case the data\n        terminals_only\n            whether to only search the terminals\n        index_path\n        '''\n        raise NotImplementedError\n\nWrite tests analogous to the ones you wrote for Task 1.\n\n# write tests here"
  }
]