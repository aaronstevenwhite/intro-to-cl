{
 "cells": [
  {
   "cell_type": "raw",
   "id": "9b7d51ee",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Assignments 3 and 4\n",
    "highlight-style: oblivion\n",
    "format:\n",
    "    html:\n",
    "        code-tools: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VNf-2eQ0E632",
   "metadata": {
    "id": "VNf-2eQ0E632"
   },
   "source": [
    "*Like Assignments 1 and 2, Assignments 3 and 4 are bundled together. You only need to do Tasks 1 and 2 for Assignment 3 and Task 3 for Assignment 4.*\n",
    "\n",
    "These assignments focus on implementing a natural language inference system. In natural language inference, we receive a _premise_ sentence and a _hypothesis_ sentence and we must say whether we can infer the premise from the hypothesis. For instance, if (1) were our premise and (2) were our hypothesis, our system should respond _yes_.\n",
    "\n",
    "1. Every firm polled saw costs grow more than expected, even after adjusting for inflation.\n",
    "2. Every big company in the poll reported cost increases.\n",
    "\n",
    "In [MacCartney & Manning 2009](https://aclanthology.org/W09-3714/) (henceforth, M&M), you read about one sort of system for doing this: a _natural logic_ system. This system works by (i) obtaining an _edit path_ from the premise and the hypothesis; (ii) mapping that edit path into an _inference path_; (iii) computing the _join_ of the inferences in this path to obtain a relation between the premise and the hypothesis; and (iv) checking whether there is a _forward entailment_ relation between the premise and the hypothesis.\n",
    "\n",
    "The definition of the relations is given in Table 2 of the paper.\n",
    "\n",
    "| Symbol           | Names                | Example                     | Set theoretic definition   |\n",
    "|:----------------:|:--------------------:|:---------------------------:|:--------------------------:|\n",
    "|$x \\equiv y$      | equivalence          | couch $\\equiv$ sofa         | $x = y$                    |\n",
    "|$x \\sqsubset y$   | forward entailment   | crow $\\sqsubset$ bird       | $x \\subset y$              |\n",
    "|$x \\sqsupset y$   | reverse entailment   | European $\\sqsupset$ French | $x \\supset y$              |\n",
    "|$x \\land y$       | negation             | human $\\land$ nonhuman      | $x \\cap y = \\emptyset$ & $x \\cup y = U$ |\n",
    "|$x \\mid y$        | alternation          | cat $\\mid$ dog              | $x \\cap y = \\emptyset$ & $x \\cup y \\neq U$ |a\n",
    "|$x \\smile y$      | cover                | animal $\\smile$ nonhuman    | $x \\cap y \\neq \\emptyset$ & $x \\cup y = U$ |\n",
    "|$x\\;\\#\\;y$        | independence         | animal $\\;\\#\\;$ nonhuman    | otherwise                  |\n",
    "\n",
    "The table of joins is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "gFcUO95oE636",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1677253193975,
     "user": {
      "displayName": "Aaron Steven White",
      "userId": "06256629009318567325"
     },
     "user_tz": 300
    },
    "id": "gFcUO95oE636",
    "outputId": "3e7135af-05e6-4a35-fdb8-c540653ca947"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t≡\t[\t]\t^\t|\tu\t#\n",
      "≡\t≡\t[\t]\t^\t|\tu\t#\n",
      "\n",
      "[\t[\t[\t≡[]|#\t|\t|\t[^|u#\t[|#\n",
      "\n",
      "]\t]\t≡[]u#\t]\tu\t]^|u#\tu\t]u#\n",
      "\n",
      "^\t^\tu\t|\t≡\t]\t[\t#\n",
      "\n",
      "|\t|\t[^|u#\t|\t[\t≡[]|#\t[\t[|#\n",
      "\n",
      "u\tu\tu\t]^|u#\t]\t]\t≡[]u#\t]u#\n",
      "\n",
      "#\t#\t[u#\t]|#\t#\t]|#\t[u#\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "relations = ['≡', '[', ']', '^', '|', 'u', '#']\n",
    "\n",
    "join_table = {('≡', '≡'): {'≡'},\n",
    "              ('≡', '['): {'['},\n",
    "              ('≡', ']'): {']'},\n",
    "              ('≡', '^'): {'^'},\n",
    "              ('≡', '|'): {'|'},\n",
    "              ('≡', 'u'): {'u'},\n",
    "              ('≡', '#'): {'#'},\n",
    "              ('[', '≡'): {'['},\n",
    "              ('[', '['): {'['},\n",
    "              ('[', ']'): {'#', '|', '≡', '[', ']'},\n",
    "              ('[', '^'): {'|'},\n",
    "              ('[', '|'): {'|'},\n",
    "              ('[', 'u'): {'#', '^', 'u', '|', '['},\n",
    "              ('[', '#'): {'#', '|', '['},\n",
    "              (']', '≡'): {']'},\n",
    "              (']', '['): {'#', 'u', '≡', '[', ']'},\n",
    "              (']', ']'): {']'},\n",
    "              (']', '^'): {'u'},\n",
    "              (']', '|'): {'#', '^', 'u', '|', ']'},\n",
    "              (']', 'u'): {'u'},\n",
    "              (']', '#'): {'#', 'u', ']'},\n",
    "              ('^', '≡'): {'^'},\n",
    "              ('^', '['): {'u'},\n",
    "              ('^', ']'): {'|'},\n",
    "              ('^', '^'): {'≡'},\n",
    "              ('^', '|'): {']'},\n",
    "              ('^', 'u'): {'['},\n",
    "              ('^', '#'): {'#'},\n",
    "              ('|', '≡'): {'|'},\n",
    "              ('|', '['): {'[', '^', '|', 'u', '#'},\n",
    "              ('|', ']'): {'|'},\n",
    "              ('|', '^'): {'['},\n",
    "              ('|', '|'): {'#', '|', '≡', '[', ']'},\n",
    "              ('|', 'u'): {'['},\n",
    "              ('|', '#'): {'#', '|', '['},\n",
    "              ('u', '≡'): {'u'},\n",
    "              ('u', '['): {'u'},\n",
    "              ('u', ']'): {'#', '^', 'u', '|', ']'},\n",
    "              ('u', '^'): {']'},\n",
    "              ('u', '|'): {']'},\n",
    "              ('u', 'u'): {'#', 'u', '≡', '[', ']'},\n",
    "              ('u', '#'): {'#', 'u', ']'},\n",
    "              ('#', '≡'): {'#'},\n",
    "              ('#', '['): {'#', 'u', '['},\n",
    "              ('#', ']'): {']', '|', '#'},\n",
    "              ('#', '^'): {'#'},\n",
    "              ('#', '|'): {'#', '|', ']'},\n",
    "              ('#', 'u'): {'#', 'u', '['},\n",
    "              ('#', '#'): set()}\n",
    "\n",
    "print('\\t'.join(['']+relations))\n",
    "for r1 in relations:\n",
    "    row = '\\t'.join(''.join([r3 for r3 in relations \n",
    "                             if r3 in join_table[r1, r2]]) \n",
    "                    for r2 in relations)\n",
    "    print(f'{r1}\\t{row}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y1BVat1GE638",
   "metadata": {
    "id": "y1BVat1GE638"
   },
   "source": [
    "In Tasks 1 and 2, you will be developing the core of this system, using the minimum edit distance-based edit paths we developed in class and assuming default inference relations associated with each atomic edit operation (as discussed in Section 4 of M&M). In Tasks 3 and 4, you will enrich this system with lexical relation information from WordNet (Task 3) and with more intelligent handling of inferences associated with certain environments (as discussed in Section 5 of M&M). You will then test the system on the classic FraCaS dataset. \n",
    "\n",
    "## Task 1\n",
    "\n",
    "*Lines:* 4\n",
    "\n",
    "Define the `__add__` magic method for the `Inference` class below. This method should use `join_table` (defined above) to produce a set of `Inference`s by joining two inferences—e.g. animal $\\sqsupset$ dog $\\bowtie$ dog $\\sqsupset$ greyhound = {animal $\\sqsupset$ greyhound}. `__add__` must return a set because, as M&M discussed, the result of joining two relations can result in indeterminacy. (In their implementation, M&M actually treat all such indetrminate joins as #. We will not do that here, since it is useful to see _why_ they do that.)\n",
    "\n",
    "Importantly, note that `__add__` should **not** be symmetric for the same reason joins are not: animal $\\sqsupset$ dog $\\bowtie$ dog $\\sqsubset$ mammal = {animal $\\equiv$ mammal, animal $\\sqsupset$ mammal, animal $\\sqsubset$ mammal, animal $\\smile$ mammal, animal $\\#$ mammal}, but dog $\\sqsubset$ mammal $\\bowtie$ animal $\\sqsupset$ dog isn't even a licit join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "WIdwn0IuE638",
   "metadata": {
    "id": "WIdwn0IuE638"
   },
   "outputs": [],
   "source": [
    "class Inference:\n",
    "    '''An inference from one linguistic expression to another\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    premise\n",
    "        The premise in the relation\n",
    "    hypothesis\n",
    "        The hypothesis in the relation\n",
    "    relation\n",
    "        The relation\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, premise: list[str], hypothesis: list[str], relation: str):\n",
    "        if relation not in relations:\n",
    "            raise ValueError(f'relation must be in {relations}')\n",
    "        \n",
    "        self.premise = premise\n",
    "        self.hypothesis = hypothesis\n",
    "        self.relation = relation\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return ' '.join(self.premise) + ' ' + self.relation + ' ' + ' '.join(self.hypothesis)\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash((tuple(self.premise), tuple(self.hypothesis), self.relation))\n",
    "        \n",
    "    def __add__(self, other: 'Inference') -> set['Inference']:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def __eq__(self, other: 'Inference') -> bool:\n",
    "        return (self.premise == other.premise) &\\\n",
    "               (self.hypothesis == other.hypothesis) &\\\n",
    "               (self.relation == other.relation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zEM79G7qE638",
   "metadata": {
    "id": "zEM79G7qE638"
   },
   "source": [
    "Test your implementation of `Inference.__add__` using the `Editor` subclasses below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cPaqdsxDE639",
   "metadata": {
    "id": "cPaqdsxDE639"
   },
   "outputs": [],
   "source": [
    "from abc import ABC\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "class Editor(ABC):\n",
    "    \n",
    "    def __init__(self, *args):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __call__(self, input: list[str], idx: int) -> Inference:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    @property\n",
    "    def input(self):\n",
    "        return self._input\n",
    "    \n",
    "    @property\n",
    "    def output(self):\n",
    "        return self._output\n",
    "        \n",
    "\n",
    "class Substitution(Editor):\n",
    "    \"\"\"A substitution editor\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input\n",
    "        The string in the input to replace\n",
    "    output\n",
    "        The string to replace the input string with\n",
    "    relation\n",
    "        The inference relation that results\n",
    "    \"\"\"\n",
    "    \n",
    "    default_relation = None\n",
    "    \n",
    "    def __init__(self, input: str, output: str, relation: str):\n",
    "        self._input = input\n",
    "        self._output = output\n",
    "        self._relation = relation\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'<SUB \"{self._output}\" for \"{self._input}\" resulting in {self._relation}>'\n",
    "    \n",
    "    def __call__(self, input: list[str], idx: int) -> Inference:\n",
    "        \"\"\"Substitute input for output at location idx\"\"\"\n",
    "        if input[idx] != self._input:\n",
    "            raise ValueError(f'SUB \"{self._input}\" -> \"{self._output}\" at {idx} '\n",
    "                             f'cannot be applied to {input}')\n",
    "        \n",
    "        output = input[:idx] + [self._output] + input[(idx+1):]\n",
    "        \n",
    "        return Inference(input, output, self._relation)\n",
    "        \n",
    "class Deletion(Editor):\n",
    "    \"\"\"A deletion editor\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input\n",
    "        The string in the input to delete\n",
    "    relation\n",
    "        The inference relation that results\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input: str, relation: str='['):\n",
    "        self._input = input\n",
    "        self._relation = relation\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'<DEL \"{self._input}\" resulting in {self._relation}>'\n",
    "        \n",
    "    def __call__(self, input: list[str], idx: int) -> Inference:\n",
    "        \"\"\"Substitute input for output at location idx\"\"\"\n",
    "        if input[idx] != self._input:\n",
    "            raise ValueError(f'DEL \"{self._input}\" at {idx} '\n",
    "                             f'cannot be applied to {input}')\n",
    "        \n",
    "        output = input[:idx] + input[(idx+1):]\n",
    "        \n",
    "        return Inference(input, output, self._relation)\n",
    "        \n",
    "class Insertion(Editor):\n",
    "    \"\"\"An insertion editor\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input\n",
    "        The string to insert into the output\n",
    "    relation\n",
    "        The inference relation that results\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,  output: str, relation: str=']'):\n",
    "        self._output = output\n",
    "        self._relation = relation\n",
    "      \n",
    "    def __repr__(self):\n",
    "        return f'<INS \"{self._output}\" resulting in {self._relation}>'\n",
    "    \n",
    "    def __call__(self, input: list[str], idx: int) -> Inference:\n",
    "        \"\"\"Substitute input for output at location idx\"\"\"\n",
    "        output = input[:idx] + [self._output] + input[idx:]\n",
    "        \n",
    "        return Inference(input, output, self._relation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hicxSa6bE639",
   "metadata": {
    "id": "hicxSa6bE639"
   },
   "source": [
    "These subclasses are initialized with input and/or output strings and a relation. For instance, \"brindle\" and \"fawn\" are two different colorings of greyhounds—no greyhound is both brindle and fawn—and so they are in the | relation. Each is at least a [subsective modifier](https://en.wikipedia.org/wiki/Subsective_modifier) (all brindle greyhounds are greyhounds), so if we delete one, we obtain a $\\sqsubset$ relation, and if we insert one, we get a $\\sqsupset$ relation (the default relations for deletion and insertion, as discussed in M&M). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "iOu7miaTE639",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1677253193976,
     "user": {
      "displayName": "Aaron Steven White",
      "userId": "06256629009318567325"
     },
     "user_tz": 300
    },
    "id": "iOu7miaTE639",
    "outputId": "e38bcde0-387e-4b1f-9291-d00a6cb64c59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<SUB \"fawn\" for \"brindle\" resulting in |>,\n",
       " <DEL \"brindle\" resulting in [>,\n",
       " <INS \"brindle\" resulting in ]>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substitute_fawn_for_brindle = Substitution('brindle', 'fawn', '|')\n",
    "delete_brindle = Deletion('brindle')\n",
    "insert_brindle = Insertion('brindle')\n",
    "\n",
    "substitute_fawn_for_brindle, delete_brindle, insert_brindle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Tme8qLxiE63-",
   "metadata": {
    "id": "Tme8qLxiE63-"
   },
   "source": [
    "Note that not all insertions or deletions of adjectives will be associated with $\\sqsubset$ or $\\sqsupset$: privative adjectives like \"fake\" will introduce a $|$: fake greyhounds are not greyhounds (fake greyhound $|$ greyhound) and greyhounds are not fake greyhounds (greyhound $|$ fake greyhound)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "SD8NogjoE63-",
   "metadata": {
    "id": "SD8NogjoE63-"
   },
   "outputs": [],
   "source": [
    "delete_fake = Deletion('fake', relation='|')\n",
    "insert_fake = Insertion('fake', relation='|')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CRcvSj5YE63-",
   "metadata": {
    "id": "CRcvSj5YE63-"
   },
   "source": [
    "Indeed, most substitutions involving \"fake\" will also yield a $|$ relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "PPT3U9OME63_",
   "metadata": {
    "id": "PPT3U9OME63_"
   },
   "outputs": [],
   "source": [
    "substitute_fake_for_virtuosic = Substitution('virtuosic', 'fake', '|')\n",
    "substitute_virtuosic_for_fake = Substitution('fake', 'virtuosic', '|')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1H2GqVYcE63_",
   "metadata": {
    "id": "1H2GqVYcE63_"
   },
   "source": [
    "But insertion and deletion edits involving \"virtuosic\" should act like \"brindle\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "jJge0uv8E63_",
   "metadata": {
    "id": "jJge0uv8E63_"
   },
   "outputs": [],
   "source": [
    "delete_virtuosic = Deletion('virtuosic')\n",
    "insert_virtuosic = Insertion('virtuosic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "luWno6WGE63_",
   "metadata": {
    "id": "luWno6WGE63_"
   },
   "source": [
    "Use the following four sentences to write your tests. These tests should involve applying an edit $e_1$ to sentence $s_i$ to yield sentence $e_1(s_i)$, then applying an edit $e_2$ to $e_1(s_i)$ to yield sentence. You should then combine the inferences associated with $e_1$ and $e_2$ using your `Inference.__add__` and check that it is correct. Make sure to test at least one case where the result should be a non-singleton set of inferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "oV5NW9KGE63_",
   "metadata": {
    "id": "oV5NW9KGE63_"
   },
   "outputs": [],
   "source": [
    "test_sentence1 = ['a', 'virtuosic', 'synthesist', 'loves', 'a', 'happy', 'brindle', 'greyhound']\n",
    "test_sentence2 = ['a', 'synthesist', 'loves', 'a', 'happy', 'greyhound']\n",
    "test_sentence3 = ['a', 'fake', 'synthesist', 'loves', 'a', 'happy', 'brindle', 'greyhound']\n",
    "test_sentence4 = ['a', 'synthesist', 'loves', 'a', 'happy', 'brindle', 'greyhound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "X7jQ1wr0E63_",
   "metadata": {
    "id": "X7jQ1wr0E63_"
   },
   "outputs": [],
   "source": [
    "# write tests here  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2579506f",
   "metadata": {},
   "source": [
    "## Editor Libraries\n",
    "\n",
    "We'll need a way to store collections of editors and, crucially, make new default ones when needed. The `EditorLibrary` class provides a convenient way to store and retrieve editors (like substitutions, deletions, and insertions). When we try to get an editor that isn't in the library, it automatically creates a default one - substitutions get a `#` relation (since we don't have a default for them), while deletions and insertions get the default behavior defined by MacCartney & Manning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ac298b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, Union\n",
    "\n",
    "EditorType = Literal['substitute', 'delete', 'insert']\n",
    "EditorInputOutput = Union[str, tuple[str, str]]\n",
    "\n",
    "empty_library = {'substitute': {}, 'delete': {}, 'insert': {}}\n",
    "\n",
    "class EditorLibrary:\n",
    "    def __init__(self, library: dict[EditorType, dict[EditorInputOutput, Editor]] = empty_library):\n",
    "        self._library = library\n",
    "        \n",
    "    def __getitem__(self, key: tuple[EditorType, EditorInputOutput]) -> Editor:\n",
    "        editor_type, edit = key\n",
    "        if edit not in self._library[editor_type]:\n",
    "            self._add_default_editor(editor_type, edit)\n",
    "        return self._library[editor_type][edit]\n",
    "    \n",
    "    def add_editor(self, editor: Editor):\n",
    "        if isinstance(editor, Substitution):\n",
    "            self._library['substitute'][(editor.input, editor.output)] = editor\n",
    "            \n",
    "        if isinstance(editor, Insertion):\n",
    "            self._library['insert'][editor.output] = editor\n",
    "            \n",
    "        if isinstance(editor, Deletion):\n",
    "            self._library['delete'][editor.input] = editor\n",
    "            \n",
    "    def _add_default_editor(self, editor_type: str, edit: EditorInputOutput):\n",
    "        if editor_type == 'substitute':\n",
    "            self.add_editor(Substitution(input=edit[0], output=edit[1], relation='#'))\n",
    "        \n",
    "        elif editor_type == 'insert':\n",
    "            self.add_editor(Insertion(output=edit))\n",
    "            \n",
    "        elif editor_type == 'delete':\n",
    "            self.add_editor(Deletion(input=edit))\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f'{editor_type} is not a recognized edit type')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obB8OzQDE63_",
   "metadata": {
    "id": "obB8OzQDE63_"
   },
   "source": [
    "## Task 2\n",
    "\n",
    "*Lines:* 20\n",
    "\n",
    "We don't want to have to hand-compute the edits that are required to convert one sentence into another. Instead, we will use a modified form of the `StringEdit` class we developed in class. What we need in particular are the edit paths that that class produces.\n",
    "\n",
    "First, we'll define a class for representing and manipulating edit paths. One important thing we want this class to do is to convert the edit path into a list of editors, for which we need to have a way to look up the editor for a given edit type and parameters given an `EditorLibrary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "8aa4a08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EditLocation = int\n",
    "EditorParameters = tuple[EditorInputOutput, EditLocation]\n",
    "\n",
    "class EditPath:\n",
    "    \"\"\"Class for representing and manipulating sequences of text edits.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    edits\n",
    "        List of tuples containing edit type and parameters for each edit operation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, edits: list[tuple[EditorType, EditorParameters]]):\n",
    "        self.edits_unshifted = edits\n",
    "        self.edits = self._shift_indices(edits)\n",
    "        \n",
    "    def __repr__(self) -> str:\n",
    "        return str(self.edits)\n",
    "\n",
    "    def __call__(self, input_text: list[str]) -> list[str]:\n",
    "        \"\"\"Apply the edit path to transform the input text.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        input_text : list[str]\n",
    "            The input text to transform\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list[str]\n",
    "            The transformed text after applying all edits\n",
    "        \"\"\"\n",
    "        current_text = input_text.copy()\n",
    "        \n",
    "        for edit_type, (edit, idx) in self.edits:\n",
    "            if edit_type == 'substitute':\n",
    "                old_word, new_word = edit\n",
    "\n",
    "                if old_word != current_text[idx]:\n",
    "                    raise ValueError(\n",
    "                        f'Substitution {old_word} -> {new_word} at {idx} '\n",
    "                        f'cannot be applied to {current_text}'\n",
    "                    )\n",
    "\n",
    "                current_text[idx] = new_word\n",
    "                \n",
    "            elif edit_type == 'delete':\n",
    "                current_text.pop(idx)\n",
    "                \n",
    "            elif edit_type == 'insert':\n",
    "                current_text.insert(idx, edit)\n",
    "                \n",
    "        return current_text\n",
    "\n",
    "    def _shift_indices(self, edit_path: list[tuple[EditorType, EditorParameters]]) -> list[tuple[EditorType, EditorParameters]]:\n",
    "        \"\"\"Adjust indices of edits to account for previous insertions and deletions.\n",
    "\n",
    "        The edit sequence output by the `StringEdit` class is always relativized to \n",
    "        the original string. But if we are applying the edits in sequence, the string\n",
    "        that we apply subsequent edits to will differ from the original string, so we\n",
    "        need to shift the indices of the subsequent edits to account for the previous\n",
    "        edits.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        edit_path : list[tuple[EditorType, EditorParameters]]\n",
    "            Original list of edits with unadjusted indices.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list[tuple[EditorType, EditorParameters]]\n",
    "            List of edits with indices shifted to account for previous edits.\n",
    "        \"\"\"\n",
    "        edit_path_shifted = []\n",
    "\n",
    "        # track cumulative index shifts from insertions/deletions\n",
    "        # we always need to shift back by 1 to account for the fact that\n",
    "        # the original edit sequence is 1-indexed (due to the sentinel)\n",
    "        shifts = [(0, -1)]\n",
    "\n",
    "        for i, (edit_type, (edit, idx)) in enumerate(edit_path):\n",
    "            original_idx = idx\n",
    "\n",
    "            # apply all previous shifts to current index\n",
    "            for j, s in shifts:\n",
    "                idx = idx + s if idx >= j else idx \n",
    "\n",
    "            if edit_type == 'substitute':\n",
    "                # if the substitution is the same element, we don't need to\n",
    "                # record the edit at all because it doesn't change the string\n",
    "                if edit[0] == edit[1]:\n",
    "                    continue\n",
    "                else:\n",
    "                    # substitution does not shift the index because \n",
    "                    # we're simply replacing one element with another\n",
    "                    shifts.append((idx, 0))\n",
    "    \n",
    "            elif edit_type == 'delete':\n",
    "                # deletion shifts the index back by 1 because \n",
    "                # they remove an element\n",
    "                shifts.append((idx, -1))\n",
    "\n",
    "            elif edit_type == 'insert':\n",
    "                # insertion shifts the index forward by 1 because \n",
    "                # they add an element\n",
    "                shifts.append((idx, 1))\n",
    "\n",
    "                next_edit_type, (_, next_idx) = edit_path[i+1]\n",
    "                \n",
    "                # ensures that the inserted element does not get inserted out of \n",
    "                # order with an immediately following substitution \n",
    "                if next_edit_type != 'substitute' or next_idx != original_idx:\n",
    "                    idx += 1\n",
    "\n",
    "            edit_path_shifted.append((edit_type, (edit, idx)))\n",
    "\n",
    "        return edit_path_shifted\n",
    "    \n",
    "    def to_editors(self, library: EditorLibrary) -> list[tuple[EditLocation, Editor]]:\n",
    "        \"\"\"Convert edit path to a sequence of editors using the provided library.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        library : EditorLibrary\n",
    "            Dictionary mapping edit types and parameters to Editor instances.\n",
    "            The outer dictionary maps edit types (e.g. 'substitute', 'delete', 'insert')\n",
    "            to inner dictionaries that map edit parameters to Editor instances.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list[tuple[EditLocation, Editor]]\n",
    "            List of tuples containing the edit location and the editor for each \n",
    "            edit in the path.\n",
    "        \"\"\"\n",
    "        return [\n",
    "            (edit_idx, library[edit_type, edit]) \n",
    "            for edit_type, (edit, edit_idx) in self.edits\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a592d6",
   "metadata": {},
   "source": [
    "Next, we'll define a class for computing edit distances, alignments, and edit paths between strings we used in class, with some slight updates for the current assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "Xm85fPY5E64A",
   "metadata": {
    "id": "Xm85fPY5E64A"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "Alignment = list[tuple[int, int]]\n",
    "\n",
    "class StringEdit:\n",
    "    \"\"\"Class for computing edit distances, alignments, and edit paths between strings.\n",
    "\n",
    "    This class implements the Wagner-Fisher algorithm for computing minimum edit\n",
    "    distance between sequences, along with the corresponding alignments and edit paths.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    insertion_cost : float, default=1.0\n",
    "        Cost of inserting a character\n",
    "    deletion_cost : float, default=1.0\n",
    "        Cost of deleting a character\n",
    "    substitution_cost : float or None, default=None\n",
    "        Cost of substituting a character. If None, defaults to insertion_cost + deletion_cost\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, insertion_cost: float = 1., deletion_cost: float = 1., substitution_cost: float | None = None):\n",
    "        self._insertion_cost = insertion_cost\n",
    "        self._deletion_cost = deletion_cost\n",
    "\n",
    "        if substitution_cost is None:\n",
    "            self._substitution_cost = insertion_cost + deletion_cost\n",
    "        else:\n",
    "            self._substitution_cost = substitution_cost\n",
    "\n",
    "    def __call__(self, source: list[str], target: list[str], only_distance: bool = False) ->  float | tuple[float, Alignment, list[EditPath]]:\n",
    "        return self._wagner_fisher(source, target, only_distance)\n",
    "            \n",
    "    def _wagner_fisher(self, source: list[str], target: list[str], only_distance: bool) ->  float | tuple[float, Alignment, list[EditPath]]:\n",
    "        \"\"\"Compute minimum edit distance, alignment, and edit sequence using Wagner-Fisher algorithm.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        source : list[str]\n",
    "            Source sequence\n",
    "        target : list[str]\n",
    "            Target sequence\n",
    "        only_distance : bool\n",
    "            If True, return only the edit distance\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float | tuple[float, Alignment, list[EditPath]]\n",
    "            If only_distance is True, returns just the edit distance.\n",
    "            Otherwise returns a tuple of (distance, alignment, edit_paths)\n",
    "        \"\"\"\n",
    "        n, m = len(source), len(target)\n",
    "        source, target = self._add_sentinel(source, target)\n",
    "\n",
    "        # initialize matrices for dynamic programming\n",
    "        distance = np.zeros([n+1, m+1], dtype=float)\n",
    "        pointers = np.zeros([n+1, m+1], dtype=list)\n",
    "        edits = np.zeros([n+1, m+1], dtype=list)\n",
    "\n",
    "        pointers[0,0] = []\n",
    "        edits[0,0] = []\n",
    "        \n",
    "        # initialize first column (deletions)\n",
    "        for i in range(1,n+1):\n",
    "            distance[i,0] = distance[i-1,0]+self._deletion_cost\n",
    "            pointers[i,0] = [(i-1,0)]\n",
    "            edits[i,0] = [('delete', (source[i], i))]\n",
    "\n",
    "        # initialize first row (insertions)\n",
    "        for j in range(1,m+1):\n",
    "            distance[0,j] = distance[0,j-1]+self._insertion_cost\n",
    "            pointers[0,j] = [(0,j-1)]\n",
    "            edits[0,j] = [('insert', (target[j], j))]\n",
    "            \n",
    "        # fill in the rest of the matrices\n",
    "        for i in range(1,n+1):\n",
    "            for j in range(1,m+1):\n",
    "                if source[i] == target[j]:\n",
    "                    substitution_cost = 0.\n",
    "                else:\n",
    "                    substitution_cost = self._substitution_cost\n",
    "                    \n",
    "                costs = np.array([distance[i-1,j]+self._deletion_cost,\n",
    "                                  distance[i-1,j-1]+substitution_cost,\n",
    "                                  distance[i,j-1]+self._insertion_cost])\n",
    "                    \n",
    "                distance[i,j] = costs.min()\n",
    "\n",
    "                best_edits = np.where(costs==distance[i,j])[0]\n",
    "\n",
    "                indices = [(i-1,j), (i-1,j-1), (i,j-1)]\n",
    "                pointers[i,j] = [indices[k] for k in best_edits]\n",
    " \n",
    "                edit_types = list(zip([\"delete\", \"substitute\", \"insert\"],\n",
    "                                      [(source[i], i), \n",
    "                                       ((source[i], target[j]), i), \n",
    "                                       (target[j], i)]))\n",
    "                edits[i,j] = [edit_types[k] for k in best_edits]\n",
    "\n",
    "        if only_distance:\n",
    "            return distance[n,m]\n",
    "\n",
    "        pointer_backtrace, edit_backtrace = self._construct_backtrace(pointers, edits, n, m)\n",
    "\n",
    "        edit_paths = [EditPath(bt) for bt in edit_backtrace]\n",
    "\n",
    "        return distance[n,m], pointer_backtrace, edit_paths\n",
    "\n",
    "    def _construct_backtrace(self, pointers: np.ndarray, edits: np.ndarray, n: int, m: int) -> tuple[list[list[tuple[int, int]]], list[list[tuple[str, tuple[str, int]]]]]:\n",
    "        \"\"\"Construct all possible backtraces through the dynamic programming matrix.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        pointers : np.ndarray\n",
    "            Matrix of pointers to previous cells\n",
    "        edits : np.ndarray\n",
    "            Matrix of edit operations\n",
    "        n : int\n",
    "            Length of source sequence\n",
    "        m : int\n",
    "            Length of target sequence\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple[list[list[tuple[int, int]]], list[list[tuple[str, tuple[str, int]]]]]\n",
    "            Returns (pointer_backtraces, edit_backtraces)\n",
    "        \"\"\"\n",
    "        stack = [([(n,m)], [])]\n",
    "        complete_pointer_backtraces = []\n",
    "        complete_edit_backtraces = []\n",
    "        \n",
    "        while stack:\n",
    "            current_pointer_path, current_edit_path = stack.pop()\n",
    "            current_pos = current_pointer_path[-1]\n",
    "            \n",
    "            if current_pos == (0,0):\n",
    "                complete_pointer_backtraces.append(current_pointer_path[::-1])\n",
    "                complete_edit_backtraces.append(current_edit_path[::-1])\n",
    "                continue\n",
    "                \n",
    "            for next_pos, edit in zip(pointers[current_pos], edits[current_pos]):\n",
    "                new_pointer_path = current_pointer_path + [next_pos]\n",
    "                new_edit_path = current_edit_path + [edit]\n",
    "                stack.append((new_pointer_path, new_edit_path))\n",
    "                \n",
    "        return complete_pointer_backtraces, complete_edit_backtraces\n",
    "        \n",
    "    def _add_sentinel(\n",
    "        self, \n",
    "        source: str | list | tuple, \n",
    "        target: str | list | tuple\n",
    "    ) -> tuple[str | list | tuple, str | list | tuple]:\n",
    "        \"\"\"Add sentinel symbols to beginning of sequences.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        source\n",
    "            Source sequence\n",
    "        target\n",
    "            Target sequence\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple[str | list | tuple, str | list | tuple]\n",
    "            Source and target with added sentinels\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            If source or target are not str, list, or tuple\n",
    "        \"\"\"\n",
    "        if isinstance(source, str):\n",
    "            source = '#'+source\n",
    "        elif isinstance(source, list):\n",
    "            source = ['#'] + source\n",
    "        elif isinstance(source, tuple):\n",
    "            source = ('#',) + source\n",
    "        else:\n",
    "            raise ValueError('source must be str, list, or tuple')\n",
    "            \n",
    "        if isinstance(target, str):\n",
    "            target = '#' + target\n",
    "        elif isinstance(target, list):\n",
    "            target = ['#'] + target\n",
    "        elif isinstance(target, tuple):\n",
    "            target = ('#',) + target\n",
    "        else:\n",
    "            raise ValueError('target must be str, list, or tuple')\n",
    "            \n",
    "        return source, target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tKFxyYhiE64A",
   "metadata": {
    "id": "tKFxyYhiE64A"
   },
   "source": [
    "In the original implementation, the edit path indexed into the source string. This made sense at the time because we wanted to know which words, relative to their original position in the string, are operated on by an edit. It's problematic for current purposes, because once we compute insertions and deletions, the position of later insertions or deletions change. The implementation below now corrects for this, but just make sure you're taking into account that the order of edits matters for this reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "vxfhbuCAE64A",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1677253193978,
     "user": {
      "displayName": "Aaron Steven White",
      "userId": "06256629009318567325"
     },
     "user_tz": 300
    },
    "id": "vxfhbuCAE64A",
    "outputId": "f6292874-34a5-4b61-a83e-e14bbc391d33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:    ['a', 'virtuosic', 'synthesist', 'loves', 'a', 'happy', 'brindle', 'greyhound']\n",
      "Target:    ['a', 'synthesist', 'loves', 'a', 'happy', 'greyhound']\n",
      "Pointer path: [[(0, 0), (1, 1), (2, 1), (3, 2), (4, 3), (5, 4), (6, 5), (7, 5), (8, 6)]]\n",
      "Edit path: [[('delete', ('virtuosic', 1)), ('delete', ('brindle', 5))]]\n",
      "Edited: [['a', 'synthesist', 'loves', 'a', 'happy', 'greyhound']]\n",
      "Edit path is correct: True\n"
     ]
    }
   ],
   "source": [
    "editdist = StringEdit(1, 1, 1)\n",
    "\n",
    "dist, align, edits = editdist(test_sentence1, test_sentence2)\n",
    "\n",
    "edit_path_is_correct = all(\n",
    "    e(test_sentence1) == test_sentence2 for e in edits\n",
    ")\n",
    "\n",
    "print('Source:   ', test_sentence1)\n",
    "print('Target:   ', test_sentence2)\n",
    "print('Pointer path:', align)\n",
    "print('Edit path:', edits)\n",
    "print(\"Edited:\", [e(test_sentence1) for e in edits])\n",
    "print(\"Edit path is correct:\", edit_path_is_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "4uCuEVluE64B",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1677253193978,
     "user": {
      "displayName": "Aaron Steven White",
      "userId": "06256629009318567325"
     },
     "user_tz": 300
    },
    "id": "4uCuEVluE64B",
    "outputId": "fb1de2b0-5140-48a3-9cbc-7b53aecab378"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:    ['a', 'synthesist', 'loves', 'a', 'happy', 'greyhound']\n",
      "Target:    ['a', 'virtuosic', 'synthesist', 'loves', 'a', 'happy', 'brindle', 'greyhound']\n",
      "Pointer path: [[(0, 0), (1, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (5, 7), (6, 8)]]\n",
      "Edit path: [[('insert', ('virtuosic', 1)), ('insert', ('brindle', 6))]]\n",
      "Edited: [['a', 'virtuosic', 'synthesist', 'loves', 'a', 'happy', 'brindle', 'greyhound']]\n",
      "Edit path is correct: True\n"
     ]
    }
   ],
   "source": [
    "dist, align, edits = editdist(test_sentence2, test_sentence1)\n",
    "\n",
    "edit_path_is_correct = all(\n",
    "    e(test_sentence2) == test_sentence1 for e in edits\n",
    ")\n",
    "\n",
    "print('Source:   ', test_sentence2)\n",
    "print('Target:   ', test_sentence1)\n",
    "print('Pointer path:', align)\n",
    "print('Edit path:', edits)\n",
    "print(\"Edited:\", [e(test_sentence2) for e in edits])\n",
    "print(\"Edit path is correct:\", edit_path_is_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "40845765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:    ['a', 'synthesist', 'loves', 'a', 'happy', 'greyhound']\n",
      "Target:    ['some', 'virtuosic', 'synthesist', 'loves', 'a', 'happy', 'brindle', 'greyhound']\n",
      "Pointer path: [[(0, 0), (1, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (5, 7), (6, 8)], [(0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (5, 7), (6, 8)]]\n",
      "Edit path: [[('substitute', (('a', 'some'), 0)), ('insert', ('virtuosic', 1)), ('insert', ('brindle', 6))], [('insert', ('some', 0)), ('substitute', (('a', 'virtuosic'), 1)), ('insert', ('brindle', 6))]]\n",
      "Edit path is correct: True\n"
     ]
    }
   ],
   "source": [
    "test_sentence1_prime = [\"some\"] + test_sentence1[1:]\n",
    "\n",
    "dist, align, edits = editdist(test_sentence2, test_sentence1_prime)\n",
    "\n",
    "edit_path_is_correct = all(\n",
    "    e(test_sentence2) == test_sentence1_prime for e in edits\n",
    ")\n",
    "\n",
    "print('Source:   ', test_sentence2)\n",
    "print('Target:   ', test_sentence1_prime)\n",
    "print('Pointer path:', align)\n",
    "print('Edit path:', edits)\n",
    "print(\"Edit path is correct:\", edit_path_is_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "eaf3c8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:    ['some', 'virtuosic', 'synthesist', 'loves', 'a', 'happy', 'brindle', 'greyhound']\n",
      "Target:    ['a', 'synthesist', 'loves', 'a', 'happy', 'greyhound']\n",
      "Pointer path: [[(0, 0), (1, 0), (2, 1), (3, 2), (4, 3), (5, 4), (6, 5), (7, 5), (8, 6)], [(0, 0), (1, 1), (2, 1), (3, 2), (4, 3), (5, 4), (6, 5), (7, 5), (8, 6)]]\n",
      "Edit path: [[('delete', ('some', 0)), ('substitute', (('virtuosic', 'a'), 0)), ('delete', ('brindle', 5))], [('substitute', (('some', 'a'), 0)), ('delete', ('virtuosic', 1)), ('delete', ('brindle', 5))]]\n",
      "Edit path is correct: True\n"
     ]
    }
   ],
   "source": [
    "dist, align, edits = editdist(test_sentence1_prime, test_sentence2)\n",
    "\n",
    "edit_path_is_correct = all(\n",
    "    e(test_sentence1_prime) == test_sentence2 for e in edits\n",
    ")\n",
    "\n",
    "print('Source:   ', test_sentence1_prime)\n",
    "print('Target:   ', test_sentence2)\n",
    "print('Pointer path:', align)\n",
    "print('Edit path:', edits)\n",
    "print(\"Edit path is correct:\", edit_path_is_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "3659e79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:    ['a', 'synthesist', 'loves', 'a', 'happy', 'greyhound']\n",
      "Target:    ['a', 'virtuosic', 'synthesist', 'loves', 'some', 'happy', 'brindle', 'greyhound']\n",
      "Pointer path: [[(0, 0), (1, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (5, 7), (6, 8)]]\n",
      "Edit path: [[('insert', ('virtuosic', 1)), ('substitute', (('a', 'some'), 4)), ('insert', ('brindle', 6))]]\n",
      "Edit path is correct: True\n"
     ]
    }
   ],
   "source": [
    "test_sentence1_prime2 = test_sentence1[:4] + [\"some\"] + test_sentence1[5:]\n",
    "\n",
    "dist, align, edits = editdist(\n",
    "    test_sentence2, \n",
    "    test_sentence1_prime2\n",
    ")\n",
    "\n",
    "edit_path_is_correct = all(\n",
    "    e(test_sentence2) == test_sentence1_prime2 for e in edits\n",
    ")\n",
    "\n",
    "print('Source:   ', test_sentence2)\n",
    "print('Target:   ', test_sentence1_prime2)\n",
    "print('Pointer path:', align)\n",
    "print('Edit path:', edits)\n",
    "print(\"Edit path is correct:\", edit_path_is_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "fc352da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:    ['a', 'virtuosic', 'synthesist', 'loves', 'some', 'happy', 'brindle', 'greyhound']\n",
      "Target:    ['a', 'synthesist', 'loves', 'a', 'happy', 'greyhound']\n",
      "Pointer path: [[(0, 0), (1, 1), (2, 1), (3, 2), (4, 3), (5, 4), (6, 5), (7, 5), (8, 6)]]\n",
      "Edit path: [[('delete', ('virtuosic', 1)), ('substitute', (('some', 'a'), 3)), ('delete', ('brindle', 5))]]\n",
      "Edit path is correct: True\n"
     ]
    }
   ],
   "source": [
    "dist, align, edits = editdist(test_sentence1_prime2, test_sentence2)\n",
    "\n",
    "edit_path_is_correct = all(\n",
    "    e(test_sentence1_prime2) == test_sentence2 for e in edits\n",
    ")\n",
    "\n",
    "print('Source:   ', test_sentence1_prime2)\n",
    "print('Target:   ', test_sentence2)\n",
    "print('Pointer path:', align)\n",
    "print('Edit path:', edits)\n",
    "print(\"Edit path is correct:\", all(e(test_sentence1_prime2) == test_sentence2 for e in edits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "bfd81ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:    ['some', 'virtuosic', 'synthesist', 'loves', 'some', 'happy', 'brindle', 'greyhound']\n",
      "Target:    ['a', 'synthesist', 'loves', 'a', 'happy', 'greyhound']\n",
      "Pointer path: [[(0, 0), (1, 0), (2, 1), (3, 2), (4, 3), (5, 4), (6, 5), (7, 5), (8, 6)], [(0, 0), (1, 1), (2, 1), (3, 2), (4, 3), (5, 4), (6, 5), (7, 5), (8, 6)]]\n",
      "Edit path: [[('delete', ('some', 0)), ('substitute', (('virtuosic', 'a'), 0)), ('substitute', (('some', 'a'), 3)), ('delete', ('brindle', 5))], [('substitute', (('some', 'a'), 0)), ('delete', ('virtuosic', 1)), ('substitute', (('some', 'a'), 3)), ('delete', ('brindle', 5))]]\n",
      "Edit path is correct: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_sentence1_prime3 = [\"some\"] + test_sentence1[1:4] + [\"some\"] + test_sentence1[5:]\n",
    "dist, align, edits = editdist(test_sentence1_prime3, test_sentence2)\n",
    "\n",
    "edit_path_is_correct = all(\n",
    "    e(test_sentence1_prime3) == test_sentence2 for e in edits\n",
    ")\n",
    "\n",
    "print('Source:   ', test_sentence1_prime3)\n",
    "print('Target:   ', test_sentence2)\n",
    "print('Pointer path:', align)\n",
    "print('Edit path:', edits)\n",
    "print(\"Edit path is correct:\", edit_path_is_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "ca9fd871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:    ['a', 'synthesist', 'loves', 'a', 'happy', 'greyhound']\n",
      "Target:    ['some', 'virtuosic', 'synthesist', 'loves', 'some', 'happy', 'brindle', 'greyhound']\n",
      "Pointer path: [[(0, 0), (1, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (5, 7), (6, 8)], [(0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (5, 7), (6, 8)]]\n",
      "Edit path: [[('substitute', (('a', 'some'), 0)), ('insert', ('virtuosic', 1)), ('substitute', (('a', 'some'), 4)), ('insert', ('brindle', 6))], [('insert', ('some', 0)), ('substitute', (('a', 'virtuosic'), 1)), ('substitute', (('a', 'some'), 4)), ('insert', ('brindle', 6))]]\n",
      "Edit path is correct: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dist, align, edits = editdist(test_sentence2, test_sentence1_prime3)\n",
    "\n",
    "edit_path_is_correct = all(\n",
    "    e(test_sentence2) == test_sentence1_prime3 for e in edits\n",
    ")\n",
    "\n",
    "print('Source:   ', test_sentence2)\n",
    "print('Target:   ', test_sentence1_prime3)\n",
    "print('Pointer path:', align)\n",
    "print('Edit path:', edits)\n",
    "print(\"Edit path is correct:\", edit_path_is_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_xVZ2SibE64B",
   "metadata": {
    "id": "_xVZ2SibE64B"
   },
   "source": [
    "Implement the `__call__` method for the `NaturalLogic` class. This should take a premise sentence and a hypothesis sentence, and it should produce the paths of inferences (computed from the paths of edits) that take you from premise to hypothesis. \n",
    "\n",
    "Each path should be a list of inferences that result from cumulatively composing the inferences associated with each edit in the path. It should **not** be a path of local inferences. That is, it should not be a list of inferences that result from each edit in an edit path, but rather a list of inferences that result from composing those edits using `Inference.__add__`.\n",
    "\n",
    "You will **not** be using `EditPath.__call__` in any way. That method is implemented to demonstrate how we should apply edit paths to strings. You should instead be using `EditPath.to_editors` to get the list of editors that result from the edit path, and then you should use those editors to compute the local inferences (again, the inferences that result from applying each editor in sequence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "F9yzAtCHE64B",
   "metadata": {
    "id": "F9yzAtCHE64B"
   },
   "outputs": [],
   "source": [
    "InferencePath = tuple[Inference]\n",
    "\n",
    "class NaturalLogic:\n",
    "    \"\"\"Class for performing natural logic inference between sentences.\n",
    "\n",
    "    This class implements natural logic inference by finding edit paths between sentences\n",
    "    and composing the inferences associated with each edit. It uses an editor library\n",
    "    that maps edit operations (substitutions, deletions, insertions) to Editor instances\n",
    "    that specify the inference relations for those edits.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    editor_library : EditorLibrary, optional\n",
    "        Dictionary mapping edit types and parameters to Editor instances. The outer \n",
    "        dictionary maps edit types (e.g. 'substitute', 'delete', 'insert') to inner \n",
    "        dictionaries that map edit parameters to Editor instances. Defaults to an empty\n",
    "        EditorLibrary.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    EDIT : StringEdit\n",
    "        StringEdit instance used for computing edit distances and paths between strings,\n",
    "        with default costs of 1 for substitution, deletion, and insertion.\n",
    "    _editor_library : EditorLibrary\n",
    "        The editor library containing the inference rules for different edits.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    EDIT = StringEdit(1, 1, 1)\n",
    "    \n",
    "    def __init__(self, editor_library: EditorLibrary=EditorLibrary()):\n",
    "        self._editor_library = editor_library\n",
    "    \n",
    "    def __getitem__(self, key: tuple[EditorType, EditorInputOutput]):\n",
    "        return self._editor_library[key]\n",
    "    \n",
    "    def __call__(self, premise: list[str], hypothesis: list[str]) -> set[InferencePath]:\n",
    "        \"\"\"Perform natural logic inference between a premise and hypothesis sentence.\n",
    "\n",
    "        This method computes the possible edit paths between the premise and \n",
    "        hypothesis, and then composes the inferences associated with each edit \n",
    "        to yield all possible inference paths implied by the edit paths.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        premise : list[str]\n",
    "            The premise sentence to infer from.\n",
    "        hypothesis : list[str]\n",
    "            The hypothesis sentence to infer to.\n",
    "\n",
    "        Returns \n",
    "        -------\n",
    "        global_inference_paths : list[InferencePath]\n",
    "            A list of inference paths representing the paths of cumulatively \n",
    "            composed inferences from the premise to the hypothesis implied by \n",
    "            the edit path.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "keeRonENE64B",
   "metadata": {
    "id": "keeRonENE64B"
   },
   "source": [
    "Implement tests using the four test sentences above. (Ignore my modified versions of these sentences.) For now, you can just assume that the editor library contains the editors defined for Task 1. (We don't need to explicitly specify any insertions that result in $\\sqsupset$ or deletions that result in $\\sqsubset$, since those are added by default by `NaturalLogic.add_editor`.) In Task 3, we will expand the library using [WordNet](https://wordnet.princeton.edu/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HVM5wCSOE64B",
   "metadata": {
    "id": "HVM5wCSOE64B"
   },
   "outputs": [],
   "source": [
    "library = {'substitute': {('virtuosic', 'fake'): substitute_fake_for_virtuosic,\n",
    "                          ('fake', 'virtuosic'): substitute_virtuosic_for_fake,\n",
    "                          ('brindle', 'fawn'): substitute_fawn_for_brindle}, \n",
    "           'delete': {\"fake\": delete_fake}, \n",
    "           'insert': {\"fake\": insert_fake}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Fzq33LxxE64B",
   "metadata": {
    "id": "Fzq33LxxE64B"
   },
   "outputs": [],
   "source": [
    "# write tests here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IzlawFvyE64B",
   "metadata": {
    "id": "IzlawFvyE64B"
   },
   "source": [
    "## Evaluating against FraCaS\n",
    "\n",
    "For the remainder of the assignment (Tasks 3 and 4), we will evaluate our `NaturalLogic` implementation using the [FraCaS textual inference test suite](https://nlp.stanford.edu/~wcmac/downloads/fracas.xml). FraCaS is shipped as XML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HDjqdHS_E64B",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1486,
     "status": "ok",
     "timestamp": 1678725791472,
     "user": {
      "displayName": "Aaron Steven White",
      "userId": "06256629009318567325"
     },
     "user_tz": 240
    },
    "id": "HDjqdHS_E64B",
    "outputId": "5472734a-05a1-43a0-ab6c-591e8237bb1b"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "wget https://nlp.stanford.edu/~wcmac/downloads/fracas.xml\n",
    "cat fracas.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Kxqlq6J7E64B",
   "metadata": {
    "id": "Kxqlq6J7E64B"
   },
   "source": [
    "I've included a simple corpus reader below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "P_0OIUnwE64B",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8901,
     "status": "ok",
     "timestamp": 1678725812401,
     "user": {
      "displayName": "Aaron Steven White",
      "userId": "06256629009318567325"
     },
     "user_tz": 240
    },
    "id": "P_0OIUnwE64B",
    "outputId": "6d0dc6c5-1c26-4fea-8e2f-05a54e304b0e"
   },
   "outputs": [],
   "source": [
    "!pip install beautifulsoup4\n",
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GjtI0AgLE64C",
   "metadata": {
    "executionInfo": {
     "elapsed": 205,
     "status": "ok",
     "timestamp": 1678725812596,
     "user": {
      "displayName": "Aaron Steven White",
      "userId": "06256629009318567325"
     },
     "user_tz": 240
    },
    "id": "GjtI0AgLE64C"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, Tag\n",
    "\n",
    "class Fracas:\n",
    "    \"\"\"Corpus reader for the FraCaS textual inference problem set\"\"\"\n",
    "    \n",
    "    def __init__(self, root: str=\"fracas.xml\"):\n",
    "        with open(root) as fp:\n",
    "            self._data = BeautifulSoup(fp, 'lxml')\n",
    "            \n",
    "        self._construct_problem_generator()\n",
    "            \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        return next(self._problem_generator)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self._data.comment.string\n",
    "     \n",
    "    def _construct_problem_generator(self):\n",
    "        for problem in self.problems:\n",
    "            yield problem\n",
    "    \n",
    "    @property\n",
    "    def problems(self):\n",
    "        return [FracasProblem(problem) \n",
    "                for problem in self._data.find_all('problem')]\n",
    "\n",
    "class FracasProblem:\n",
    "    \"\"\"A FraCaS problem\"\"\"\n",
    "    \n",
    "    problem_type_map = {'001'}\n",
    "    \n",
    "    def __init__(self, problem: Tag):\n",
    "        self.id = problem.get('id')\n",
    "        self.answer = problem.get('fracas_answer')\n",
    "        \n",
    "        self.premise = problem.p.string.strip()\n",
    "        self.question = problem.q.string.strip()\n",
    "        self.hypothesis = problem.h.string.strip()\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return (f\"id: {self.id}\"\n",
    "                f\"\\n\\npremise: {self.premise}\"\n",
    "                f\"\\nquestion: {self.question}\"\n",
    "                f\"\\nhypothesis: {self.hypothesis}\"\n",
    "                f\"\\n\\nanswer: {self.answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "P95G2O6CE64C",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 381,
     "status": "ok",
     "timestamp": 1678725812975,
     "user": {
      "displayName": "Aaron Steven White",
      "userId": "06256629009318567325"
     },
     "user_tz": 240
    },
    "id": "P95G2O6CE64C",
    "outputId": "3d903679-41d7-4dc8-f240-16eb1bf17fae"
   },
   "outputs": [],
   "source": [
    "fracas = Fracas()\n",
    "\n",
    "fracas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XnjCoTQOE64C",
   "metadata": {
    "id": "XnjCoTQOE64C"
   },
   "source": [
    "Since the sentences are just raw strings, to get them in the form of a list of strings, you will need a tokenizer. I would suggest using the one available in the [`stanza`](https://stanfordnlp.github.io/stanza/) package. For our purposes, it is also simpler to use the lemma, rather than the token itself, because your WordNet editor library won't handle inflectional morphology (unless you explicitly engineered it to)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zVHJauoyE64C",
   "metadata": {
    "id": "zVHJauoyE64C"
   },
   "outputs": [],
   "source": [
    "!pip install stanza\n",
    "\n",
    "import stanza\n",
    "\n",
    "stanza.download('en')\n",
    "lemmatizer = stanza.Pipeline('en', processors='tokenize, mwt, pos, lemma')\n",
    "\n",
    "lemmatizer('Every virtuosic synthesist loves some greyhounds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FUAo0QidE64C",
   "metadata": {
    "id": "FUAo0QidE64C"
   },
   "source": [
    "To use this dataset to test your `NaturalLogic` implementation, you will need to convert the inference produced by `__call__` into a \"yes\", \"no\", or \"don't know\" answer. (Don't worry about any items not labeled with one of these three. This will require you to define a mapping from inference types to answers. You should then compute the accuracy, precision, recall, and F1 of your system.\n",
    "\n",
    "Each of these metrics can be defined in terms of...\n",
    "\n",
    "1. The true positive count for class $c$: $$\\mathrm{tp}(\\hat{\\mathbf{y}}^\\mathrm{test}_i, \\mathbf{y}^\\mathrm{test}, c) = |\\{i\\;:\\;y^\\mathrm{test}_i = \\hat{y}^\\mathrm{test}_i = c\\}|$$\n",
    "2. The true negative count for class $c$: $$\\mathrm{tn}(\\hat{\\mathbf{y}}^\\mathrm{test}_i, \\mathbf{y}^\\mathrm{test}, c) = |\\{i\\;:\\;y^\\mathrm{test}_i \\neq c \\land \\hat{y}^\\mathrm{test}_i \\neq c\\}|$$\n",
    "3. The false positve count for class $c$: $$\\mathrm{fp}(\\hat{\\mathbf{y}}^\\mathrm{test}_i, \\mathbf{y}^\\mathrm{test}, c) = |\\{i\\;:\\;y^\\mathrm{test}_i \\neq c \\land \\hat{y}^\\mathrm{test}_i = c\\}|$$\n",
    "4. The false negative count for class $c$: $$\\mathrm{fn}(\\hat{\\mathbf{y}}^\\mathrm{test}_i, \\mathbf{y}^\\mathrm{test}, c) = |\\{i\\;:\\;y^\\mathrm{test}_i = c \\land \\hat{y}^\\mathrm{test}_i \\neq c\\}|$$\n",
    "\n",
    "...where the class is \"yes\", \"no\", or \"unknown\"; $y^\\mathrm{test}_i$ is the true label for item $i$ (found in FraCaS) and $\\hat{y}^\\mathrm{test}_i$ is your system's prediction for the class of item $i$. (Ignore cases where the class is not one of these three.)\n",
    "\n",
    "#### Accuracy\n",
    "\n",
    "For what proportion of the test data $\\{(x^\\mathrm{test}_{1}, y^\\mathrm{test}_1), ..., (x^\\mathrm{test}_N, y^\\mathrm{test}_N)\\}$ does the model's predicted class $f(x^\\mathrm{test}_i) = \\hat{y}^\\mathrm{test}_i$ for an item match the ground truth class for that item?\n",
    "\n",
    "$$\\mathrm{accuracy}\\left(\\hat{\\mathbf{y}}^\\mathrm{test}_i, \\mathbf{y}^\\mathrm{test}\\right) = \\frac{\\sum_{c \\in \\mathcal{Y}}\\mathrm{tp}(\\hat{\\mathbf{y}}^\\mathrm{test}_i, \\mathbf{y}^\\mathrm{test}, c) + \\mathrm{tn}(\\hat{\\mathbf{y}}^\\mathrm{test}_i, \\mathbf{y}^\\mathrm{test}, c)}{N}$$\n",
    "\n",
    "[`sklearn.metrics`](https://scikit-learn.org/stable/modules/model_evaluation.html) technically provides an [`accuracy_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score) function, but generally it's just as straightforward to compute it yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pxxhjxCNE64C",
   "metadata": {
    "id": "pxxhjxCNE64C"
   },
   "outputs": [],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ULbeDMdE64C",
   "metadata": {
    "id": "6ULbeDMdE64C"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DImQUFN-E64C",
   "metadata": {
    "id": "DImQUFN-E64C"
   },
   "source": [
    "#### Precision\n",
    "\n",
    "For a particular class $c$, what proportion of the test items that the model said have that class actually have that class?\n",
    "\n",
    "$$\\mathrm{precision}\\left(\\hat{\\mathbf{y}}^\\mathrm{test}_i, \\mathbf{y}^\\mathrm{test}, c\\right) = \\frac{\\mathrm{tp}(\\hat{\\mathbf{y}}^\\mathrm{test}_i, \\mathbf{y}^\\mathrm{test}, c)}{\\mathrm{tp}(\\hat{\\mathbf{y}}^\\mathrm{test}_i, \\mathbf{y}^\\mathrm{test}, c) + \\mathrm{fp}(\\hat{\\mathbf{y}}^\\mathrm{test}_i, \\mathbf{y}^\\mathrm{test}, c)}$$\n",
    "\n",
    "For giving an aggregate precision across classes, it's common to distinguish _micro-average_ precision and _macro-average_ precision.\n",
    "\n",
    "$$\\mathrm{microprecision}\\left(\\hat{\\mathbf{y}}^\\mathrm{test}_i, \\mathbf{y}^\\mathrm{test}\\right) = \\frac{\\sum_{c \\in \\mathcal{Y}} \\mathrm{tp}(\\hat{\\mathbf{y}}^\\mathrm{test}_i, \\mathbf{y}^\\mathrm{test}, c)}{\\sum_{c \\in \\mathcal{Y}} \\mathrm{tp}(\\hat{\\mathbf{y}}^\\mathrm{test}_i, \\mathbf{y}^\\mathrm{test}, c) + \\mathrm{fp}(\\hat{\\mathbf{y}}^\\mathrm{test}_i, \\mathbf{y}^\\mathrm{test}, c)}$$\n",
    "\n",
    "$$\\mathrm{macroprecision}\\left(\\hat{\\mathbf{y}}^\\mathrm{test}_i, \\mathbf{y}^\\mathrm{test}\\right) = \\frac{1}{|\\mathcal{Y}|}\\sum_{c \\in \\mathcal{Y}} \\mathrm{precision}\\left(\\hat{\\mathbf{y}}^\\mathrm{test}_i, \\mathbf{y}^\\mathrm{test}, c\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JxyyeQcNE64C",
   "metadata": {
    "id": "JxyyeQcNE64C"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VoXJmzqFE64C",
   "metadata": {
    "id": "VoXJmzqFE64C"
   },
   "source": [
    "#### Recall\n",
    "\n",
    "For a particular class $c$, what proportion of the test items that have that class did the model correctly predict to have that class?\n",
    "\n",
    "$$\\mathrm{recall}\\left(\\hat{\\mathbf{y}}^\\mathrm{test}_i, \\mathbf{y}^\\mathrm{test}, c\\right) = \\frac{\\mathrm{tp}(\\hat{\\mathbf{y}}^\\mathrm{test}_i, \\mathbf{y}^\\mathrm{test}, c)}{\\mathrm{tp}(\\hat{\\mathbf{y}}^\\mathrm{test}_i, \\mathbf{y}^\\mathrm{test}, c) + \\mathrm{fn}(\\hat{\\mathbf{y}}^\\mathrm{test}_i, \\mathbf{y}^\\mathrm{test}, c)}$$\n",
    "\n",
    "Similar definitions for micro- and macro-average recall can be given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdx8i1tUE64C",
   "metadata": {
    "id": "bdx8i1tUE64C"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "idHJcBLoE64C",
   "metadata": {
    "id": "idHJcBLoE64C"
   },
   "source": [
    "#### F1\n",
    "\n",
    "For a class $c$, what is the [harmonic mean](https://en.wikipedia.org/wiki/Harmonic_mean) of precision and recall?\n",
    "\n",
    "$$F_1\\left(\\hat{\\mathbf{y}}^\\mathrm{test}_i, \\mathbf{y}^\\mathrm{test}, c\\right) = \\frac{2}{\\frac{1}{\\mathrm{precision}\\left(\\hat{\\mathbf{y}}^\\mathrm{test}_i, \\mathbf{y}^\\mathrm{test}, c\\right)} + \\frac{1}{\\mathrm{recall}\\left(\\hat{\\mathbf{y}}^\\mathrm{test}_i, \\mathbf{y}^\\mathrm{test}, c\\right)}} = 2\\frac{\\mathrm{precision}\\left(\\hat{\\mathbf{y}}^\\mathrm{test}_i, \\mathbf{y}^\\mathrm{test}, c\\right)\\;\\cdot\\;\\mathrm{recall}\\left(\\hat{\\mathbf{y}}^\\mathrm{test}_i, \\mathbf{y}^\\mathrm{test}, c\\right)}{\\mathrm{precision}\\left(\\hat{\\mathbf{y}}^\\mathrm{test}_i, \\mathbf{y}^\\mathrm{test}, c\\right) + \\mathrm{recall}\\left(\\hat{\\mathbf{y}}^\\mathrm{test}_i, \\mathbf{y}^\\mathrm{test}, c\\right)}$$ \n",
    "\n",
    "To define micro- and macro-average $F_1$ it can be useful to reexpress it.\n",
    "\n",
    "$$F_1\\left(\\hat{\\mathbf{y}}^\\mathrm{test}_i, \\mathbf{y}^\\mathrm{test}, c\\right) = \\frac{2\\mathrm{tp}(\\hat{\\mathbf{y}}^\\mathrm{test}_i, \\mathbf{y}^\\mathrm{test}, c)}{2\\mathrm{tp}(\\hat{\\mathbf{y}}^\\mathrm{test}_i, \\mathbf{y}^\\mathrm{test}, c) + \\mathrm{fp}(\\hat{\\mathbf{y}}^\\mathrm{test}_i, \\mathbf{y}^\\mathrm{test}, c) + \\mathrm{fn}(\\hat{\\mathbf{y}}^\\mathrm{test}_i, \\mathbf{y}^\\mathrm{test}, c)}$$\n",
    "\n",
    "Definitions similar to those for precision can be given for micro- and macro-average $F_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8rdl0iLbE64D",
   "metadata": {
    "id": "8rdl0iLbE64D"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DEpwS_t8E64D",
   "metadata": {
    "id": "DEpwS_t8E64D"
   },
   "source": [
    "## Task 3\n",
    "\n",
    "Define an instance method `NaturalLogic.load_wordnet` that constructs an editor library from WordNet hypernymy, hyponymy, and antonymy relations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QIKTZA4lE64D",
   "metadata": {
    "id": "QIKTZA4lE64D"
   },
   "outputs": [],
   "source": [
    "!pip install nltk\n",
    "\n",
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bT_2UB2GE64D",
   "metadata": {
    "id": "bT_2UB2GE64D"
   },
   "outputs": [],
   "source": [
    "class NaturalLogic(NaturalLogic):\n",
    "\n",
    "    def load_wordnet(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @classmethod\n",
    "    def from_wordnet(cls):\n",
    "        natlog = cls()\n",
    "        natlog.load_wordnet()\n",
    "        \n",
    "        return natlog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0Mv_NnVME64D",
   "metadata": {
    "id": "0Mv_NnVME64D"
   },
   "source": [
    "Test your new library by writing examples that require knowledge of hypernymy, hyponymy, and antonymy to correctly handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aG7QdCX5E64D",
   "metadata": {
    "id": "aG7QdCX5E64D"
   },
   "outputs": [],
   "source": [
    "# write tests here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mmCEFr6cE64D",
   "metadata": {
    "id": "mmCEFr6cE64D"
   },
   "source": [
    "Evaluate your new library on FraCaS by computing precision, recall, and F1 for the items that are either labeled \"yes\", \"no\", or \"don't know\". Remember that this is going to require you to define a way of mapping inference types to answers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yjz1hjjME64D",
   "metadata": {
    "id": "yjz1hjjME64D"
   },
   "outputs": [],
   "source": [
    "# write evaluation here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jTRdluaUE64D",
   "metadata": {
    "id": "jTRdluaUE64D"
   },
   "source": [
    "These numbers will be bad. The point is to see that handling even the apparently simple cases in FraCaS is very difficult, even with a fairly extensive edit library.\n",
    "\n",
    "Find at least three examples you get wrong. For each example, identify where in the edit sequence the problem occurs and explain how this issue might be fixed on the basis of what you read in MacCartney and Manning. (Hint: look at how they model quantifiers and negation.) If the MacCartney and Manning approach is not fully sufficient to fix the error, identify what you would need to do to extend it to handle the problem. (Hint: this will often involve changes to your editor library. What would those changes need to look like?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7478f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write explanation here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
