{"cells":[{"cell_type":"raw","id":"314e5b2f","metadata":{},"source":["---\n","title: Assignments 9 and 10\n","highlight-style: oblivion\n","format:\n","    html:\n","        code-tools: true\n","---"]},{"cell_type":"markdown","id":"NFKTUYv18pGu","metadata":{"id":"NFKTUYv18pGu"},"source":["*Assignment 9 consists of Tasks 1 and 2 and Assignment 10 consists of Tasks 3-5.*\n","\n","In these assignments, we will focus on (i) extracting context free grammars (CFGs) from a treebank; and (ii) implement the CKY and Earley algorithms for recognizing/parsing CFGs.\n","\n","## Trees\n","\n","We'll use a slightly augmented version of the `Tree` class we developed earlier in the class to represent trees that should be output by the parser."]},{"cell_type":"code","execution_count":1,"id":"jSV_DOz58pGx","metadata":{"id":"jSV_DOz58pGx"},"outputs":[],"source":["import pyparsing\n","\n","from typing import TypeVar, Optional\n","from collections.abc import Hashable, Callable\n","\n","DataType = Hashable\n","TreeList = list[str, Optional[list['TreeList']]]\n","TreeTuple = tuple[DataType, Optional[tuple['TreeTuple', ...]]]\n","\n","class Tree:\n","\n","    LPAR = pyparsing.Suppress('(')\n","    RPAR = pyparsing.Suppress(')')\n","    DATA = pyparsing.Regex(r'[^\\(\\)\\s]+')\n","\n","    PARSER = pyparsing.Forward()\n","    SUBTREE = pyparsing.ZeroOrMore(PARSER)\n","    PARSERLIST = pyparsing.Group(LPAR + DATA + SUBTREE + RPAR)\n","    PARSER <<= DATA | PARSERLIST\n","    \n","    def __init__(self, data: DataType, children: list['Tree'] = []):\n","        self._data = data\n","        self._children = children\n","        \n","        self._validate()\n","  \n","    def to_tuple(self) -> TreeTuple:\n","        return self._data, tuple(c.to_tuple() for c in self._children)\n","\n","    def __hash__(self) -> int:\n","        return hash(self.to_tuple())\n","    \n","    def __eq__(self, other: 'Tree') -> bool:\n","        return self.to_tuple() == other.to_tuple()\n","\n","    def __str__(self) -> str:\n","        return ' '.join(self.terminals)\n","        \n","    def __repr__(self) -> str:\n","        return self.to_string()\n","     \n","    def to_string(self, depth=0) -> str:\n","        s = (depth - 1) * '  ' +\\\n","            int(depth > 0) * '--' +\\\n","            self._data + '\\n'\n","        s += ''.join(c.to_string(depth+1)\n","                     for c in self._children)\n","        \n","        return s\n","    \n","    def __contains__(self, data: DataType) -> bool:\n","        # pre-order depth-first search\n","        if self._data == data:\n","            return True\n","        else:\n","            for child in self._children:\n","                if data in child:\n","                    return True\n","                \n","            return False\n","        \n","    def __getitem__(self, idx: int | tuple[int, ...]) -> 'Tree':\n","        if isinstance(idx, int):\n","            return self._children[idx]\n","        elif len(idx) == 1:\n","            return self._children[idx[0]]\n","        elif idx:\n","            return self._children[idx[0]].__getitem__(idx[1:])\n","        else:\n","            return self\n","        \n","    @property\n","    def data(self) -> DataType:\n","        return self._data \n","    \n","    @property\n","    def children(self) -> list['Tree']:\n","        return self._children\n","     \n","    @property\n","    def terminals(self) -> list[str]:\n","        if self._children:\n","            return [w for c in self._children \n","                    for w in c.terminals]\n","        else:\n","            return [str(self._data)]\n","        \n","    def _validate(self) -> None:\n","        try:\n","            assert all(isinstance(c, Tree)\n","                       for c in self._children)\n","        except AssertionError:\n","            msg = 'all children must be trees'\n","            raise TypeError(msg)\n","            \n","    def index(self, data: DataType, index_path: tuple[int, ...] = tuple()) -> list[tuple[int, ...]]:\n","        indices = [index_path] if self._data==data else []\n","        root_path = [] if index_path == -1 else index_path\n","        \n","        indices += [j \n","                    for i, c in enumerate(self._children) \n","                    for j in c.index(data, root_path+(i,))]\n","\n","        return indices\n","    \n","    def relabel(self, label_map: Callable[[DataType], DataType], \n","                nonterminals_only: bool = False, terminals_only: bool = False) -> 'Tree':\n","        if not nonterminals_only and not terminals_only:\n","            data = label_map(self._data)\n","        elif nonterminals_only and self._children:\n","            data = label_map(self._data)\n","        elif terminals_only and not self._children:\n","            data = label_map(self._data)\n","        else:\n","            data = self._data\n","        \n","        children = [c.relabel(label_map, nonterminals_only, terminals_only) \n","                    for c in self._children]\n","        \n","        return self.__class__(data, children)\n","    \n","    @classmethod\n","    def from_string(cls, treestr: str) -> 'Tree':\n","        treelist = cls.PARSER.parseString(treestr[2:-2])[0]\n","        \n","        return cls.from_list(treelist)\n","    \n","    @classmethod\n","    def from_list(cls, treelist: TreeList) -> 'Tree':\n","        if isinstance(treelist, str):\n","            return cls(treelist[0])\n","        elif isinstance(treelist[1], str):\n","            return cls(treelist[0], [cls(treelist[1])])\n","        else:\n","            return cls(treelist[0], [cls.from_list(l) for l in treelist[1:]])"]},{"cell_type":"markdown","id":"SmKm0nfs8pGy","metadata":{"id":"SmKm0nfs8pGy"},"source":["## CFG rules\n","\n","Vanilla context free grammar rules (in contrast to the dotted rules we use for Earley, define below) will be represented using a fairly lightweight wrapper around pairings of a string (the left side) with a tuple of strings (the right side)."]},{"cell_type":"code","execution_count":2,"id":"tS4mlSNw8pGz","metadata":{"id":"tS4mlSNw8pGz"},"outputs":[],"source":["from enum import Enum\n","\n","class NormalForm(Enum):\n","    CNF = 0\n","    BNF = 1\n","    GNF = 2\n","\n","class Rule:\n","    \"\"\"A context free grammar rule\n","\n","    Parameters\n","    ----------\n","    left_side\n","    right_side\n","    \"\"\"\n","\n","    def __init__(self, left_side: str, *right_side: str):\n","        self._left_side = left_side\n","        self._right_side = right_side\n","\n","    def __repr__(self) -> str:\n","        return self._left_side + ' -> ' + ' '.join(self._right_side)\n","        \n","    def to_tuple(self) -> tuple[str, tuple[str, ...]]:\n","        return (self._left_side, self._right_side)\n","        \n","    def __hash__(self) -> int:\n","        return hash(self.to_tuple())\n","\n","    def __eq__(self, other: 'Rule') -> bool:\n","        left_side_equal = self._left_side == other._left_side\n","        right_side_equal = self._right_side == other._right_side\n","\n","        return left_side_equal and right_side_equal\n","\n","    def validate(self, alphabet: set[str], variables: set[str], normal_form: NormalForm = NormalForm.CNF):\n","        \"\"\"validate the rule\n","\n","        Parameters\n","        ----------\n","        alphabet : set(str)\n","        variables : set(str)\n","        \"\"\"\n","\n","        if self._left_side not in variables:\n","            msg = \"left side of rule must be a variable\"\n","            raise ValueError(msg)\n","\n","        acceptable = alphabet | variables | {''}\n","            \n","        if not all([s in acceptable for s in self._right_side]):\n","            msg = \"right side of rule must contain only\" +\\\n","                  \"a variable, a symbol, or the empty string\"\n","            raise ValueError(msg)\n","\n","        if normal_form == NormalForm.CNF:\n","            try:\n","                if len(self.right_side) == 1:\n","                    assert self.right_side[0] in alphabet\n","                elif len(self.right_side) == 2:\n","                    assert all([s in variables for s in self.right_side])\n","                else:\n","                    raise AssertionError\n","\n","            except AssertionError:\n","                raise ValueError(f\"{self} is not in CNF\")\n","        \n","\n","    @property\n","    def left_side(self) -> str:\n","        return self._left_side\n","\n","    @property\n","    def right_side(self) -> tuple[str, ...]:\n","        return self._right_side\n","\n","    @property\n","    def is_unary(self) -> bool:\n","        return len(self._right_side) == 1\n","    \n","    @property\n","    def is_binary(self) -> bool:\n","        return len(self._right_side) == 2"]},{"cell_type":"markdown","id":"dC8xe18e8pG0","metadata":{"id":"dC8xe18e8pG0"},"source":["Defining a rule is straightforward."]},{"cell_type":"code","execution_count":3,"id":"Yd9HpZ-h8pG0","metadata":{"id":"Yd9HpZ-h8pG0"},"outputs":[{"data":{"text/plain":["S -> NP VP"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["Rule(\"S\", \"NP\", \"VP\")"]},{"cell_type":"markdown","id":"GQ9M1Srq8pG1","metadata":{"id":"GQ9M1Srq8pG1"},"source":["Note that these rules are hashable, so they can be members of a python `set`."]},{"cell_type":"code","execution_count":4,"id":"A_wXf5JE8pG1","metadata":{"id":"A_wXf5JE8pG1"},"outputs":[{"data":{"text/plain":["{S -> NP VP}"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["{Rule(\"S\", \"NP\", \"VP\"), Rule(\"S\", \"NP\", \"VP\")}"]},{"cell_type":"markdown","id":"yQ3MC9Ks8pG1","metadata":{"id":"yQ3MC9Ks8pG1"},"source":["## Context Free Grammar\n","\n","As in the previous two assignments, we will define a `ContextFreeGrammar` to align very closely with the formal definition we covered in class. But because the recognition and parsing algorithms are slightly more complicated than those for finite state automata, we will factor the parsing algorithms themselves out of this class. To do this, we will specify a parser class that the grammar will initialize during its own initilization. We will set it to `None` to start, which will mean that we won't be able to use the `ContextFreeGrammar.__call__` method until we define a parser."]},{"cell_type":"code","execution_count":5,"id":"yG_H6oVh8pG1","metadata":{"id":"yG_H6oVh8pG1"},"outputs":[],"source":["from typing import Literal\n","from functools import lru_cache\n","\n","Mode = Literal[\"recognize\", \"parse\"]\n","\n","class ContextFreeGrammar:\n","\n","    \"\"\"\n","    A context free grammar\n","\n","    Parameters\n","    ----------\n","    alphabet : set(str)\n","    variables : set(str)\n","    rules : set(Rule)\n","    start_variable : str\n","\n","    Attributes\n","    ----------\n","    alphabet : set(str)\n","    variables : set(str)\n","    rules : set(Rule)\n","    start_variable : str\n","\n","    Methods\n","    -------\n","    reduce(left_side)\n","    \"\"\"\n","    \n","    # this will need to be filled in by the parser class, once it is defined:\n","    # - CKYParser\n","    # - EarleyParser\n","    parser_class = None\n","    \n","    def __init__(self, alphabet: set[str], variables: set[str], rules: set[Rule], start_variable: str):\n","        self._alphabet = alphabet\n","        self._variables = variables\n","        self._rules = rules\n","        self._start_variable = start_variable\n","        \n","        self._validate_variables()\n","        self._validate_rules()\n","\n","        if self.parser_class is not None:\n","            self._parser = self.parser_class(self)\n","        else:\n","            self._parser = None\n","\n","    def __call__(self, string: str | list[str], mode: Mode = \"recognize\"):\n","        if self._parser is not None:\n","            return self._parser(string, mode)\n","        else:\n","            raise AttributeError(\"no parser is specified\")\n","        \n","    def _validate_variables(self):\n","        if self._alphabet & self._variables:\n","            raise ValueError('alphabet and variables must not share elements')\n","        \n","        if self._start_variable not in self._variables:\n","            raise ValueError('start variable must be in set of variables')\n","\n","    def _validate_rules(self):\n","        if self.parser_class is not None:\n","            for r in self._rules:\n","                r.validate(self._alphabet, self._variables,\n","                           self.parser_class.normal_form)\n","\n","    @property            \n","    def alphabet(self) -> set[str]:\n","        return self._alphabet\n","\n","    @property    \n","    def variables(self) -> set[str]:\n","        return self._variables\n","   \n","    @lru_cache(2**10)\n","    def rules(self, left_side: str | None = None) -> set[Rule]:\n","        if left_side is None:\n","            return self._rules\n","        else:\n","            return {rule for rule in self._rules \n","                    if rule.left_side == left_side}\n","\n","    @property\n","    def start_variable(self) -> str:\n","        return self._start_variable\n","\n","    @lru_cache(2**14)\n","    def parts_of_speech(self, word: str | None = None) -> set[str]:\n","        if word is None:\n","            return {rule.left_side for rule in self._rules \n","                    if rule.is_unary \n","                    if rule.right_side[0] in self._alphabet}\n","        \n","        else:\n","            return {rule.left_side for rule in self._rules \n","                    if rule.is_unary \n","                    if rule.right_side[0] == word}\n","  \n","    @property\n","    def phrase_variables(self) -> set[str]:\n","        try:\n","            return self._phrase_variables\n","        except AttributeError:\n","            self._phrase_variables = {rule.left_side for rule in self._rules \n","                                      if not rule.is_unary or \n","                                      rule.right_side[0] not in self._alphabet}\n","            return self._phrase_variables\n","\n","    @lru_cache(2^15)\n","    def reduce(self, *right_side: str) -> set[str]:\n","        \"\"\"\n","        the nonterminals that can be rewritten as right_side\n","\n","        Parameters\n","        ----------\n","        right_side\n","\n","        Returns\n","        -------\n","        set(str)\n","        \"\"\"\n","        return {r.left_side for r in self._rules\n","                if r.right_side == tuple(right_side)}"]},{"cell_type":"markdown","id":"4O8M4cJH8pG2","metadata":{"id":"4O8M4cJH8pG2"},"source":["We can then define a context free grammar as below."]},{"cell_type":"code","execution_count":6,"id":"B5vYpBRB8pG2","metadata":{"id":"B5vYpBRB8pG2"},"outputs":[],"source":["grammar = ContextFreeGrammar(alphabet={'the', 'greyhound', 'ate', 'the', 'salmon',\n","                                       'with', 'a', 'fork', 'again', 'quickly'},\n","                             variables={'S', 'NP', 'VP', 'PP', 'D', 'N', 'V', 'P', 'Adv'},\n","                             rules={Rule('S', 'NP', 'VP'),\n","                                    Rule('NP', 'D', 'N'),\n","                                    Rule('NP', 'NP', 'PP'),\n","                                    Rule('VP', 'V', 'NP'),\n","                                    Rule('VP', 'VP', 'PP'),\n","                                    Rule('VP', 'Adv', 'VP'),\n","                                    Rule('VP', 'VP', 'Adv'),\n","                                    Rule('PP', 'P', 'NP'),\n","                                    Rule('D', 'the'),\n","                                    Rule('D', 'a'),\n","                                    Rule('N', 'greyhound'),\n","                                    Rule('N', 'salmon'),\n","                                    Rule('N', 'fork'),\n","                                    Rule('V', 'fork'),\n","                                    Rule('V', 'ate'),\n","                                    Rule('P', 'with'),\n","                                    Rule('Adv', 'again'),\n","                                    Rule('Adv', 'quickly')},\n","                             start_variable='S')"]},{"cell_type":"markdown","id":"rxr9Ue7g8pG2","metadata":{"id":"rxr9Ue7g8pG2"},"source":["There are a few attributes and methods to take note of here. One allows you to easily work with parts of speech..."]},{"cell_type":"code","execution_count":7,"id":"ZbSfJXk78pG2","metadata":{"id":"ZbSfJXk78pG2"},"outputs":[{"data":{"text/plain":["{'Adv', 'D', 'N', 'P', 'V'}"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["grammar.parts_of_speech()"]},{"cell_type":"markdown","id":"qQIKqENE8pG2","metadata":{"id":"qQIKqENE8pG2"},"source":["...including finding all the parts of speech for a particular word."]},{"cell_type":"code","execution_count":8,"id":"v0mw27ob8pG2","metadata":{"id":"v0mw27ob8pG2"},"outputs":[{"data":{"text/plain":["{'N', 'V'}"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["grammar.parts_of_speech(\"fork\")"]},{"cell_type":"markdown","id":"N0ycomga8pG3","metadata":{"id":"N0ycomga8pG3"},"source":["Another allows easy access to rules..."]},{"cell_type":"code","execution_count":9,"id":"2nM2bPa48pG3","metadata":{"id":"2nM2bPa48pG3"},"outputs":[{"data":{"text/plain":["{Adv -> again,\n"," Adv -> quickly,\n"," D -> a,\n"," D -> the,\n"," N -> fork,\n"," N -> greyhound,\n"," N -> salmon,\n"," NP -> D N,\n"," NP -> NP PP,\n"," P -> with,\n"," PP -> P NP,\n"," S -> NP VP,\n"," V -> ate,\n"," V -> fork,\n"," VP -> Adv VP,\n"," VP -> V NP,\n"," VP -> VP Adv,\n"," VP -> VP PP}"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["grammar.rules()"]},{"cell_type":"markdown","id":"sX7QfEsA8pG3","metadata":{"id":"sX7QfEsA8pG3"},"source":["...including finding all rules that have a particular left side."]},{"cell_type":"code","execution_count":10,"id":"YaQnNqY58pG3","metadata":{"id":"YaQnNqY58pG3"},"outputs":[{"data":{"text/plain":["{VP -> Adv VP, VP -> V NP, VP -> VP Adv, VP -> VP PP}"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["grammar.rules(\"VP\")"]},{"cell_type":"markdown","id":"-_OQqtNX8pG3","metadata":{"id":"-_OQqtNX8pG3"},"source":["Most importantly, I have implemented a `ContextFreeGrammar.reduce` method for finding all left sides that can be rewritten from a particular right side."]},{"cell_type":"code","execution_count":11,"id":"PGdU2deZ8pG3","metadata":{"id":"PGdU2deZ8pG3"},"outputs":[{"data":{"text/plain":["{'VP'}"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["grammar.reduce(\"V\", \"NP\")"]},{"cell_type":"markdown","id":"wvfO1Mkk8pG3","metadata":{"id":"wvfO1Mkk8pG3"},"source":["## Treebank\n","\n","We will extract a CFG from the English Web Treebank. We can use the reader developed earlier in the course to read the treebank."]},{"cell_type":"code","execution_count":null,"id":"9IOJLHJ28pG4","metadata":{"id":"9IOJLHJ28pG4"},"outputs":[],"source":["import tarfile\n","from abc import ABC\n","\n","class TreeBank(ABC):\n","    \n","    def __iter__(self):\n","        return self\n","    \n","    def __next__(self):\n","        return next(self._tree_iter)\n","        \n","class EnglishWebTreebank(TreeBank):\n","    \n","    def __init__(self, root='LDC2012T13.tgz'):\n","        self._root = root\n","\n","        self._tree_iter = self._construct_tree_iter()\n","        \n","    def _construct_tree_iter(self):\n","        with tarfile.open(self._root) as corpus:\n","            for fname in corpus.getnames():\n","                if '.xml.tree' in fname:\n","                    with corpus.extractfile(fname) as treefile:\n","                        treestr = treefile.readline().decode()\n","                        yield fname, Tree.from_string(treestr)"]},{"cell_type":"markdown","id":"Sg-AyLfm8pG4","metadata":{"id":"Sg-AyLfm8pG4"},"source":["## Task 1\n","\n","Write a class method `ContextFreeGrammar.from_treebank` that extracts all of the alphabet elements, variables, and rules implied by the trees in the treebank. For instance, the rules implied by the following tree..."]},{"cell_type":"code","execution_count":null,"id":"SWR6pR4K8pG4","metadata":{"id":"SWR6pR4K8pG4"},"outputs":[],"source":["print(next(EnglishWebTreebank())[1].__repr__())"]},{"cell_type":"markdown","id":"LhcaF4708pG4","metadata":{"id":"LhcaF4708pG4"},"source":["...are:\n","\n","```\n","VB -> try\n","PP-LOC -> IN NP\n","NP -> NNP NNP\n","JJ -> argentinian\n","UH -> please\n","NP -> DT JJ NN\n","VB -> like\n","-NONE- -> *PRO*\n","NP-SBJ-1 -> PRP\n","NNP -> tampa\n","NP-SBJ -> PRP\n","IN -> in\n","SQ -> MD NP-SBJ VP\n","S -> NP-SBJ-1 VP\n","WHADVP-9 -> WRB\n","VP -> VB NP PP-LOC ADVP-LOC-9\n","VP -> VB NP INTJ\n","NNP -> bay\n","NP -> NNS\n","PRP -> I\n","S -> NP-SBJ VP\n","NNS -> morcillas\n","VP -> TO VP\n","MD -> will\n","-NONE- -> *T*\n","NN -> type\n","WRB -> where\n","VP -> MD S\n","MD -> can\n","INTJ -> UH\n",". -> ?\n","CC -> but\n",", -> ,\n","NP-SBJ-1 -> -NONE-\n","S -> S , CC S\n","VB -> get\n","NNS -> anothers\n","S -> SBARQ , S .\n","ADVP-LOC-9 -> -NONE-\n","VP -> VB NP\n","DT -> the\n","VP -> MD VP\n","TO -> to\n","SBARQ -> WHADVP-9 SQ\n","```\n","\n","I suggest breaking extraction into extraction from a tree using a `rules` attribute..."]},{"cell_type":"code","execution_count":null,"id":"E3v1ovK18pG4","metadata":{"id":"E3v1ovK18pG4"},"outputs":[],"source":["class Tree(Tree):\n","    \n","    @property\n","    def rules(self) -> set[Rule]:\n","        raise NotImplementedError "]},{"cell_type":"markdown","id":"4-BAPlq08pG4","metadata":{"id":"4-BAPlq08pG4"},"source":["...which you can use to implement `ContextFreeGrammar.from_treebank`."]},{"cell_type":"code","execution_count":null,"id":"xWBidgU38pG4","metadata":{"id":"xWBidgU38pG4"},"outputs":[],"source":["class ContextFreeGrammar(ContextFreeGrammar):\n","    \n","    @classmethod\n","    def from_treebank(cls, treebank: TreeBank) -> 'ContextFreeGrammar':\n","        raise NotImplementedError"]},{"cell_type":"markdown","id":"g4slKcIY8pG4","metadata":{"id":"g4slKcIY8pG4"},"source":["One thing you will need to make sure to do is to ensure that the alphabet and variables are disjoint. This is not guaranteed using naive extraction: nine symbols that show up as nonterminals also show up as terminals. Handling this will require some relabeling, which you can do using `Tree.relabel`.\n","\n","Another thing you should make sure to do is to correctly handle trees whose root node is not `S`: a variety of \"sentences\" in EWT have `NP` or `FRAG` root nodes. But there are true sentences that have a root note other than `S`: `S-IMP`, `SBAR`, `SQ`, `SINV`, `SBARQ`, and `S-HLN`. Assume that all and only trees with variables at the root _starting_ with `S` are sentences. Doing this will entail adding some rules to the grammar.\n","\n","Finally, you should lower case all terminals. This can also be done with `Tree.relabel`.\n","\n","Test your `Tree.rules` attribute against the tree we looked at above."]},{"cell_type":"code","execution_count":null,"id":"nFOBkZaz8pG4","metadata":{"id":"nFOBkZaz8pG4"},"outputs":[],"source":["# write tests"]},{"cell_type":"markdown","id":"HMUBiNTc8pG4","metadata":{"id":"HMUBiNTc8pG4"},"source":["## CKY parsing\n","\n","We will implement CKY parsing and recognition using a system of classes: `CKYChart`s contain `CKYChartEntry`s and are filled with those entries by a `CKYParser`, which is a kind of `ContextFreeGrammarParser`. The reasoning behind having an abstract base class for `ContextFreeGrammarParser`s when we implement the `EarleyParser`."]},{"cell_type":"code","execution_count":null,"id":"IVhIsGbx8pG5","metadata":{"id":"IVhIsGbx8pG5"},"outputs":[],"source":["from typing import Union\n","\n","SpanIndices = tuple[int, int]\n","CKYBackPointer = tuple[str, SpanIndices]\n","\n","class Chart(ABC):\n","\n","    @property\n","    def parses(self):\n","        raise NotImplementedError\n","\n","class ChartEntry(ABC):\n","\n","    def __hash__(self) -> int:\n","        raise NotImplementedError\n","\n","    @property\n","    def backpointers(self):\n","        raise NotImplementedError\n","\n","class CKYChartEntry(ChartEntry):\n","    \"\"\"\n","    A chart entry for a CKY chart\n","\n","    Parameters\n","    ----------\n","    symbol\n","    backpointers\n","\n","    Attributes\n","    ----------\n","    symbol\n","    backpointers\n","    \"\"\"\n","\n","    def __init__(self, symbol: str, *backpointers: CKYBackPointer):\n","        self._symbol = symbol\n","        self._backpointers = backpointers\n","\n","    def to_tuple(self):\n","        return (self._symbol, self._backpointers)\n","        \n","    def __hash__(self) -> int:\n","        return hash(self.to_tuple())\n","\n","    def __eq__(self, other: 'CKYChartEntry') -> bool:\n","        return self.to_tuple() == other.to_tuple()\n","    \n","    def __repr__(self) -> str:\n","        return self._symbol + ' -> ' + ' '.join(\n","            f\"{bp[0]}({bp[1][0]}, {bp[1][1]})\" \n","            for bp in self.backpointers\n","        )\n","\n","    def __str__(self) -> str:\n","        return self.__repr__()\n","    \n","    @property\n","    def symbol(self) -> str:\n","        return self._symbol\n","\n","    @property\n","    def backpointers(self) -> tuple[CKYBackPointer, ...]:\n","        return self._backpointers\n","\n","class CKYChart(Chart):\n","    \"\"\"\n","    A chart for a CKY parser\n","\n","    Jurafsky & Martin call this a table\n","\n","    Parameters\n","    ----------\n","    input_size\n","\n","    Attributes\n","    ----------\n","    parses\n","    \"\"\"\n","\n","    def __init__(self, input_size: int):\n","        self._input_size = input_size\n","        \n","        self._chart: list[list[set[CKYChartEntry]]] = [\n","            [set({})\n","             for _ in range(input_size+1)]\n","            for _ in range(input_size+1)\n","        ]\n","        \n","    def __getitem__(self, index: SpanIndices) -> set[CKYChartEntry]:\n","        i, j = index\n","\n","        self._validate_index(i, j)\n","        \n","        return self._chart[i][j]\n","\n","    def __setitem__(self, key: SpanIndices, item: set[CKYChartEntry]):\n","        i, j = key\n","\n","        self._chart[i][j] = item\n","        \n","    def _validate_index(self, i, j):\n","        try:\n","            assert i < j\n","        except AssertionError:\n","            msg = \"cannot index into the lower \" +\\\n","                  \"triangle of the chart\"\n","            raise ValueError(msg)\n","\n","        try:\n","            self._chart[i]\n","        except IndexError:\n","            msg = \"row index is too large\"\n","            raise ValueError(msg)\n","\n","        try:\n","            self._chart[i][j]\n","        except IndexError:\n","            msg = \"column index is too large\"\n","            raise ValueError(msg)\n","\n","    @property\n","    def parses(self) -> set[Tree]:\n","        try:\n","            return self._parses\n","        except AttributeError:\n","            self._parses = self._construct_parses()\n","            return self._parses\n","\n","    def _construct_parses(self, entry: Union['CKYChartEntry', None] = None) -> set[Tree]:\n","        \"\"\"Construct the parses implied by the chart\n","\n","        Parameters\n","        ----------\n","        entry\n","        \"\"\"\n","        raise NotImplementedError\n","    \n","class ContextFreeGrammarParser(ABC):\n","    \n","    def __init__(self, grammar: ContextFreeGrammar):\n","        self._grammar = grammar\n","\n","    def __call__(self, string, mode=\"recognize\"):\n","        if mode == \"recognize\":\n","            return self._recognize(string)\n","        elif mode == \"parse\":\n","            return self._parse(string)            \n","        else:\n","            msg = 'mode must be \"parse\" or \"recognize\"'\n","            raise ValueError(msg)\n","\n","class CKYParser(ContextFreeGrammarParser):\n","    \"\"\"\n","    A CKY parser\n","\n","    Parameters\n","    ----------\n","    grammar : ContextFreeGrammar\n","    \"\"\"\n","    \n","    normal_form = NormalForm.CNF\n","    \n","    def _fill_chart(self, string: list[str]) -> CKYChart:\n","        raise NotImplementedError\n","\n","    def _parse(self, string):\n","        chart = self._fill_chart(string)\n","        return chart.parses\n","        \n","    def _recognize(self, string):\n","        chart = self._fill_chart(string)\n","        \n","        return any([self._grammar.start_variable == entry.symbol\n","                    for entry in chart[0,len(string)]])\n","        "]},{"cell_type":"markdown","id":"_YjHra6z8pG5","metadata":{"id":"_YjHra6z8pG5"},"source":["## Task 2\n","\n","Implement the `CKYParser._fill_chart` and `CKYChart._construct_parses` methods."]},{"cell_type":"code","execution_count":null,"id":"5nNEYEP18pG5","metadata":{"id":"5nNEYEP18pG5"},"outputs":[],"source":["class CKYParser(CKYParser):\n","    \n","    def _fill_chart(self, string: list[str]) -> CKYChart:\n","        raise NotImplementedError \n","    \n","class CKYChart(CKYChart):\n","    \n","    def _construct_parses(self, entry: CKYChartEntry | None = None) -> set[Tree]:\n","        raise NotImplementedError"]},{"cell_type":"markdown","id":"Q-9CLKXy8pG5","metadata":{"id":"Q-9CLKXy8pG5"},"source":["Test your implementation by ensuring that the following call yields the correct number of `Tree`s. (We are not using the grammar you extracted from the treebank because we want to a relatively minimal example to test against. The grammar you extracted will be relevant for Task 4 below.)"]},{"cell_type":"code","execution_count":null,"id":"WvXTtzfT8pG5","metadata":{"id":"WvXTtzfT8pG5"},"outputs":[],"source":["ContextFreeGrammar.parser_class = CKYParser\n","\n","grammar = ContextFreeGrammar(alphabet={'the', 'greyhound', 'ate', 'the', 'salmon',\n","                                       'with', 'a', 'fork', 'again', 'quickly'},\n","                             variables={'S', 'NP', 'VP', 'PP', 'D', 'N', 'V', 'P', 'Adv'},\n","                             rules={Rule('S', 'NP', 'VP'),\n","                                    Rule('NP', 'D', 'N'),\n","                                    Rule('NP', 'NP', 'PP'),\n","                                    Rule('VP', 'V', 'NP'),\n","                                    Rule('VP', 'VP', 'PP'),\n","                                    Rule('VP', 'Adv', 'VP'),\n","                                    Rule('VP', 'VP', 'Adv'),\n","                                    Rule('PP', 'P', 'NP'),\n","                                    Rule('D', 'the'),\n","                                    Rule('D', 'a'),\n","                                    Rule('N', 'greyhound'),\n","                                    Rule('N', 'salmon'),\n","                                    Rule('N', 'fork'),\n","                                    Rule('V', 'fork'),\n","                                    Rule('V', 'ate'),\n","                                    Rule('P', 'with'),\n","                                    Rule('Adv', 'again'),\n","                                    Rule('Adv', 'quickly')},\n","                             start_variable='S')\n","\n","grammar(['the', 'greyhound', 'again', 'ate', 'the',\n","         'salmon', 'with', 'a', 'fork', 'quickly'], mode=\"parse\")"]},{"cell_type":"markdown","id":"7nPhvz3v8pG5","metadata":{"id":"7nPhvz3v8pG5"},"source":["## Dotted Rules\n","\n","To implement Earley parsing, we need to augment our vanilla CFG rule from above to a dotted CFG rule, which tracks which constituents we may have seen up to a particular position in a sentence. This dotted rule needs to track not only the position of the dot in the rule (what kinds of consistuents might have been seen so far), but also which substring the dotted rule is associated with."]},{"cell_type":"code","execution_count":null,"id":"y-hn8x8n8pG6","metadata":{"id":"y-hn8x8n8pG6"},"outputs":[],"source":["class DottedRule(Rule):\n","    \n","    def __init__(self, rule: Rule, span: SpanIndices, dot: int = 0):\n","        self._rule = rule\n","        self._left_side = rule.left_side\n","        self._right_side = rule.right_side\n","        \n","        self._span = span\n","        self._dot = dot\n","    \n","    def to_tuple(self) -> tuple[Rule, SpanIndices, int]:\n","        return self._rule, self._span, self._dot\n","    \n","    def __hash__(self) -> int:\n","        return hash(self.to_tuple())\n","    \n","    def __eq__(self, other) -> bool:\n","        return self.to_tuple() == other.to_tuple()\n","    \n","    def __repr__(self) -> str:\n","        return self._left_side + ' -> ' +\\\n","               ' '.join(self._right_side[:self._dot]) +\\\n","               ' . ' +\\\n","               ' '.join(self._right_side[self._dot:]) +\\\n","               ' [' + str(self._span[0]) + ', ' + str(self._span[1]) + ']'\n","    \n","    def complete(self, new_left_edge: int) -> tuple['DottedRule', int]:\n","        \"\"\"Complete the next symbol in this rule\n","        \n","        Parameters\n","        ----------\n","        new_left_edge\n","\n","        Returns\n","        -------\n","        new_dotted_rule\n","        completed_symbol\n","        old_left_edge\n","        \"\"\"\n","        dot = self._dot + 1\n","        span = (self._span[0], new_left_edge)\n","\n","        return DottedRule(self._rule, span, dot)\n","\n","    @property\n","    def next_symbol(self) -> str:\n","        if self.is_complete:\n","            raise AttributeError('dotted rule is already complete')\n","        else:\n","            return self._right_side[self._dot]\n","        \n","    @property\n","    def dot(self) -> int:\n","        return self._dot\n","    \n","    @property\n","    def span(self) -> SpanIndices:\n","        return self._span\n","    \n","    @property\n","    def is_complete(self) -> bool:\n","        return self._dot == len(self._right_side)\n","    \n","    @property\n","    def left_side(self) -> str:\n","        return self._rule.left_side"]},{"cell_type":"markdown","id":"y2PpsZBX8pG6","metadata":{"id":"y2PpsZBX8pG6"},"source":["To initialize a dotted CFG rule, we pass a vanilla CFG rule along with a tuple of indices representing the span that rule has recognized. If it has recognized nothing, the left index will be equal to the right index. We don't need to pass the dot position because we assume that, on initialization, the dot is before the first right side symbol."]},{"cell_type":"code","execution_count":null,"id":"7-xY1nA-8pG6","metadata":{"id":"7-xY1nA-8pG6"},"outputs":[],"source":["dotted_rule = DottedRule(Rule('S', 'NP', 'VP'), (0, 0))\n","\n","dotted_rule"]},{"cell_type":"markdown","id":"Swit-EGT8pG6","metadata":{"id":"Swit-EGT8pG6"},"source":["We can increment the dot by calling `DottedRule.complete` with the new right edge of the span."]},{"cell_type":"code","execution_count":null,"id":"EDnsBuhj8pG6","metadata":{"id":"EDnsBuhj8pG6"},"outputs":[],"source":["dotted_rule.complete(2)"]},{"cell_type":"markdown","id":"xBCWhddt8pG6","metadata":{"id":"xBCWhddt8pG6"},"source":["This procedure creates an entirely new object."]},{"cell_type":"code","execution_count":null,"id":"vmHnH4dD8pG6","metadata":{"id":"vmHnH4dD8pG6"},"outputs":[],"source":["id(dotted_rule), id(dotted_rule.complete(2))"]},{"cell_type":"markdown","id":"8Mr2qojL8pG6","metadata":{"id":"8Mr2qojL8pG6"},"source":["Calling `DottedRule.complete` twice will increment the dot twice."]},{"cell_type":"code","execution_count":null,"id":"EKE4wgxj8pG6","metadata":{"id":"EKE4wgxj8pG6"},"outputs":[],"source":["dotted_rule.complete(2).complete(10)"]},{"cell_type":"markdown","id":"5fML1RCJ8pG6","metadata":{"id":"5fML1RCJ8pG6"},"source":["Finally, dotted rules are hashable and behave how you would expect when hashed."]},{"cell_type":"code","execution_count":null,"id":"GDL_2hUg8pG7","metadata":{"id":"GDL_2hUg8pG7"},"outputs":[],"source":["{dotted_rule, DottedRule(Rule('S', 'NP', 'VP'), (0, 0))}"]},{"cell_type":"markdown","id":"6RscvJ_q8pG7","metadata":{"id":"6RscvJ_q8pG7"},"source":["## Earley Parsing\n","\n","We will implement Earley parsing and recognition using a similar system of classes to the ones we developed for CKY: `EarleyChart`s contain `EarleyChartEntry`s and are filled with those entries by a `EarleyParser`, which is a kind of `ContextFreeGrammarParser`."]},{"cell_type":"code","execution_count":null,"id":"6P3I7kuF8pG7","metadata":{"id":"6P3I7kuF8pG7"},"outputs":[],"source":["EarleyBackPointer = tuple[str, int]\n","\n","class EarleyChartEntry(ChartEntry):\n","    \"\"\"A chart entry for a Earley chart\n","\n","    Parameters\n","    ----------\n","    dotted_rule\n","    backpointers\n","    \"\"\"\n","\n","    def __init__(self, dotted_rule: DottedRule, *backpointers: EarleyBackPointer):\n","        self._dotted_rule = dotted_rule\n","        self._backpointers = backpointers\n","\n","    def to_tuple(self) -> tuple[DottedRule, tuple[EarleyBackPointer, ...]]:\n","        return self._dotted_rule, self._backpointers\n","        \n","    def __hash__(self) -> int:\n","        return hash(self.to_tuple())\n","\n","    def __eq__(self, other) -> bool:\n","        return self.to_tuple() == other.__key()\n","    \n","    def __repr__(self) -> str:\n","        return self._dotted_rule.__repr__()\n","\n","    def __str__(self) -> str:\n","        return self.__repr__()\n","\n","    @property\n","    def backpointers(self) -> tuple[EarleyBackPointer, ...]:\n","        return self._backpointers\n","    \n","    @property\n","    def dotted_rule(self):\n","        return self._dotted_rule\n","    \n","    @property\n","    def next_symbol(self) -> str:\n","        return self._dotted_rule.next_symbol\n","    \n","    @property\n","    def span(self) -> tuple[int]:\n","        return self._dotted_rule.span\n","    \n","    @property\n","    def is_complete(self):\n","        return self._dotted_rule.is_complete\n","    \n","    def complete(self, entry: 'EarleyChartEntry', new_left_edge: int) -> 'EarleyChartEntry':\n","        new_dotted_rule = self._dotted_rule.complete(new_left_edge)\n","        \n","        bp = (self._dotted_rule.next_symbol, self._dotted_rule.span[1])\n","        backpointers = self._backpointers + (bp,)\n","        \n","        return EarleyChartEntry(new_dotted_rule, backpointers)\n","    \n","    def is_completion_of(self, other: 'EarleyChartEntry') -> bool:\n","        return self._dotted_rule.left_side == other.dotted_rule.next_symbol\n","\n","class EarleyChart(Chart):\n","    \"\"\"A chart for an Earley parser\n","\n","    Parameters\n","    ----------\n","    input_size\n","    \"\"\"\n","    def __init__(self, input_size: int, start_variable: str = 'S'):\n","        self._start_variable = start_variable\n","        \n","        self._chart: list[set[EarleyChartEntry]] = [\n","            set() for _ in range(input_size+1)\n","        ]\n","        \n","    def __getitem__(self, index) -> set[EarleyChartEntry]:\n","        return self._chart[index]\n","\n","    def __setitem__(self, key, item) -> None:\n","        self._chart[key] = item\n","\n","    @property\n","    def parses(self) -> set[Tree]:\n","        try:\n","            return self._parses\n","        except AttributeError:\n","            self._parses = set()\n","            \n","            for entry in self._chart[-1]:\n","                is_start = entry.dotted_rule.left_side == self._start_variable\n","                covers_string = entry.dotted_rule.span == (0, self.input_size)\n","                \n","                if is_start and covers_string:\n","                    self._parses.add(self._construct_parses(entry))\n","            \n","            return self._parses\n","\n","    def _construct_parses(self, entry: 'EarleyChartEntry') -> Tree:\n","        \"\"\"Construct the parses implied by the chart\n","\n","        Parameters\n","        ----------\n","        entry\n","        \"\"\"\n","        raise NotImplementedError     \n","    \n","    @property\n","    def input_size(self) -> int:\n","        return len(self._chart) - 1\n","    \n","class EarleyParser(ContextFreeGrammarParser):\n","    \"\"\"\n","    An Earley parser\n","\n","    Parameters\n","    ----------\n","    grammar : ContextFreeGrammar\n","    \"\"\"\n","    normal_form = None\n","    \n","    def _fill_chart(self, string: list[str]) -> EarleyChart:\n","        \"\"\"\n","        a chart for the string based on a CFG\n","\n","        Parameters\n","        ----------\n","        string\n","        \"\"\"\n","        raise NotImplementedError\n","                    \n","    def _predict(self, chart: EarleyChart, entry: EarleyChartEntry, position: int):\n","        for rule in self._grammar.rules(entry.next_symbol):\n","            span = (position, position)\n","            dotted_rule = DottedRule(rule, span)\n","            entry = EarleyChartEntry(dotted_rule)\n","\n","            chart[position].add(entry)\n","     \n","    def _scan(self, chart: EarleyChart, entry: EarleyChartEntry, position: int):\n","        word = self._string[position]\n","        pos_for_word = self._grammar.parts_of_speech(word)\n","        \n","        if entry.next_symbol in pos_for_word:\n","            rule = Rule(entry.next_symbol, word)\n","            span = (position, position+1)\n","            dotted_rule = DottedRule(rule, span, dot=1)\n","            \n","            unary_entry = EarleyChartEntry(dotted_rule)\n","            \n","            chart[position+1].add(unary_entry)\n","        \n","    def _complete(self, chart: EarleyChart, entry: EarleyChartEntry, position: int):\n","        start, end = entry.span\n","        \n","        for prev_entry in chart[start]:\n","            if not prev_entry.is_complete and entry.is_completion_of(prev_entry):\n","                completed_entry = prev_entry.complete(entry, end)\n","                \n","                chart[position].add(completed_entry)\n","        \n","    def _parse(self, string: str | list[str]):\n","        chart = self._fill_chart(string)\n","        return chart.parses\n","\n","    def _recognize(self, string: str | list[str]):\n","        chart = self._fill_chart(string)\n","        \n","        for entry in chart[-1]:\n","            is_start = entry.dotted_rule.left_side == self._grammar.start_variable\n","            covers_string = entry.dotted_rule.span == (0, chart.input_size)\n","            \n","            if is_start and covers_string:\n","                return True\n","            \n","        else:\n","            return False\n","        \n","ContextFreeGrammar.parser_class = EarleyParser"]},{"cell_type":"markdown","id":"5mZKvTOl8pG7","metadata":{"id":"5mZKvTOl8pG7"},"source":["## Task 3\n","\n","Implement the `EarleyParser._fill_chart` and `EarleyChart._construct_parses` method. Note that `EarleyChart._construct_parses` works slightly differently than `CKYChart._construct_parses` in only producing a single `Tree`. The parses attributes collects all `Tree`s implied by a chart into a set."]},{"cell_type":"code","execution_count":null,"id":"dMGolJKA8pG7","metadata":{"id":"dMGolJKA8pG7"},"outputs":[],"source":["class EarleyParser(EarleyParser):\n","    \n","    def _fill_chart(self, string: list[str]) -> EarleyChart:\n","        \"\"\"\n","        a chart for the string based on a CFG\n","\n","        Parameters\n","        ----------\n","        string\n","        \"\"\"\n","        raise NotImplementedError\n","    \n","class EarleyChart(EarleyChart):\n","    \n","    def _construct_parses(self, entry: 'EarleyChartEntry') -> Tree:\n","        \"\"\"Construct the parses implied by the chart\n","\n","        Parameters\n","        ----------\n","        entry\n","        \"\"\"\n","        raise NotImplementedError"]},{"cell_type":"markdown","id":"Wob7TmvM8pG7","metadata":{"id":"Wob7TmvM8pG7"},"source":["Test your implementation using the same grammar and sentence we used to test the CKY implementation."]},{"cell_type":"code","execution_count":null,"id":"pfiUSI7p8pG8","metadata":{"id":"pfiUSI7p8pG8"},"outputs":[],"source":["ContextFreeGrammar.parser_class = EarleyParser\n","\n","grammar = ContextFreeGrammar(alphabet={'the', 'greyhound', 'ate', 'the', 'salmon',\n","                                       'with', 'a', 'fork', 'again', 'quickly'},\n","                             variables={'S', 'NP', 'VP', 'PP', 'D', 'N', 'V', 'P', 'Adv'},\n","                             rules={Rule('S', 'NP', 'VP'),\n","                                    Rule('NP', 'D', 'N'),\n","                                    Rule('NP', 'NP', 'PP'),\n","                                    Rule('VP', 'V', 'NP'),\n","                                    Rule('VP', 'VP', 'PP'),\n","                                    Rule('VP', 'Adv', 'VP'),\n","                                    Rule('VP', 'VP', 'Adv'),\n","                                    Rule('PP', 'P', 'NP'),\n","                                    Rule('D', 'the'),\n","                                    Rule('D', 'a'),\n","                                    Rule('N', 'greyhound'),\n","                                    Rule('N', 'salmon'),\n","                                    Rule('N', 'fork'),\n","                                    Rule('V', 'fork'),\n","                                    Rule('V', 'ate'),\n","                                    Rule('P', 'with'),\n","                                    Rule('Adv', 'again'),\n","                                    Rule('Adv', 'quickly')},\n","                             start_variable='S')\n","\n","grammar(['the', 'greyhound', 'again', 'ate', 'the',\n","         'salmon', 'with', 'a', 'fork', 'quickly'], mode=\"parse\")"]},{"cell_type":"markdown","id":"wQhTtQlr8pG8","metadata":{"id":"wQhTtQlr8pG8"},"source":["## Task 4\n","\n","Implement an instance method `EarleyParser._predict_next_word` that is used when `EarleyParser` is called in `\"predict\"` mode. This method should take in a tokenized string—the _prefix_ —and output a dictionary mapping from parts-of-speech that could come after the prefix to words that could come after the prefix."]},{"cell_type":"code","execution_count":null,"id":"G-g677b78pG8","metadata":{"id":"G-g677b78pG8"},"outputs":[],"source":["from typing import Dict\n","from collections import defaultdict\n","\n","class EarleyParser(EarleyParser):\n","    \n","    def __call__(self, string, mode=\"recognize\"):\n","        if mode == \"recognize\":\n","            return self._recognize(string)\n","        elif mode == \"parse\":\n","            return self._parse(string)  \n","        elif mode == \"predict\":\n","            return self._predict_next_word(string)  \n","        else:\n","            msg = 'mode must be \"parse\", \"recognize\", or \"predict\"'\n","            raise ValueError(msg)\n","    \n","    def _predict_next_word(self, prefix: list[str]) -> Dict[str, set[str]]:\n","        raise NotImplementedError\n","\n","ContextFreeGrammar.parser_class = EarleyParser"]},{"cell_type":"markdown","id":"bDu2_F1W8pG8","metadata":{"id":"bDu2_F1W8pG8"},"source":["Test your prediction method against the grammar we used in class."]},{"cell_type":"code","execution_count":null,"id":"GFHYowVi8pG8","metadata":{"id":"GFHYowVi8pG8"},"outputs":[],"source":["grammar = ContextFreeGrammar(alphabet={'the', 'greyhound', 'ate', 'the', 'salmon',\n","                                       'with', 'a', 'fork', 'again', 'too'},\n","                             variables={'S', 'NP', 'VP', 'PP', 'D', 'N', 'V', 'P', 'Adv'},\n","                             rules={Rule('S', 'NP', 'VP'),\n","                                    Rule('NP', 'D', 'N'),\n","                                    Rule('NP', 'NP', 'PP'),\n","                                    Rule('VP', 'V', 'NP'),\n","                                    Rule('VP', 'VP', 'PP'),\n","                                    Rule('VP', 'Adv', 'VP'),\n","                                    Rule('VP', 'VP', 'Adv'),\n","                                    Rule('PP', 'P', 'NP'),\n","                                    Rule('D', 'the'),\n","                                    Rule('D', 'a'),\n","                                    Rule('N', 'greyhound'),\n","                                    Rule('N', 'salmon'),\n","                                    Rule('N', 'fork'),                                        \n","                                    Rule('V', 'ate'),\n","                                    Rule('VP', 'ate'),\n","                                    Rule('P', 'with'),\n","                                    Rule('Adv', 'again'),\n","                                    Rule('Adv', 'too')},\n","                             start_variable='S')"]},{"cell_type":"markdown","id":"FouH2lPV8pG8","metadata":{"id":"FouH2lPV8pG8"},"source":["For instance, with the prefix _the greyhound_, you should get the following dictionary:\n","\n","```\n","{'Adv': {'again', 'too'},\n"," 'VP': {'ate'},\n"," 'P': {'with'},\n"," 'V': {'ate'}}\n","```"]},{"cell_type":"code","execution_count":null,"id":"hQT7FUA58pG8","metadata":{"id":"hQT7FUA58pG8"},"outputs":[],"source":["# write tests here"]},{"cell_type":"markdown","id":"x-fE75O08pG8","metadata":{"id":"x-fE75O08pG8"},"source":["## Task 5\n","\n","Randomly sample sentences from EWT and compute the predicted words given the first one, two, and three words in that sentence. For each such set of predictions for each sentence count the total number of parts-of-speech and the total number of words that could follow that prefix."]},{"cell_type":"code","execution_count":null,"id":"zJDllzZ38pG8","metadata":{"id":"zJDllzZ38pG8"},"outputs":[],"source":["grammar = ContextFreeGrammar.from_treebank(EnglishWebTreebank())\n","\n","# sample and predict here"]},{"cell_type":"markdown","id":"w3upx5FP8pG8","metadata":{"id":"w3upx5FP8pG8"},"source":["You'll see a general pattern in the numbers, but if you dig down into exactly what the next word predictions are, they will look at. What gives rise to this oddness?"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.10"}},"nbformat":4,"nbformat_minor":5}
