{"cells":[{"cell_type":"markdown","metadata":{"id":"XRrZkwYuB_lW"},"source":["# Assignments 7 and 8\n","\n","*Assignment 7 will consist of Tasks 1-3 and Assignment 8 will consist of Tasks 4-5.*\n","\n","In these assignments, you will be implementing finite state automata for generating/recognizing/parsing English syllables and words (Assignment 7) as well as finite state transducers for recognizing/parsing/transducing English sentences (Assigment 8). You will implement these using the `FiniteStateAutomaton` class that we developed in class as well as a `FiniteStateTransducer` class that builds on it.\n","\n","## Finite State Automata\n","\n","The first set of utilities are used for determinization and epsilon closure."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Zck-pnrB_lZ"},"outputs":[],"source":["from functools import reduce\n","from itertools import chain, combinations\n","\n","from typing import Set, Tuple\n","\n","def powerset(iterable):\n","    \"\"\"https://docs.python.org/3/library/itertools.html#recipes\"\"\"\n","    s = list(iterable)\n","    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n","\n","def transitive_closure(edges: set[Tuple[str]]) -> set[Tuple[str]]:\n","    \"\"\"\n","    the transitive closure of a graph\n","\n","    Parameters\n","    ----------\n","    edges\n","        the graph to compute the closure of\n","\n","    Returns\n","    ----------\n","    set(tuple)\n","    \"\"\"\n","    while True:\n","        new_edges = {(x, w)\n","                     for x, y in edges\n","                     for q, w in edges\n","                     if q == y}\n","\n","        all_edges = edges | new_edges\n","\n","        if all_edges == edges:\n","            return edges\n","\n","        edges = all_edges"]},{"cell_type":"markdown","metadata":{"id":"ajKQ8RLGB_la"},"source":["`transitive_closure` in particular is useful in computing the epsilon closure (though epsilon closure requires quite a bit more code, as you can see below)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZJlO37q3B_la"},"outputs":[],"source":["transitive_closure({(0, 1), (1, 2), (2, 3), (3, 4)})"]},{"cell_type":"markdown","metadata":{"id":"ONJPc04iB_la"},"source":["And here's the base `FiniteStateAutomaton` class, which relies on a `TransitionFunction` class to hide some of the operations on transition functions that can get nasty."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RI41lBVzB_la"},"outputs":[],"source":["from logging import warn\n","from copy import copy, deepcopy\n","from functools import lru_cache\n","from typing import Literal\n","\n","TransitionGraph = dict[tuple[str, str], str | set[str]]\n","FSAParse = tuple[tuple[str, str]]\n","FSAMode = Literal[\"recognize\", \"parse\"]\n","\n","class FiniteStateAutomaton:\n","    \"\"\"A finite state automaton\n","\n","    Parameters\n","    ----------\n","    alphabet\n","    states\n","    initial_state\n","    final states\n","    transition_graph\n","    \"\"\"\n","\n","    def __init__(self, alphabet: set[str], states: set[str], \n","                 initial_state: str, final_states: set[str], \n","                 transition_graph: TransitionGraph):\n","        self._alphabet = alphabet | {''}\n","        self._states = states\n","        self._initial_state = initial_state\n","        self._final_states = final_states\n","        self._transition_function = TransitionFunction(\n","            self._alphabet, \n","            states,\n","            transition_graph\n","        )\n","\n","        self._validate_initial_state()\n","        self._validate_final_states()\n","\n","        self._generator = self._build_generator()\n","\n","    def __contains__(self, string):\n","        return self._recognize(string)\n","        \n","    def __add__(self, other):\n","        return self.concatenate(other)\n","\n","    def __or__(self, other):\n","        return self.union(other)\n","\n","    def __and__(self, other):\n","        return self.intersect(other)\n","\n","    def __pow__(self, k):\n","        return self.exponentiate(k)\n","\n","    def __neg__(self):\n","        return self.complement()\n","\n","    def __iter__(self):\n","        return self\n","\n","    def __next__(self):\n","        return next(self._generator)\n","\n","    def _build_generator(self):\n","        string_buffer = [(self._initial_state, '')]\n","        \n","        if self._initial_state in self._final_states:\n","            stack = ['']\n","        else:\n","            stack = []\n","\n","        while string_buffer:\n","            if stack:\n","                yield stack.pop()\n","\n","            else:\n","                # this is very inefficient when we have total\n","                # transition functions with many transitions to the\n","                # sink state; could be optimized by removing a string\n","                # if it's looping in a sink state, but we don't know\n","                # in general what the sink state is\n","                new_buffer = []\n","                for symb in self._alphabet:\n","                    for old_state, string in string_buffer:\n","                        new_states = self._transition_function(old_state, symb)\n","                        for st in new_states:\n","                            new_elem = (st, string+symb)\n","                            new_buffer.append(new_elem)\n","\n","                stack += [string\n","                          for state, string in new_buffer\n","                          if state in self._final_states]\n","\n","                string_buffer = new_buffer\n","    \n","    def __call__(self, string: str | list[str], mode: FSAMode = \"recognize\") -> bool | set[FSAParse]:\n","        \"\"\"\n","        whether/how a string is accepted/parsed by the FSA\n","\n","        Parameters\n","        ----------\n","        string\n","            the string to recognize or parse\n","        mode\n","            whether to run in \"recognize\" or \"parse\" mode\n","        \"\"\"\n","\n","        if mode == 'recognize':\n","            return self._recognize(string)\n","        elif mode == 'parse':\n","            return self._parse(string)\n","        else:\n","            msg = 'mode must be \"recognize\" or \"parse\"'\n","            raise ValueError(msg)\n","\n","    def _add_epsilon_extensions(self, paths: set[tuple[str]]) -> set[tuple[str]]:\n","        paths_extended = {\n","            (s1, s2) \n","            for s1 in paths \n","            for s2 in self._transition_function(s1[-1], '')\n","        }\n","        \n","        break_counter = 0\n","\n","        while not paths >= paths_extended:\n","            paths |= paths_extended\n","            paths_extended = {\n","                s1 + (s2,) \n","                for s1 in paths\n","                for s2 in self._transition_function(s1[-1], '')\n","            }\n","\n","            break_counter += 1\n","\n","            if break_counter > 10:\n","                warn(\"epsilon path limit reached\")\n","                break\n","            \n","        return paths\n","\n","    @lru_cache(512)\n","    def _recognize(self, string: str | list[str], prev_state: str | None = None) -> bool:\n","        \"\"\"Whether a string is accepted by the FSA\n","\n","        Parameters\n","        ----------\n","        string\n","            the string to recognize or parse\n","        \"\"\"\n","        paths = {(self._initial_state,)} if prev_state is None else {(prev_state,)}\n","        paths = self._add_epsilon_extensions(paths)\n","\n","        if string:\n","            return any(\n","                self._recognize(string[1:], state)\n","                for p in paths\n","                for state in self._transition_function(p[-1], string[0])\n","            )\n","\n","        else:\n","            return any(\n","                s[-1] in self._final_states for s in paths\n","            )\n","\n","    @lru_cache(512)\n","    def _parse(self, string: str | list[str], \n","               prev_state: str | None = None) -> set[FSAParse]:\n","        \"\"\"How a string is parsed by the FSA\n","        \n","        This should return the list of transitions that \n","        the machine could go through to parse a string\n","\n","        Parameters\n","        ----------\n","        string\n","            the string to recognize or parse\n","        \"\"\"\n","        paths = {(self._initial_state,)} if prev_state is None else {(prev_state,)}\n","        paths = self._add_epsilon_extensions(paths)\n","\n","        if string:\n","            return {\n","                tuple((s,'') for s in p[1:]) + ((state, string[0]),) + parse\n","                for p in paths\n","                for state in self._transition_function(p[-1], string[0])\n","                for parse in self._parse(string[1:], state)\n","            }\n","\n","        else:\n","            return {\n","                tuple((s,'') for s in p[1:])\n","                for p in paths\n","                if p[-1] in self._final_states\n","            }\n","\n","    def _validate_initial_state(self):\n","        try:\n","            assert self._initial_state in self._states\n","\n","        except AssertionError:\n","            raise ValueError('initial state must be in set of states')\n","\n","    def _validate_final_states(self):\n","        try:\n","            assert all([s in self._states for s in self._final_states])\n","\n","        except AssertionError:\n","            raise ValueError('final states must all be in set of states')\n","\n","    def _deepcopy(self):\n","        fsa = copy(self)\n","        del fsa._generator\n","\n","        return deepcopy(fsa)\n","        \n","    def _relabel_fsas(self, other):\n","        \"\"\"\n","        append tag to the input/ouput states throughout two FSAs\n","\n","        Parameters\n","        ----------\n","        other : FiniteStateAutomaton\n","        \"\"\"\n","\n","        fsa1 = self._deepcopy()._relabel_states(str(id(self)))\n","        fsa2 = other._deepcopy()._relabel_states(str(id(other)))\n","\n","        return fsa1, fsa2\n","\n","    def _relabel_states(self, tag: str) -> 'FiniteStateAutomaton':\n","        \"\"\"\n","        append tag to the input/ouput states throughout the FSA\n","\n","        Parameters\n","        ----------\n","        tag : str\n","        \"\"\"\n","\n","        state_map = {s: s+'_'+tag for s in self._states}\n","        \n","        self._states = {state_map[s] for s in self._states}    \n","        self._initial_state += '_'+tag\n","        self._final_states = {state_map[s] for s in self._final_states}\n","\n","        self._transition_function.relabel_states(state_map)\n","        \n","        return self\n","\n","    def concatenate(self, other: 'FiniteStateAutomaton'):\n","        \"\"\"\n","        concatenate this FSA with another\n","\n","        Parameters\n","        ----------\n","        other : FiniteStateAutomaton\n","\n","        Returns\n","        -------\n","        FiniteStateAutomaton\n","        \"\"\"\n","        msg = \"you still need to implement FiniteStateAutomaton.concatenate\"\n","        raise NotImplementedError(msg)\n","\n","    def kleene_star(self)  -> 'FiniteStateAutomaton':\n","        \"\"\"\n","        construct the kleene closure machine\n","\n","        Returns\n","        -------\n","        FiniteStateAutomaton\n","        \"\"\"\n","        fsa = self._deepcopy()\n","        \n","        new_transition = fsa._transition_function\n","        new_transition.add_transitions({(s, ''): fsa._initial_state\n","                                        for s in fsa._final_states})\n","\n","        return FiniteStateAutomaton(fsa._alphabet, fsa._states,\n","                                    fsa._initial_state, fsa._final_states,\n","                                    new_transition.transition_graph)\n","\n","    def exponentiate(self, k: int) -> 'FiniteStateAutomaton':\n","        \"\"\"\n","        concatenate this FSA k times\n","\n","        Parameters\n","        ----------\n","        k : int\n","            the number of times to repeat; must be >1\n","\n","        Returns\n","        -------\n","        FiniteStateAutomaton\n","        \"\"\"\n","        if k <= 1:\n","            raise ValueError(\"must be >1\")\n","\n","        new = self\n","\n","        for i in range(1,k):\n","            new += self\n","\n","        return new\n","\n","    def union(self, other: 'FiniteStateAutomaton') -> 'FiniteStateAutomaton':\n","        \"\"\"\n","        union this FSA with another\n","\n","        Parameters\n","        ----------\n","        other : FiniteStateAutomaton\n","\n","        Returns\n","        -------\n","        FiniteStateAutomaton\n","        \"\"\"\n","        msg = \"you still need to implement FiniteStateAutomaton.union\"\n","        raise NotImplementedError(msg)\n","\n","    def complement(self) -> 'FiniteStateAutomaton':\n","        \"\"\"\n","        complement this FSA\n","\n","        Returns\n","        -------\n","        FiniteStateAutomaton\n","        \"\"\"\n","        fsa = self._deepcopy()\n","        fsa = fsa.determinize()\n","        fsa._transition_function.totalize()\n","        fsa._final_states = fsa._states - fsa._final_states\n","\n","        return fsa\n","\n","    def intersect(self, other: 'FiniteStateAutomaton') -> 'FiniteStateAutomaton':\n","        \"\"\"\n","        intersect this FSA with another\n","\n","        Parameters\n","        ----------\n","        other : FiniteStateAutomaton\n","\n","        Returns\n","        -------\n","        FiniteStateAutomaton\n","        \"\"\"\n","        fsa1 = self.complement()\n","        fsa2 = other.complement()\n","\n","        return fsa1.union(fsa2).complement()\n","        \n","    def determinize(self) -> 'FiniteStateAutomaton':\n","        \"\"\"\n","        if nondeterministic, determinize the FSA\n","\n","        Returns\n","        -------\n","        FiniteStateAutomaton\n","        \"\"\"\n","        new_states, new_initial_state, new_transition_graph = self._transition_function.determinize(self._initial_state)\n","\n","        new_states = {'_'.join(sorted(s)) for s in new_states}\n","        new_initial_state = \"_\".join(sorted(new_initial_state))\n","        new_final_states = {\n","            '_'.join(sorted(s)) for s in powerset(self._states)\n","            if any([t in s for t in self._final_states])\n","            if s\n","        }\n","        new_transition_graph = {\n","            (\"_\".join(sorted(instates)), symb): {\"_\".join(sorted(o)) for o in outstates}\n","            for (instates, symb), outstates in new_transition_graph.items()\n","        }\n","\n","        return FiniteStateAutomaton(\n","            self._alphabet-{''}, \n","            new_states,\n","            new_initial_state, \n","            new_final_states,\n","            new_transition_graph\n","        )\n","\n","    @property\n","    def isdeterministic(self) -> bool:\n","        return self._transition_function.isdeterministic\n","\n","class TransitionFunction(object):\n","    \"\"\"\n","    A finite state machine transition function\n","\n","    Parameters\n","    ----------\n","    transition_graph\n","\n","    Attributes\n","    ----------\n","    isdeterministic : bool\n","    istotalfunction : bool\n","    transition_graph : dict\n","\n","    Methods\n","    -------\n","    validate(alphabet, states)\n","    relable_states(state_map)\n","    totalize()\n","    \"\"\"\n","\n","    def __init__(self, alphabet: set[str], states: set[str], transition_graph: TransitionGraph):\n","        self._alphabet = alphabet\n","        self._states = states\n","        self._transition_graph = transition_graph\n","\n","        self._validate()\n","\n","    def __call__(self, state: str, symbol: str) -> set[str]:\n","        try:\n","            return self._transition_graph[(state, symbol)]\n","        except KeyError:\n","            return set({})\n","\n","    def __or__(self, other: 'TransitionFunction') -> 'TransitionFunction':\n","        return TransitionFunction(\n","            dict(\n","                self._transition_graph, \n","                **other._transition_graph\n","            )\n","        )\n","\n","    def _add_epsilon_transitive_closure(self):\n","        # get the state graph of all epsilon transitions\n","        transitions = {\n","            (instate, outstate)\n","            for (instate, insymb), outs in self._transition_graph.items()\n","            for outstate in outs if not insymb\n","        }\n","        \n","        # compute the transitive closure of the epsilon transition\n","        # state graph; requires homogenization beforehand\n","        for instate, outstate in transitive_closure(transitions):\n","            self._transition_graph[(instate, '')] |= {outstate}\n","\n","        new_graph = dict(self._transition_graph)\n","\n","        # add alphabet transitions from all states q_i that exit\n","        # with an alphabet transition (q_i, a) and enter states q_j\n","        # with epsilon transitions to states q_k\n","        for (instate1, insymb1), outs1 in self._transition_graph.items():\n","            for (instate2, insymb2), outs2 in self._transition_graph.items():\n","                if instate2 in outs1 and not insymb2:\n","                    # vacuously adds the already added epsilon\n","                    # transitions as well\n","                    try:\n","                        new_graph[(instate1,insymb1)] |= outs2\n","                    except KeyError:\n","                        new_graph[(instate1,insymb1)] = outs2\n","\n","        return new_graph\n","\n","    def determinize(self, initial_state: str) -> tuple[set[frozenset[str]], frozenset[str], dict[frozenset[str],str], frozenset[str]]:\n","        # define the new states as the elements of the power set of the old \n","        # states\n","        new_states = {frozenset(s) for s in powerset(self._states) if s}\n","\n","        # add epsilon transitive closure\n","        epsilon_closed_graph = self._add_epsilon_transitive_closure()\n","\n","        # the new initial states is the set containing the old initial set \n","        # along with any state that could be reached by an epsilon transition\n","        # from the original initial state; because we have formed the epsilon\n","        # transitive closure, we only need to take one hope from the initial\n","        # state to get all such states \n","        new_initial_state = frozenset(\n","            {initial_state} | epsilon_closed_graph[initial_state, '']\n","        )\n","\n","        # filter epislon transitions\n","        filtered_transition_graph = {\n","            (instate, insymb): outstates\n","            for (instate, insymb), outstates in epsilon_closed_graph.items()\n","            if insymb\n","        }\n","\n","        # construct the new transition graph\n","        new_transition_graph = {\n","            (frozenset(s), a): {frozenset(t)}\n","            for s in new_states\n","            for t in new_states\n","            for a in self._alphabet\n","            if s and t\n","            if any(\n","                (sprime, a) in filtered_transition_graph and \n","                tprime in filtered_transition_graph[sprime, a]\n","                for sprime in s for tprime in t\n","            )\n","        }\n","\n","        return new_states, new_initial_state, new_transition_graph\n","        \n","    def add_transitions(self, transition_graph):\n","        self._transition_graph.update(transition_graph)\n","\n","    def _validate(self):\n","        self._validate_input_values()\n","        self._validate_output_types()\n","        self._homogenize_output_types()\n","        self._validate_output_values()\n","\n","    def _validate_input_values(self):\n","        for state, symbol in self._transition_graph.keys():\n","            if symbol not in self._alphabet:\n","                msg = 'all input symbols in transition function ' +\\\n","                      'must be in alphabet'\n","                raise ValueError(msg)\n","\n","            if state not in self._states:\n","                msg = 'all input states in transition function ' +\\\n","                      'must be in set of states'\n","                raise ValueError(msg)\n","\n","    def _validate_output_types(self):\n","        for states in self._transition_graph.values():\n","            if type(states) is not str and type(states) is not set:\n","                msg = 'all outputs in transition function ' +\\\n","                      'must be specified via str or set'\n","                raise ValueError(msg)            \n","\n","    def _homogenize_output_types(self):\n","        for inp, out in self._transition_graph.items():\n","            if type(out) is str:\n","                self._transition_graph[inp] = {out}\n","\n","    def _validate_output_values(self):\n","        for out in self._transition_graph.values():\n","            try:\n","                assert all([state in self._states for state in out])\n","            except AssertionError:\n","                msg = 'all output symbols in transition function' +\\\n","                      'must be in states'\n","                raise ValueError(msg)\n","\n","    @property\n","    def isdeterministic(self):\n","        return all(\n","            len(v) < 2 for v in self._transition_graph.values()\n","        )\n","\n","    @property\n","    def istotalfunction(self):\n","        return all(\n","            (s, a) in self._transition_graph\n","            for s in self._states\n","            for a in self._alphabet\n","        )\n","\n","    def relabel_states(self, state_map: dict[str, str]):\n","        \"\"\"Append tag to the input/ouput states in the transition function\n","\n","        Parameters\n","        ----------\n","        state_map\n","            A mapping from old states to new states\n","        \"\"\"\n","\n","        new_transition_graph = {}\n","\n","        for (instate, insymb), outs in self._transition_graph.items():\n","            new_inp = (state_map[instate], insymb)\n","            new_outs = {state_map[o] for o in outs}\n","            new_transition_graph[new_inp] = new_outs\n","\n","        self._transition_graph = new_transition_graph\n","\n","    def totalize(self):\n","        if not self.istotalfunction:\n","            domain = {\n","                (s, a) \n","                for s in self._states \n","                for a in self._alphabet\n","            }\n","\n","            sink_state = 'qsink'\n","\n","            while sink_state in self._states:\n","                sink_state += 'sink'\n","\n","            for inp in domain:\n","                if inp not in self._transition_graph:\n","                    self._transition_graph[inp] = {sink_state}\n","\n","    @property\n","    def transition_graph(self):\n","        return self._transition_graph"]},{"cell_type":"markdown","metadata":{"id":"d7sKjk8DB_ld"},"source":["An FSA can then be defined in a way that pretty closely matches the formal definition."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hUEub0BVB_ld"},"outputs":[],"source":["fsa1 = FiniteStateAutomaton(alphabet={\"a\", \"b\", \"\"},\n","                            states={\"q0\", \"q1\", \"q2\"},\n","                            initial_state=\"q0\",\n","                            final_states={\"q0\", \"q1\"},\n","                            transition_graph={(\"q0\", \"a\"): {\"q0\", \"q1\"},\n","                                              (\"q0\", \"\"): {\"q1\"},\n","                                              (\"q1\", \"\"): {\"q2\"},\n","                                              (\"q1\", \"a\"): {\"q0\"},\n","                                              (\"q1\", \"b\"): {\"q0\"}})"]},{"cell_type":"markdown","metadata":{"id":"I5KUc8M7B_ld"},"source":["You won't need to ever access the transition function directly, but note that it won't necessarily be equivalent to the dictionary you passed, since the epsilon closure is computed when the `TransitionFunction` is initialized. (This means that the machine may only be weakly equivalent to the one defined, since computing the epsilon transitive closure may add edges that allow states along an epsilon-only path the be skipped.)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BxqbZ9_5B_le"},"outputs":[],"source":["fsa1._transition_function._transition_graph"]},{"cell_type":"markdown","metadata":{"id":"OQuHxy1yB_le"},"source":["You also won't need to determinize the FSA directly, but just to show you that this is also implemented: "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rWGv7zJOB_le"},"outputs":[],"source":["fsa1_det = fsa1.determinize()\n","\n","fsa1_det._initial_state"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sGkow8wFB_le"},"outputs":[],"source":["fsa1_det._transition_function._transition_graph"]},{"cell_type":"markdown","metadata":{"id":"drk11-lQB_le"},"source":["And as expected, our original FSA is nondeterministic, while the determinized version is deterministic."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eRU4gMfeB_le"},"outputs":[],"source":["fsa1.isdeterministic, fsa1_det.isdeterministic"]},{"cell_type":"markdown","metadata":{"id":"fefg9tTRB_le"},"source":["You also won't need to compute the complement directly—it is used as part of computing intersection—but I have implemented that operation as well."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"adq9ert0B_lf"},"outputs":[],"source":["fsa1_comp = fsa1.complement()\n","\n","print(fsa1_det._states)\n","print(fsa1_comp._states)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wKsihYmjB_lf"},"outputs":[],"source":["print(fsa1_det._final_states)\n","print(fsa1_comp._final_states)"]},{"cell_type":"markdown","metadata":{"id":"Yhaau_SrB_lf"},"source":["Notice that, because taking the complement requires a totalized transition function, we have exactly the deterministic machine from above, except with explicit sink states."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bAPMUOFQB_lf"},"outputs":[],"source":["fsa1_comp._transition_function._transition_graph"]},{"cell_type":"markdown","metadata":{"id":"uFHTVm0nB_lf"},"source":["We don't need explicit determinization with the power set construction to have a deterministic machine. It's also possible to define a DFA directly. This machine gets implicitly converted to the strongly equivalent NFA."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aDmtjiHiB_lf"},"outputs":[],"source":["fsa2 = FiniteStateAutomaton(alphabet={\"c\", \"d\"},\n","                            states={\"q0\"},\n","                            initial_state=\"q0\",\n","                            final_states={\"q0\"},\n","                            transition_graph={(\"q0\", \"c\"): \"q0\",\n","                                              (\"q0\", \"d\"): \"q0\"})\n","\n","fsa2.isdeterministic"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z84mWiscB_lf"},"outputs":[],"source":["fsa2._transition_function._transition_graph"]},{"cell_type":"markdown","metadata":{"id":"ezQHTxJmB_lf"},"source":["Important for our purposes, we can compute strings that are in the language generated by the FSA by simply iterating through the `FiniteStateAutomaton` object. This behavior is implemented in `FiniteStateAutomaton.__iter__` and `FiniteStateAutomaton.__next__`, which rely heavily on `FiniteStateAutomaton._build_generator`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mEBnLrf7B_lf"},"outputs":[],"source":["for i, string in enumerate(fsa1):\n","    if i < 50:\n","        print(string)\n","    else:\n","        break"]},{"cell_type":"markdown","metadata":{"id":"18GkGUNRB_lf"},"source":["Note that we end up with some repeated elements. This is because different paths through an FSA can result in the same string—which, of course, is why there can be multiple parses associated with a string. We could make it so that elements are not repeated, but I have not done this for the sake of clarity (for Task 1).\n","\n","Compare the determinized machine."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VfSDwwv2B_lg"},"outputs":[],"source":["for i, string in enumerate(fsa1_det):\n","    if i < 50:\n","        print(string)\n","    else:\n","        break"]},{"cell_type":"markdown","metadata":{"id":"ZPx1cc8BB_lg"},"source":["Also for the sake of clarity, I have implemented iteration in a simplistic way that will often result in the iteration hanging for long periods of time (or infinitely) when there are many sink states and/or when the machine computes the empty set. This could be fixed, but it would require a bit of extra code that would be harder to understand, and so I have retained the simpler implementation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lXUWXWn0B_lg"},"outputs":[],"source":["# this will hang\n","for i, string in enumerate(fsa1_comp):\n","    if i < 50:\n","        print(string)\n","    else:\n","        break"]},{"cell_type":"markdown","metadata":{"id":"ErAMv9gWB_lg"},"source":["And just to show that our DFA works as expected:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GWe9Z134B_lg"},"outputs":[],"source":["for i, string in enumerate(fsa2):\n","    if i < 50:\n","        print(string)\n","    else:\n","        break"]},{"cell_type":"markdown","metadata":{"id":"yTlZq9v-B_lg"},"source":["Finally (and probably most importantly), I have implemented the recognition and parsing algorithms for you. The `FiniteStateAutomaton.__call__` method implements an interface to both the recognizer and the parser. To use the recognizer, set `mode=\"recognize\"`. As you would expect, the output will be a boolean."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d3NqSpq8B_lg"},"outputs":[],"source":["fsa1(\"ab\", mode=\"recognize\"), fsa1(\"ac\", mode=\"recognize\")"]},{"cell_type":"markdown","metadata":{"id":"pe1bQpEHB_lg"},"source":["To use the parser, set `mode=\"parse\"`. If the string is recognized, a set of parses will be output."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fyk4jZ_UB_lg"},"outputs":[],"source":["fsa1(\"ab\", mode=\"parse\")"]},{"cell_type":"markdown","metadata":{"id":"_OH7fze6B_lg"},"source":["If the string is not recognized, an empty set will be returned."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-33g1BN8B_lg"},"outputs":[],"source":["fsa1(\"ac\", mode=\"parse\")"]},{"cell_type":"markdown","metadata":{"id":"xw1RGQ0HB_lg"},"source":["Even though I have already implemented these algorithms for you, you should study their implementation in detail: in Task 4, you will be implementing the analogous algorithms for FSTs, and a good chunk of the logic in my implementation can be reused there."]},{"cell_type":"markdown","metadata":{"id":"3tP5utVpB_lh"},"source":["## Task 1\n","\n","Implement `FiniteStateAutomaton.union` and `FiniteStateAutomaton.concatenate`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iC8bHzoEB_lh"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"QVenV2iKB_lh"},"source":["Test your implementation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JvwTAdpgB_lh"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"s9pt6IuFB_lh"},"source":["## Task 2\n","\n","Define an FSA that can generate English noun phrases built from the following vocabulary.\n","\n","$$\\Sigma = \\{\\text{the}, \\text{that}, \\text{those}, \\text{lazy}, \\text{greyhound}, \\text{greyhounds}, \\text{human}, \\text{humans}, \\text{love}, \\text{loves}\\}$$\n","\n","You may find it useful to define a few different machines and then union or concatenate them.\n","\n","Your FSA should recognize not only simple noun phrases—such as *greyhounds*, *the greyhound*, *that human*, *those lazy greyhounds*, and *the humans* —but also noun phrases with relative clauses—such as *the greyhound that the lazy human loves* and *the humans that love the lazy greyhound*. Make sure, however, that your machine cannot generate any string that is not an noun phrase of English. For instance, your machine should **not** generate noun phrases with agreement errors in the relative clause—such as *the humans that loves the greyhound*.\n","\n","To make the parses produced by a parser for your machine interpretable—i.e. the sequence of states the FSA goes through to recognize the string—use state labels that track at least part of speech information—e.g. that *the* is a determiner; that is some contexts *that* is a determiner, while in others it is a complementizer. You may want to track additional information in the states to handle agreement correctly.\n","\n","You will not be able to build an FSA that can generate the infinite possible English noun phrases that can be built using this vocabulary. We will discuss the reasons for this when we cover context free grammars. But you should strive to capture as many noun phrases that can be built from this vocabulary as possible—including, insofar as it is possible, noun phrases of the form *the humans that love the lazy greyhound that loves the humans that...* with an unbounded number of relative clauses (making sure that you get the agreement correct)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E8SNAjlWB_lh"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"ZaWr3EU3B_lh"},"source":["Test this FSA by attempting to parse and recognize five possible noun phrases, which should be recognizable and have at least one parse, and five possible noun phrases, which should not be recognizable and should have no parses."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sbb0xe-9B_lh"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"zWN0GibrB_lh"},"source":["What kind of noun phrase cannot be generated by an FSA at all? Why?"]},{"cell_type":"markdown","metadata":{"id":"_LDMB0-SB_lh"},"source":[]},{"cell_type":"markdown","metadata":{"id":"OoqrYqWZB_lh"},"source":["## Task 3\n","\n","Define an FSA that can generate English sentences built from the vocabulary from Task 2. You are encouraged to use the noun phrase machine you developed in that task to generate the noun phrases within these sentences. As in that task, you may find it useful to define a few different machines (in addition to the noun phrase machine) and then union and/or concatenate them. \n","\n","Your FSA should recognize not only simple transitive sentences—such as *the greyhound loves the humans* —but also sentences that involve clause-embedding—such as *the greyhound loves that the humans love the greyhound*. As before, make sure you are correctly handling agreement; and insofar as it is possible, make sure that you can recognize sentences of unbounded size—such as *the humans love that the greyhound loves that the humans love that...*."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MjNnF67IB_lh"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"S0nA8bhDB_lh"},"source":["Test this FSA by attempting to parse and recognize five possible sentences, which should be recognizable and have at least one parse, and five possible sentences, which should not be recognizable and should have no parses."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"trJklHQCB_lh"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"jU6TqmXbB_lh"},"source":["## Finite State Transducers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vx-rK7zmB_li"},"outputs":[],"source":["FSTMode = Literal[\"recognize\", \"parse\", \"transduce\"]\n","FSTParse = tuple[tuple[str, str, str]]\n","\n","TransductionGraph = dict[tuple[str, str, str], str]\n","\n","class FiniteStateTransducer(FiniteStateAutomaton):\n","\n","    \"\"\"A finite state transducer\n","\n","    Parameters\n","    ----------\n","    alphabet1\n","    alphabet2\n","    states\n","    initial_state\n","    final states\n","    transition_graph\n","    transduction_graph\n","    \"\"\"\n","\n","    def __init__(self, alphabet1: set[str], alphabet2: set[str], states: set[str], \n","                 initial_state: str, final_states: set[str],\n","                 transition_graph: TransitionGraph, \n","                 transduction_graph: TransductionGraph):\n","        self._transduction_function = TransductionFunction(transduction_graph)\n","        self._alphabet2 = alphabet2        \n","        self._transduction_function.validate(alphabet1, alphabet2, states)\n","\n","        super().__init__(alphabet1,\n","                         states,\n","                         initial_state,\n","                         final_states,\n","                         transition_graph)\n","        \n","    def __next__(self):\n","        msg = \"we do not need this for the current assignment\"\n","        raise NotImplementedError(msg)\n","        \n","    def __call__(self, string1: str | list[str], \n","                 string2: str | list[str] | None = None, \n","                 mode: FSTMode = \"recognize\") -> bool | set[FSTParse] | set[str] | set[list[str]]:\n","        \"\"\"\n","        whether/how/what a string is accepted/parsed/transduced to by the FST\n","\n","        Parameters\n","        ----------\n","        string1\n","        string2\n","            only necessary if mode is \"recognize\" or \"parse\"\n","        mode\n","            whether to run in \"recognize\", \"parse\", or \"transduce\" mode\n","        \"\"\"\n","\n","        if mode == 'recognize':\n","            return self._recognize(string1, string2)\n","        elif mode == 'parse':\n","            return self._parse(string1, string2)\n","        elif mode == \"transduce\":\n","            return self._transduce(string1)\n","        else:\n","            msg = 'mode must be \"recognize\", \"parse\", or \"transduce\"'\n","            raise ValueError(msg)\n","\n","    @lru_cache(65536)\n","    def _recognize(self, string1: str | list[str], string2: str | list[str], \n","                   state: str | None = None) -> bool:\n","        \"\"\"\n","        whether a pair of string is accepted by the FST\n","\n","        Parameters\n","        ----------\n","        string1 : str\n","        string2 : str\n","        state : str | NoneType\n","\n","        Returns\n","        -------\n","        bool\n","        \"\"\"\n","        msg = \"you still need to implement FiniteStateTransducer._recognize\"\n","        raise NotImplementedError(msg)\n","\n","    @lru_cache(65536)\n","    def _parse(self, string1: str | list[str], string2: str | list[str], \n","               prev_state: str | None = None) -> set[FSTParse]:\n","        \"\"\"\n","        how a pair of strings is parsed by the FST\n","\n","        Parameters\n","        ----------\n","        string1 : str\n","        state : str | NoneType\n","        previous_states : list(str)\n","\n","        Returns\n","        -------\n","        list(list(str))\n","        \"\"\"\n","        msg = \"you still need to implement FiniteStateTransducer._parse\"\n","        raise NotImplementedError(msg)\n","\n","    @lru_cache(65536)\n","    def _transduce(self, string: str | list[str], state: str | None = None, \n","                   new_string: str='') -> set[str] | set[list[str]]:\n","        \"\"\"\n","        the strings transduced from the input by the FST\n","\n","        Parameters\n","        ----------\n","        string\n","        state\n","        new_string\n","        \"\"\"\n","        msg = \"you still need to implement FiniteStateTransducer._transduce\"\n","        raise NotImplementedError(msg)\n","\n","    def _relabel_states(self, tag: str):\n","        \"\"\"\n","        append tag to the input/ouput states throughout the FSA\n","\n","        Parameters\n","        ----------\n","        tag\n","        \"\"\"\n","\n","        super()._relabel_states(tag)\n","        \n","        state_map = {s: s+'_'+tag for s in self._states}\n","        self._transduction_function.relabel_states(state_map)\n","\n","        return self\n","\n","    def concatenate(self, other):\n","        msg = \"we do not need this for the current assignment\"\n","        raise NotImplementedError(msg)\n","    \n","    def exponentiate(self, k):        \n","        msg = \"we do not need this for the current assignment\"\n","        raise NotImplementedError(msg)\n","    \n","    def intersect(self, other):\n","        msg = \"we do not need this for the current assignment\"\n","        raise NotImplementedError(msg)\n","    \n","    def complement(self):\n","        msg = \"we do not need this for the current assignment\"\n","        raise NotImplementedError(msg)\n","    \n","    def union(other, self):\n","        msg = \"we do not need this for the current assignment\"\n","        raise NotImplementedError(msg)\n","\n","    def determinize(self):\n","        msg = \"we do not need this for the current assignment\"\n","        raise NotImplementedError(msg)\n","\n","class TransductionFunction(object):\n","    \"\"\"\n","    A finite state transduction function\n","\n","    Parameters\n","    ----------\n","    transduction_graph\n","    \"\"\"\n","\n","    def __init__(self, transduction_graph: TransductionGraph):\n","        self._transduction_graph = transduction_graph\n","\n","    def __call__(self, state1, state2, symbol):\n","        try:\n","            return self._transduction_graph[(state1, state2, symbol)]\n","        except KeyError:\n","            return set({})\n","\n","    def add_transductions(self, transduction_graph: TransductionGraph):\n","        self._transduction_graph.update(transduction_graph)\n","\n","    def validate(self, alphabet1, alphabet2, states):\n","        self._validate_input_values(alphabet1, states)\n","        self._validate_output_values(alphabet2)\n","\n","    def _validate_input_values(self, alphabet, states):\n","        for state1, state2, symbol in self._transduction_graph.keys():\n","            try:\n","                assert symbol in alphabet\n","\n","            except AssertionError:\n","                msg = 'all input symbols in transduction function ' +\\\n","                      'must be in alphabet1'\n","                raise ValueError(msg)\n","\n","            try:\n","                assert state1 in states and state2 in states\n","\n","            except AssertionError:\n","                msg = 'all input states in transduction function ' +\\\n","                      'must be in set of states'\n","                raise ValueError(msg)\n","\n","            try:\n","                assert symbol != ''\n","\n","            except AssertionError:\n","                msg = 'epsilon transduction not currently supported'\n","                raise ValueError(msg)\n","\n","                \n","        self._istotalfunction = all([(s1, s2, a) in self._transduction_graph\n","                                     for s1 in states\n","                                     for s2 in states\n","                                     for a in alphabet])\n","\n","    def _validate_output_values(self, alphabet):\n","        for symb in self._transduction_graph.values():\n","            try:\n","                assert symb in alphabet\n","            except AssertionError:\n","                msg = 'all output symbols in transduction function' +\\\n","                      'must be in alphabet2'\n","                raise ValueError(msg)\n","\n","    def relabel_states(self, state_map):\n","        \"\"\"\n","        append tag to the input/ouput states in the transduction function\n","\n","        Parameters\n","        ----------\n","        tag : str\n","        \"\"\"\n","\n","        new_transduction_graph = {}\n","\n","        for (instate, outstate, insymb), outs in self._transduction_graph.items():\n","            new_inp = (state_map[instate], state_map[outstate], insymb)\n","            new_transduction_graph[new_inp] = outs\n","\n","        self._transduction_graph = new_transduction_graph\n","\n","    @property\n","    def transduction_graph(self):\n","        return self._transduction_graph"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cZEBwqW-B_li"},"outputs":[],"source":["fst = FiniteStateTransducer(alphabet1={\"a\", \"b\"},\n","                            alphabet2={\"c\", \"d\"},\n","                            states={\"q0\", \"q1\"},\n","                            initial_state=\"q0\",\n","                            final_states={\"q0\", \"q1\"},\n","                            transition_graph={(\"q0\", \"a\"): {\"q0\", \"q1\"},\n","                                              (\"q0\", \"b\"): {\"q0\"},\n","                                              (\"q1\", \"a\"): {\"q0\"},\n","                                              (\"q1\", \"b\"): {\"q0\"}},\n","                            transduction_graph={(\"q0\", \"q0\", \"a\"): \"d\",\n","                                                (\"q0\", \"q0\", \"b\"): \"d\",\n","                                                (\"q0\", \"q1\", \"a\"): \"c\",\n","                                                (\"q0\", \"q1\", \"b\"): \"d\",\n","                                                (\"q1\", \"q0\", \"a\"): \"c\",\n","                                                (\"q1\", \"q0\", \"b\"): \"d\"})"]},{"cell_type":"markdown","metadata":{"id":"vkKpIC-bB_li"},"source":["## Task 4\n","\n","Implement `FiniteStateTransducer._recognize`, `FiniteStateTransducer._parse`, and `FiniteStateTransducer._transduce`. If you wish, you may alter the typing of the `transduction_graph` so that it outputs sets of characters in the output alphabet rather the single character."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SxvokaFOB_li"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"a13HJ5QuB_li"},"source":["## Task 5\n","\n","For this task, we'll be working with the [MegaAcceptability dataset](http://megaattitude.io/projects/mega-acceptability/), which you can read about in [this paper](https://www.glossa-journal.org/articles/10.5334/gjgl.1001/galley/1056/download/)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5E43OrhSB_li"},"outputs":[],"source":["!pip install pandas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zu-Hetr9B_li"},"outputs":[],"source":["import pandas as pd\n","\n","mega_acceptability = pd.read_csv('http://megaattitude.io/projects/mega-acceptability/mega-acceptability-v1/mega-acceptability-v1-normalized.tsv', sep='\\t')\n","\n","mega_acceptability"]},{"cell_type":"markdown","metadata":{"id":"URHuND_GB_li"},"source":["We will specifically be interested in the frames..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-y9HlBvEB_li"},"outputs":[],"source":["frames = set(mega_acceptability.frame.unique())\n","\n","frames"]},{"cell_type":"markdown","metadata":{"id":"HxZR_N5VB_li"},"source":["...and the sentences."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ci4cmR96B_lj"},"outputs":[],"source":["sentences = {frame: {s.lower() for s in mega_acceptability.query(f'frame==\"{frame}\"').sentence.unique()} \n","             for frame in frames}\n","\n","sentences['NP Ved NP']"]},{"cell_type":"markdown","metadata":{"id":"D_DANaFSB_lj"},"source":["Though for this task, you will find having access to the verb forms useful."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vQMqDJuoB_lj"},"outputs":[],"source":["verbs = {'root': set(mega_acceptability.verb.unique()),\n","         'past': set(mega_acceptability.query('frame==\"NP Ved\"').verbform.unique()),\n","         'past_participle': set(mega_acceptability.query('frame==\"NP was Ved\"').verbform.unique())}\n","\n","verbs['past']"]},{"cell_type":"markdown","metadata":{"id":"hiCWvRdxB_lj"},"source":["Construct a finite state transducer whose input language is the set of frames and whose output language is the set of sentences. The transducer should map a frame—e.g. `NP Ved NP`—to all sentences that instantiate that frame—e.g. `someone liked something`, `someone thought something`, etc."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2U1MrZsoB_lj"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Vk9iVJLdB_lj"},"source":["Test whether your FST recognizes all of the sentences in MegaAcceptability."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B4PtnOVmB_lj"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"NMa4c0r1B_lj"},"source":["Test whether your transduction works correctly by testing whether you output all of the sentences corresponding to a particular frame."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J9xtvGy8B_lj"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"2W20ANmwB_lj"},"source":["MegaAcceptability contains many items that are unacceptable, denoted by having a more negative `responsenorm`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8M0OoM6HB_lj"},"outputs":[],"source":["mega_acceptability.sort_values('responsenorm')"]},{"cell_type":"markdown","metadata":{"id":"_rEIY4YWB_lj"},"source":["Suppose that, given some frame in the input language, we wanted our FST to output only sentences that are instances of that frame whose `responsenorm` is above a particular threshold—i.e. generate only acceptable instances of a frame. You do not need to do it, but describe how you might go about it."]},{"cell_type":"markdown","metadata":{"id":"IoSNnxVHB_lk"},"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
